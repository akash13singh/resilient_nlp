{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "027f446b",
   "metadata": {},
   "source": [
    "# Multi Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67daa863",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T17:37:11.549957Z",
     "iopub.status.busy": "2022-03-31T17:37:11.549161Z",
     "iopub.status.idle": "2022-03-31T17:38:55.687241Z",
     "shell.execute_reply": "2022-03-31T17:38:55.687845Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import copy\n",
    "import cProfile\n",
    "from datasets import load_dataset\n",
    "import itertools\n",
    "import json\n",
    "import math\n",
    "import nltk\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "import time\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer, DataCollatorWithPadding, \\\n",
    "                         AutoModelForSequenceClassification, BertForSequenceClassification, \\\n",
    "                         BertModel, RobertaForSequenceClassification, RobertaModel\n",
    "\n",
    "from resilient_nlp.mini_roben import Clustering, ClusterRepRecoverer, ClusterRecovererWithPassthrough\n",
    "from resilient_nlp.models import BertClassifier\n",
    "from resilient_nlp.perturbers import ToyPerturber, WordScramblerPerturber\n",
    "from runner import ExperimentRunner\n",
    "from word_score_attack import BertWordScoreAttack\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5745bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tasks = ('imdb', 'sst', 'sst_bin', 'yelp_bin', 'yelp_full')\n",
    "#tasks = ('sst_bin', 'yelp_bin', 'yelp_full')\n",
    "tasks = ('sst_bin',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08b0399e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_types = ('bert', 'roberta')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920f47fc",
   "metadata": {},
   "source": [
    "Config for final evaluation on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4efd0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_set_size = 500\n",
    "use_dev_set = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67326e3",
   "metadata": {},
   "source": [
    "Config for evaluation on dev set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5e1860e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#eval_set_size = 113\n",
    "#use_dev_set = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08d28b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_raw_length = 826\n",
    "preprocess = lambda row: { 'text': row['text'].lower()[:max_raw_length]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c824af5",
   "metadata": {},
   "source": [
    "## IMDb Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0903049b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_test_set = {}\n",
    "sampled_test_set_dict = {}\n",
    "sampled_test_set_adv_no_ws = {}\n",
    "sampled_test_set_adv_incl_ws = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ae7a7c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T17:38:55.696962Z",
     "iopub.status.busy": "2022-03-31T17:38:55.696275Z",
     "iopub.status.idle": "2022-03-31T17:38:57.375270Z",
     "shell.execute_reply": "2022-03-31T17:38:57.375885Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration redacted--imdb-f63738dec0d5e230\n",
      "Reusing dataset parquet (/home/user/.cache/huggingface/datasets/parquet/redacted--imdb-f63738dec0d5e230/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7329d07297df4a1ba33e9adcaff2a945",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "imdb = load_dataset('../output/huggingface/imdb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9bc64b56",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T17:38:57.393928Z",
     "iopub.status.busy": "2022-03-31T17:38:57.393247Z",
     "iopub.status.idle": "2022-03-31T17:38:57.432347Z",
     "shell.execute_reply": "2022-03-31T17:38:57.432870Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/user/.cache/huggingface/datasets/parquet/redacted--imdb-f63738dec0d5e230/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901/cache-b45d493b37ab1dc7.arrow\n"
     ]
    }
   ],
   "source": [
    "random.seed(11)\n",
    "if use_dev_set:\n",
    "    sampled_test_set['imdb'] = imdb['dev'].select(random.choices(range(len(imdb['dev'])), k=eval_set_size)).map(preprocess)\n",
    "else:\n",
    "    sampled_test_set['imdb'] = imdb['attack_eval_truncated'].select(range(eval_set_size)).map(preprocess)\n",
    "\n",
    "\n",
    "# This is silly but apparently huggingface datasets are immutable?\n",
    "# Representing it as something a bit more sane\n",
    "sampled_test_set_dict['imdb'] = [\n",
    "    {\n",
    "        'text': row['text'],\n",
    "        'label': row['label'],\n",
    "    }\n",
    "    for row in sampled_test_set['imdb']\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34d21ea",
   "metadata": {},
   "source": [
    "## SST-5 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38106401",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No config specified, defaulting to: sst/default\n",
      "Reusing dataset sst (/home/user/.cache/huggingface/datasets/sst/default/1.0.0/b8a7889ef01c5d3ae8c379b84cc4080f8aad3ac2bc538701cbe0ac6416fb76ff)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a574a2578e044dd7a68100b798b016d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/user/.cache/huggingface/datasets/sst/default/1.0.0/b8a7889ef01c5d3ae8c379b84cc4080f8aad3ac2bc538701cbe0ac6416fb76ff/cache-3c142acdab53f98c.arrow\n",
      "Loading cached processed dataset at /home/user/.cache/huggingface/datasets/sst/default/1.0.0/b8a7889ef01c5d3ae8c379b84cc4080f8aad3ac2bc538701cbe0ac6416fb76ff/cache-0bf56ce0086915ee.arrow\n",
      "Loading cached processed dataset at /home/user/.cache/huggingface/datasets/sst/default/1.0.0/b8a7889ef01c5d3ae8c379b84cc4080f8aad3ac2bc538701cbe0ac6416fb76ff/cache-19fdf8d124be4ba7.arrow\n",
      "Loading cached processed dataset at /home/user/.cache/huggingface/datasets/sst/default/1.0.0/b8a7889ef01c5d3ae8c379b84cc4080f8aad3ac2bc538701cbe0ac6416fb76ff/cache-fc3e75429c3f7637.arrow\n"
     ]
    }
   ],
   "source": [
    "treebank_detok = TreebankWordDetokenizer()\n",
    "\n",
    "sst = load_dataset('sst').map(\n",
    "    lambda row: {\n",
    "        \"text\": treebank_detok.detokenize(row[\"sentence\"].split()),\n",
    "        \"label\": min(math.floor(row[\"label\"] / 0.2), 4.0),\n",
    "    }, remove_columns=['sentence', 'tokens', 'tree']\n",
    ")\n",
    "\n",
    "random.seed(11)\n",
    "if use_dev_set:\n",
    "    sampled_test_set['sst'] = sst['validation'].select(random.choices(range(len(sst['validation'])), k=eval_set_size)).map(preprocess)\n",
    "else:\n",
    "    sampled_test_set['sst'] = sst['test'].select(random.choices(range(len(sst['test'])), k=eval_set_size)).map(preprocess)\n",
    "\n",
    "sampled_test_set_dict['sst'] = [\n",
    "    {\n",
    "        'text': row['text'],\n",
    "        'label': row['label'],\n",
    "    }\n",
    "    for row in sampled_test_set['sst']\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3bae186",
   "metadata": {},
   "source": [
    "## SST-2 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f1e5046",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No config specified, defaulting to: sst/default\n",
      "Reusing dataset sst (/home/user/.cache/huggingface/datasets/sst/default/1.0.0/b8a7889ef01c5d3ae8c379b84cc4080f8aad3ac2bc538701cbe0ac6416fb76ff)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f025cc984eda496ba2a0775c4db3051e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/user/.cache/huggingface/datasets/sst/default/1.0.0/b8a7889ef01c5d3ae8c379b84cc4080f8aad3ac2bc538701cbe0ac6416fb76ff/cache-f4f1ada73617d193.arrow\n",
      "Loading cached processed dataset at /home/user/.cache/huggingface/datasets/sst/default/1.0.0/b8a7889ef01c5d3ae8c379b84cc4080f8aad3ac2bc538701cbe0ac6416fb76ff/cache-6279b6f0f8a08f9a.arrow\n",
      "Loading cached processed dataset at /home/user/.cache/huggingface/datasets/sst/default/1.0.0/b8a7889ef01c5d3ae8c379b84cc4080f8aad3ac2bc538701cbe0ac6416fb76ff/cache-6c5f77e5aefdd0e2.arrow\n",
      "Loading cached processed dataset at /home/user/.cache/huggingface/datasets/sst/default/1.0.0/b8a7889ef01c5d3ae8c379b84cc4080f8aad3ac2bc538701cbe0ac6416fb76ff/cache-c46f07c913633b4d.arrow\n",
      "Loading cached processed dataset at /home/user/.cache/huggingface/datasets/sst/default/1.0.0/b8a7889ef01c5d3ae8c379b84cc4080f8aad3ac2bc538701cbe0ac6416fb76ff/cache-87779081ead23eae.arrow\n",
      "Loading cached processed dataset at /home/user/.cache/huggingface/datasets/sst/default/1.0.0/b8a7889ef01c5d3ae8c379b84cc4080f8aad3ac2bc538701cbe0ac6416fb76ff/cache-7813af5c6a05de02.arrow\n",
      "Loading cached processed dataset at /home/user/.cache/huggingface/datasets/sst/default/1.0.0/b8a7889ef01c5d3ae8c379b84cc4080f8aad3ac2bc538701cbe0ac6416fb76ff/cache-8a65da8df1dcb8ac.arrow\n"
     ]
    }
   ],
   "source": [
    "treebank_detok = TreebankWordDetokenizer()\n",
    "\n",
    "sst_bin = load_dataset('sst').filter(\n",
    "        lambda row: row[\"label\"] < 0.4 or row[\"label\"] >= 0.6\n",
    "    ).map(\n",
    "    lambda row: {\n",
    "        \"text\": treebank_detok.detokenize(row[\"sentence\"].split()),\n",
    "        \"label\": min(math.floor(row[\"label\"] / 0.5), 1.0),\n",
    "    }\n",
    ")\n",
    "\n",
    "random.seed(11)\n",
    "if use_dev_set:\n",
    "    sampled_test_set['sst_bin'] = sst_bin['validation'].select(random.choices(range(len(sst_bin['validation'])), k=eval_set_size)).map(preprocess)\n",
    "else:\n",
    "    sampled_test_set['sst_bin'] = sst_bin['test'].select(random.choices(range(len(sst_bin['test'])), k=eval_set_size)).map(preprocess)\n",
    "\n",
    "sampled_test_set_dict['sst_bin'] = [\n",
    "    {\n",
    "        'text': row['text'],\n",
    "        'label': row['label'],\n",
    "    }\n",
    "    for row in sampled_test_set['sst_bin']\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b096c3f",
   "metadata": {},
   "source": [
    "## Yelp-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ccfe1b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset yelp_polarity (/home/user/.cache/huggingface/datasets/yelp_polarity/plain_text/1.0.0/a770787b2526bdcbfc29ac2d9beb8e820fbc15a03afd3ebc4fb9d8529de57544)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "956e6630b7ab4d118e6d878c67451038",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/user/.cache/huggingface/datasets/yelp_polarity/plain_text/1.0.0/a770787b2526bdcbfc29ac2d9beb8e820fbc15a03afd3ebc4fb9d8529de57544/cache-103b3f679d53323c.arrow\n"
     ]
    }
   ],
   "source": [
    "yelp_bin = load_dataset('yelp_polarity')\n",
    "\n",
    "random.seed(11)\n",
    "sampled_test_set['yelp_bin'] = yelp_bin['test'].select(random.choices(range(len(sst['test'])), k=eval_set_size)).map(preprocess)\n",
    "\n",
    "sampled_test_set_dict['yelp_bin'] = [\n",
    "    {\n",
    "        'text': row['text'],\n",
    "        'label': row['label'],\n",
    "    }\n",
    "    for row in sampled_test_set['yelp_bin']\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f2fc43",
   "metadata": {},
   "source": [
    "## Yelp-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "92deac75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset yelp_polarity (/home/user/.cache/huggingface/datasets/yelp_polarity/plain_text/1.0.0/a770787b2526bdcbfc29ac2d9beb8e820fbc15a03afd3ebc4fb9d8529de57544)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "362ee4f8496b4c1d98038a9f7e64cb4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/user/.cache/huggingface/datasets/yelp_polarity/plain_text/1.0.0/a770787b2526bdcbfc29ac2d9beb8e820fbc15a03afd3ebc4fb9d8529de57544/cache-103b3f679d53323c.arrow\n"
     ]
    }
   ],
   "source": [
    "yelp_full = load_dataset('yelp_polarity')\n",
    "\n",
    "random.seed(11)\n",
    "sampled_test_set['yelp_full'] = yelp_bin['test'].select(random.choices(range(len(sst['test'])), k=eval_set_size)).map(preprocess)\n",
    "\n",
    "sampled_test_set_dict['yelp_full'] = [\n",
    "    {\n",
    "        'text': row['text'],\n",
    "        'label': row['label'],\n",
    "    }\n",
    "    for row in sampled_test_set['yelp_full']\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5ec74a",
   "metadata": {},
   "source": [
    "### Perturbations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cb0dab9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_perturbed_multiset(input, wsp):\n",
    "    random.seed(11)\n",
    "    result = []\n",
    "\n",
    "    for i in range(10):\n",
    "        test_item = copy.deepcopy(input)\n",
    "\n",
    "        for row in test_item:\n",
    "            row['text'] = wsp.perturb([row['text']])[0][0]\n",
    "        result.append(test_item)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf674fa6",
   "metadata": {},
   "source": [
    "Perturbed set with no whitespace modifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8712401f",
   "metadata": {},
   "outputs": [],
   "source": [
    "wsp = WordScramblerPerturber(perturb_prob=0.1, weight_add=1, weight_drop=1, weight_swap=1,\n",
    "                             weight_split_word=0, weight_merge_words=0)\n",
    "\n",
    "for task in tasks:\n",
    "    sampled_test_set_adv_no_ws[task] = generate_perturbed_multiset(sampled_test_set_dict[task], wsp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc4acd0",
   "metadata": {},
   "source": [
    "Perturbed set with whitespace modifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "72861511",
   "metadata": {},
   "outputs": [],
   "source": [
    "wsp = WordScramblerPerturber(perturb_prob=0.1, weight_add=1, weight_drop=1, weight_swap=1,\n",
    "                             weight_split_word=1, weight_merge_words=1)\n",
    "\n",
    "for task in tasks:\n",
    "    sampled_test_set_adv_incl_ws[task] = generate_perturbed_multiset(sampled_test_set_dict[task], wsp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6454c2",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370b1cdb",
   "metadata": {},
   "source": [
    "### BERT, including finetuned variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3573bce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = {}\n",
    "model_base = {}\n",
    "model_finetuned = { type: {} for type in model_types }\n",
    "model_finetuned_all_pert = { type: {} for type in model_types }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "17700b9e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T17:38:57.438989Z",
     "iopub.status.busy": "2022-03-31T17:38:57.436437Z",
     "iopub.status.idle": "2022-03-31T17:38:58.316850Z",
     "shell.execute_reply": "2022-03-31T17:38:58.316245Z"
    }
   },
   "outputs": [],
   "source": [
    "bert_checkpoint = \"bert-base-uncased\"\n",
    "tokenizer['bert'] = AutoTokenizer.from_pretrained(bert_checkpoint)\n",
    "model_base['bert'] = BertModel.from_pretrained(bert_checkpoint).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a09ce62d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T17:38:58.323968Z",
     "iopub.status.busy": "2022-03-31T17:38:58.321059Z",
     "iopub.status.idle": "2022-03-31T17:41:02.742864Z",
     "shell.execute_reply": "2022-03-31T17:41:02.743367Z"
    }
   },
   "outputs": [],
   "source": [
    "bert_checkpoint_finetuned_imdb = \"../output/huggingface/bert-base-uncased-imdb\"\n",
    "if 'bert' in model_types and 'imdb' in tasks:\n",
    "    model_finetuned['bert']['imdb'] = BertForSequenceClassification.from_pretrained(bert_checkpoint_finetuned_imdb).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e0bc679c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_checkpoint_finetuned_imdb_all_pert = \"../output/huggingface/bert-base-uncased-imdb-all-pert\"\n",
    "if 'bert' in model_types and 'imdb' in tasks:\n",
    "    model_finetuned_all_pert['bert']['imdb'] = BertForSequenceClassification.from_pretrained(bert_checkpoint_finetuned_imdb_all_pert).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2454c4ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T17:38:58.323968Z",
     "iopub.status.busy": "2022-03-31T17:38:58.321059Z",
     "iopub.status.idle": "2022-03-31T17:41:02.742864Z",
     "shell.execute_reply": "2022-03-31T17:41:02.743367Z"
    }
   },
   "outputs": [],
   "source": [
    "bert_checkpoint_finetuned_sst = \"../output/huggingface/bert-base-uncased-sst\"\n",
    "if 'bert' in model_types and 'sst' in tasks:\n",
    "    model_finetuned['bert']['sst'] = BertForSequenceClassification.from_pretrained(bert_checkpoint_finetuned_sst).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "af9a1b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_checkpoint_finetuned_sst_bin = '../output/huggingface/bert-base-uncased-sst_bin'\n",
    "if 'bert' in model_types and 'sst_bin' in tasks:\n",
    "    model_finetuned['bert']['sst_bin'] = BertForSequenceClassification.from_pretrained(bert_checkpoint_finetuned_sst_bin).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a6c66b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_checkpoint_finetuned_yelp_bin = '../output/huggingface/bert-base-uncased-yelp_bin'\n",
    "if 'bert' in model_types and 'yelp_bin' in tasks:\n",
    "    model_finetuned['bert']['yelp_bin'] = BertForSequenceClassification.from_pretrained(bert_checkpoint_finetuned_yelp_bin).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ad769b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_checkpoint_finetuned_yelp_full = '../output/huggingface/bert-base-uncased-yelp_full'\n",
    "if 'bert' in model_types and 'yelp_full' in tasks:\n",
    "    model_finetuned['bert']['yelp_full'] = BertForSequenceClassification.from_pretrained(bert_checkpoint_finetuned_yelp_full).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "084978a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T17:38:57.438989Z",
     "iopub.status.busy": "2022-03-31T17:38:57.436437Z",
     "iopub.status.idle": "2022-03-31T17:38:58.316850Z",
     "shell.execute_reply": "2022-03-31T17:38:58.316245Z"
    }
   },
   "outputs": [],
   "source": [
    "roberta_checkpoint = \"roberta-base\"\n",
    "tokenizer['roberta'] = AutoTokenizer.from_pretrained(roberta_checkpoint)\n",
    "model_base['roberta'] = RobertaModel.from_pretrained(roberta_checkpoint).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6a93a042",
   "metadata": {},
   "outputs": [],
   "source": [
    "roberta_checkpoint_finetuned_imdb = \"../output/huggingface/roberta-base-imdb\"\n",
    "if 'roberta' in model_types and 'imdb' in tasks:\n",
    "    model_finetuned['roberta']['imdb'] = RobertaForSequenceClassification.from_pretrained(roberta_checkpoint_finetuned_imdb).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8ae40370",
   "metadata": {},
   "outputs": [],
   "source": [
    "roberta_checkpoint_finetuned_sst = '../output/huggingface/roberta-base-sst'\n",
    "if 'roberta' in model_types and 'sst' in tasks:\n",
    "    model_finetuned['roberta']['sst'] = RobertaForSequenceClassification.from_pretrained(roberta_checkpoint_finetuned_sst).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dfd9fc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "roberta_checkpoint_finetuned_sst_bin = '../output/huggingface/roberta-base-sst_bin'\n",
    "if 'roberta' in model_types and 'sst_bin' in tasks:\n",
    "    model_finetuned['roberta']['sst_bin'] = RobertaForSequenceClassification.from_pretrained(roberta_checkpoint_finetuned_sst_bin).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "328428ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "roberta_checkpoint_finetuned_yelp_bin = '../output/huggingface/roberta-base-yelp_bin'\n",
    "if 'roberta' in model_types and 'yelp_bin' in tasks:\n",
    "    model_finetuned['roberta']['yelp_bin'] = RobertaForSequenceClassification.from_pretrained(roberta_checkpoint_finetuned_yelp_bin).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bb218742",
   "metadata": {},
   "outputs": [],
   "source": [
    "roberta_checkpoint_finetuned_yelp_full = '../output/huggingface/roberta-base-yelp_full'\n",
    "if 'roberta' in model_types and 'yelp_full' in tasks:\n",
    "    model_finetuned['roberta']['yelp_full'] = RobertaForSequenceClassification.from_pretrained(roberta_checkpoint_finetuned_yelp_full).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63dab18",
   "metadata": {},
   "source": [
    "### RobEn clusterings (as baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5758ab39",
   "metadata": {},
   "source": [
    "The first clustering is ConnComp (which very aggressively merges clusters). The second is AggClust, which uses a cost function to better preserve fidelity. The second one should generally be better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8b3c3fb8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T17:41:02.748232Z",
     "iopub.status.busy": "2022-03-31T17:41:02.747612Z",
     "iopub.status.idle": "2022-03-31T17:43:45.925467Z",
     "shell.execute_reply": "2022-03-31T17:43:45.924906Z"
    }
   },
   "outputs": [],
   "source": [
    "roben_clustering = Clustering.from_pickle(\"../vocab100000_ed1.pkl\")\n",
    "roben_recoverer = ClusterRecovererWithPassthrough(\"cache\", roben_clustering)\n",
    "roben_clustering2 = Clustering.from_pickle(\"../vocab100000_ed1_gamma0.3.pkl\")\n",
    "roben_recoverer2 = ClusterRecovererWithPassthrough(\"cache\", roben_clustering2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17aaf07",
   "metadata": {},
   "source": [
    "## Model Prediction Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a2efe10f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T17:43:49.085047Z",
     "iopub.status.busy": "2022-03-31T17:43:49.084381Z",
     "iopub.status.idle": "2022-03-31T17:43:49.087081Z",
     "shell.execute_reply": "2022-03-31T17:43:49.086570Z"
    }
   },
   "outputs": [],
   "source": [
    "max_sequence_length = 128\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cebe273",
   "metadata": {},
   "source": [
    "These are wrappers for standard (possibly finetuned) Huggingface models, using their normal tokenizers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7b958a5c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T17:43:49.094914Z",
     "iopub.status.busy": "2022-03-31T17:43:49.094323Z",
     "iopub.status.idle": "2022-03-31T17:43:49.096390Z",
     "shell.execute_reply": "2022-03-31T17:43:49.096869Z"
    }
   },
   "outputs": [],
   "source": [
    "def standard_model_predict(tokenizer, model, sentences, recoverer, return_pred_tensor, recoverer_tokenize):\n",
    "    if recoverer is not None:\n",
    "        if recoverer_tokenize:\n",
    "            tok = nltk.tokenize.treebank.TreebankWordTokenizer()\n",
    "            sentences = [ \" \".join(tok_list) for tok_list in tok.tokenize_sents(sentences) ]\n",
    "        sentences = [ recoverer.recover(s.lower()) for s in sentences ]\n",
    "        if recoverer_tokenize:\n",
    "            detok = nltk.tokenize.treebank.TreebankWordDetokenizer()\n",
    "            sentences = [ detok.detokenize(s.split(\" \")) for s in sentences]\n",
    "    tokenized = tokenizer(sentences, truncation=True, padding='max_length', max_length=max_sequence_length,\n",
    "                          return_tensors='pt')\n",
    "    tokenized = { k: v.to(device) for k, v in tokenized.items() }\n",
    "    preds = model(**tokenized)\n",
    "    if return_pred_tensor:\n",
    "        return preds\n",
    "    else:\n",
    "        return torch.argmax(preds.logits, dim=1)\n",
    "\n",
    "def wrap_standard_model(tokenizer, model, recoverer=None, return_pred_tensor=True, recoverer_tokenize=False):\n",
    "    return lambda sentences: standard_model_predict(tokenizer, model, sentences, recoverer, return_pred_tensor,\n",
    "                                                    recoverer_tokenize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3cfccf9",
   "metadata": {},
   "source": [
    "This is a wrapper for the machine trained tokenizer+embedder (aka MockingBERT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0ba7bb36",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T17:43:49.104843Z",
     "iopub.status.busy": "2022-03-31T17:43:49.104249Z",
     "iopub.status.idle": "2022-03-31T17:43:49.106973Z",
     "shell.execute_reply": "2022-03-31T17:43:49.107449Z"
    }
   },
   "outputs": [],
   "source": [
    "def mltokenizer_model_predict(runner, model, cls_embedding, sep_embedding, pad_embedding, sentences, return_pred_tensor):\n",
    "    # Truncate and lower case. Truncation is for performance only\n",
    "    sentences = [ s.lower()[:8*max_sequence_length] for s in sentences]\n",
    "    embedding = runner.embed(sentences=sentences,\n",
    "        start_token=cls_embedding, end_token=sep_embedding, pad_token=pad_embedding,\n",
    "        max_tokens=max_sequence_length)\n",
    "    preds = model(inputs_embeds=embedding['inputs_embeds'], attention_mask=embedding['attention_mask'])\n",
    "    if return_pred_tensor:\n",
    "        return preds\n",
    "    else:\n",
    "        return torch.argmax(preds.logits, dim=1)\n",
    "\n",
    "def wrap_mltokenizer_model(mltokenizer_prefix, tokenizer, model, cf_embedding, type, return_pred_tensor=True):\n",
    "    filename = \"../{}.pth\".format(mltokenizer_prefix)\n",
    "    runner = ExperimentRunner(device, model_filename=filename)\n",
    "    if type == 'bert':\n",
    "        cls_token_id = tokenizer.vocab['[CLS]']\n",
    "        sep_token_id = tokenizer.vocab['[SEP]']\n",
    "        pad_token_id = tokenizer.vocab['[PAD]']\n",
    "    elif type == 'roberta':\n",
    "        cls_token_id = tokenizer.vocab['<s>']\n",
    "        sep_token_id = tokenizer.vocab['</s>']\n",
    "        pad_token_id = tokenizer.vocab['<pad>']\n",
    "    cls_embedding = cf_embedding(torch.tensor([cls_token_id], device=device)).view(-1)\n",
    "    sep_embedding = cf_embedding(torch.tensor([sep_token_id], device=device)).view(-1)\n",
    "    pad_embedding = cf_embedding(torch.tensor([pad_token_id], device=device)).view(-1)\n",
    "    \n",
    "    return lambda sentences: mltokenizer_model_predict(runner, model, cls_embedding, sep_embedding,\n",
    "                                                      pad_embedding, sentences, return_pred_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1da87ea",
   "metadata": {},
   "source": [
    "## Evaluation Helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a4b8cf",
   "metadata": {},
   "source": [
    "Evaluates a wrapped model on a test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2033ec30",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T17:43:49.113921Z",
     "iopub.status.busy": "2022-03-31T17:43:49.113314Z",
     "iopub.status.idle": "2022-03-31T17:43:49.115410Z",
     "shell.execute_reply": "2022-03-31T17:43:49.115943Z"
    }
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate_model(model, test_set):\n",
    "    num_batches = math.ceil(len(test_set) / batch_size)\n",
    "    \n",
    "    sentences = [ x['text'] for x in test_set ]\n",
    "    labels = [ x['label'] for x in test_set ]\n",
    "    pred_batches = []\n",
    "    \n",
    "    for i in tqdm(range(num_batches)):\n",
    "        bs = i * batch_size\n",
    "        be = bs + batch_size\n",
    "        \n",
    "        output = model(sentences[bs:be])\n",
    "        \n",
    "        pred_batches.append(torch.argmax(output.logits, dim=1).detach().cpu())\n",
    "    preds = torch.cat(pred_batches)\n",
    "    \n",
    "    print(classification_report(labels, preds, digits=4))\n",
    "    \n",
    "    accuracy = accuracy_score(labels, preds)\n",
    "    f1 = f1_score(labels, preds, average='macro')\n",
    "    \n",
    "    return accuracy, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac39aaf",
   "metadata": {},
   "source": [
    "Evaluates a wrapped model on a stochastic, pseudo-adversarial test set. This means that each input sentence is replicated x times (typically 10) with randomized perturbations, and an attack is considered successful if *any* of the predictions is incorrect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "33c8259a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T17:43:49.124562Z",
     "iopub.status.busy": "2022-03-31T17:43:49.123971Z",
     "iopub.status.idle": "2022-03-31T17:43:49.125916Z",
     "shell.execute_reply": "2022-03-31T17:43:49.126467Z"
    }
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate_model_adv(model, test_sets):\n",
    "    labels = [ x['label'] for x in test_sets[0] ]\n",
    "    adv_preds = copy.copy(labels)\n",
    "    accuracy_list = []\n",
    "    f1_list = []\n",
    "    \n",
    "    for idx in tqdm(range(len(test_sets))):\n",
    "        test_set = test_sets[idx]\n",
    "        num_batches = math.ceil(len(test_set) / batch_size)\n",
    "    \n",
    "        sentences = [ x['text'] for x in test_set ]\n",
    "        pred_batches = []\n",
    "    \n",
    "        for i in range(num_batches):\n",
    "            bs = i * batch_size\n",
    "            be = bs + batch_size\n",
    "        \n",
    "            output = model(sentences[bs:be])\n",
    "        \n",
    "            pred_batches.append(torch.argmax(output.logits, dim=1).detach().cpu())\n",
    "        preds = torch.cat(pred_batches)\n",
    "        \n",
    "        for i in range(len(adv_preds)):\n",
    "            if labels[i] != preds[i]:\n",
    "                adv_preds[i] = preds[i]\n",
    "\n",
    "        accuracy_list.append(accuracy_score(labels, adv_preds))\n",
    "        f1_list.append(f1_score(labels, adv_preds, average='macro'))\n",
    "    \n",
    "    print(classification_report(labels, adv_preds, digits=4))    \n",
    "    \n",
    "    return accuracy_list, f1_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1bba12b",
   "metadata": {},
   "source": [
    "Evaluates a model using WordScoreAttack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "26be9ad5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T17:43:49.132768Z",
     "iopub.status.busy": "2022-03-31T17:43:49.132187Z",
     "iopub.status.idle": "2022-03-31T17:43:49.134404Z",
     "shell.execute_reply": "2022-03-31T17:43:49.134865Z"
    }
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate_model_word_score(model, test_set, allow_whitespace_pert=True, report_prefix=None, word_scores_file=None):\n",
    "    attacker = BertWordScoreAttack(\n",
    "        WordScramblerPerturber(perturb_prob=1, weight_add=1, weight_drop=1, weight_swap=1,\n",
    "                               weight_split_word=int(allow_whitespace_pert),\n",
    "                               weight_merge_words=0),\n",
    "        word_scores_file, model, tokenizer=None, max_sequence_length=max_sequence_length,\n",
    "        attack_whitespace=allow_whitespace_pert,\n",
    "    )\n",
    "\n",
    "    res = attacker.attack(test_set, max_tokens_to_perturb=10, max_tries_per_token=4, mode=0, print_summary=False)\n",
    "\n",
    "    if report_prefix is not None:\n",
    "        res.to_csv(f\"{report_prefix}_df.csv\")\n",
    "        with open(f\"{report_prefix}_stats.json\", \"w\") as f:\n",
    "            json.dump(attacker.compute_attack_stats(), fp=f)            \n",
    "    \n",
    "    print(classification_report(res['ground_truth'], res['perturbed_preds'], digits=4))    \n",
    "    \n",
    "    accuracy = accuracy_score(res['ground_truth'], res['perturbed_preds'])\n",
    "    f1 = f1_score(res['ground_truth'], res['perturbed_preds'], average='macro')\n",
    "    \n",
    "    return accuracy, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3b6fcd6e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T17:44:32.712568Z",
     "iopub.status.busy": "2022-03-31T17:44:32.711928Z",
     "iopub.status.idle": "2022-03-31T17:45:57.105422Z",
     "shell.execute_reply": "2022-03-31T17:45:57.104806Z"
    }
   },
   "outputs": [],
   "source": [
    "all_models = {\n",
    "    'baseline': lambda task, type: wrap_standard_model(tokenizer[type], model_finetuned[type][task]),\n",
    "    'baseline_all_pert': lambda task, type: wrap_standard_model(tokenizer[type], model_finetuned_all_pert[type][task]),\n",
    "    'roben_1': lambda task, type: wrap_standard_model(tokenizer[type], model_finetuned[type][task], roben_recoverer),\n",
    "    'roben_2': lambda task, type: wrap_standard_model(tokenizer[type], model_finetuned[type][task], roben_recoverer2),\n",
    "    'roben_1_tok': lambda task, type: wrap_standard_model(tokenizer[type], model_finetuned[type][task], roben_recoverer, recoverer_tokenize=True),\n",
    "    'roben_2_tok': lambda task, type: wrap_standard_model(tokenizer[type], model_finetuned[type][task], roben_recoverer2, recoverer_tokenize=True),\n",
    "}\n",
    "\n",
    "mltok_model_names = [\n",
    "    '64k_lstm_clean_vanilla',\n",
    "    '64k_lstm_no_whitespace_pert_vanilla',\n",
    "    '64k_lstm_all_pert_vanilla',\n",
    "    '64k_lstm_clean_finetuned',\n",
    "    '64k_lstm_no_whitespace_pert_finetuned',\n",
    "    '64k_lstm_all_pert_finetuned',\n",
    "    '64k_cnn_no_whitespace_pert_finetuned',\n",
    "    '2m_lstm_all_pert_finetuned',\n",
    "    '32k_lstm_all_pert_finetuned_100ep',\n",
    "]\n",
    "\n",
    "for name in mltok_model_names:\n",
    "    if name.endswith('_vanilla'):\n",
    "        cf_embedding = lambda task, type: model_base[type].embeddings.word_embeddings\n",
    "        filename = lambda task, type, name: f'output/{type}_{name}'\n",
    "    else:\n",
    "        cf_embedding = lambda task, type: model_finetuned[type][task].base_model.embeddings.word_embeddings\n",
    "        filename = lambda task, type, name: f'output/{type}_{name}_{task}'\n",
    "    # name=name is a hack to avoid Python late binding\n",
    "    all_models[name] = lambda task, type, name=name, filename=filename, cf_embedding=cf_embedding: wrap_mltokenizer_model(filename(task, type, name), tokenizer[type], model_finetuned[type][task], cf_embedding(task, type), type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e61f9273",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T17:45:57.109658Z",
     "iopub.status.busy": "2022-03-31T17:45:57.109097Z",
     "iopub.status.idle": "2022-03-31T17:45:57.111181Z",
     "shell.execute_reply": "2022-03-31T17:45:57.111650Z"
    }
   },
   "outputs": [],
   "source": [
    "evaluations = [\n",
    "    'clean',\n",
    "    'stochastic_no_ws',\n",
    "    'stochastic_incl_ws',\n",
    "    'word_score_no_ws',\n",
    "    'word_score_incl_ws',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "602a9ff8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T17:45:57.146612Z",
     "iopub.status.busy": "2022-03-31T17:45:57.142921Z",
     "iopub.status.idle": "2022-04-01T06:14:51.176862Z",
     "shell.execute_reply": "2022-04-01T06:14:51.177399Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model baseline on bert on clean for task sst_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:02<00:00,  6.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9482    0.8881    0.9171       268\n",
      "         1.0     0.8795    0.9440    0.9106       232\n",
      "\n",
      "    accuracy                         0.9140       500\n",
      "   macro avg     0.9139    0.9160    0.9139       500\n",
      "weighted avg     0.9163    0.9140    0.9141       500\n",
      "\n",
      "Evaluation took 2.590557336807251 seconds\n",
      "Evaluating model baseline on bert on stochastic_no_ws for task sst_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:24<00:00,  2.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.7210    0.7425    0.7316       268\n",
      "         1.0     0.6920    0.6681    0.6798       232\n",
      "\n",
      "    accuracy                         0.7080       500\n",
      "   macro avg     0.7065    0.7053    0.7057       500\n",
      "weighted avg     0.7075    0.7080    0.7076       500\n",
      "\n",
      "Evaluation took 24.96378231048584 seconds\n",
      "Evaluating model baseline on bert on stochastic_incl_ws for task sst_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:25<00:00,  2.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.7107    0.7425    0.7263       268\n",
      "         1.0     0.6864    0.6509    0.6681       232\n",
      "\n",
      "    accuracy                         0.7000       500\n",
      "   macro avg     0.6985    0.6967    0.6972       500\n",
      "weighted avg     0.6994    0.7000    0.6993       500\n",
      "\n",
      "Evaluation took 25.06691837310791 seconds\n",
      "Evaluating model baseline on bert on word_score_no_ws for task sst_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:54<00:00,  9.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.4618    0.4739    0.4678       268\n",
      "         1.0     0.3733    0.3621    0.3676       232\n",
      "\n",
      "    accuracy                         0.4220       500\n",
      "   macro avg     0.4176    0.4180    0.4177       500\n",
      "weighted avg     0.4208    0.4220    0.4213       500\n",
      "\n",
      "Evaluation took 54.94610905647278 seconds\n",
      "Evaluating model baseline on bert on word_score_incl_ws for task sst_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:53<00:00,  9.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.4336    0.4627    0.4477       268\n",
      "         1.0     0.3271    0.3017    0.3139       232\n",
      "\n",
      "    accuracy                         0.3880       500\n",
      "   macro avg     0.3803    0.3822    0.3808       500\n",
      "weighted avg     0.3842    0.3880    0.3856       500\n",
      "\n",
      "Evaluation took 53.2917218208313 seconds\n",
      "Failed loading model baseline_all_pert on bert for task sst_bin, skipping\n",
      "Evaluating model roben_1 on bert on clean for task sst_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:02<00:00,  6.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8438    0.7052    0.7683       268\n",
      "         1.0     0.7138    0.8491    0.7756       232\n",
      "\n",
      "    accuracy                         0.7720       500\n",
      "   macro avg     0.7788    0.7772    0.7719       500\n",
      "weighted avg     0.7834    0.7720    0.7717       500\n",
      "\n",
      "Evaluation took 2.62431001663208 seconds\n",
      "Evaluating model roben_1 on bert on stochastic_no_ws for task sst_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:25<00:00,  2.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.6955    0.6306    0.6614       268\n",
      "         1.0     0.6148    0.6810    0.6462       232\n",
      "\n",
      "    accuracy                         0.6540       500\n",
      "   macro avg     0.6551    0.6558    0.6538       500\n",
      "weighted avg     0.6580    0.6540    0.6544       500\n",
      "\n",
      "Evaluation took 25.36691403388977 seconds\n",
      "Evaluating model roben_1 on bert on stochastic_incl_ws for task sst_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:25<00:00,  2.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.5613    0.5299    0.5451       268\n",
      "         1.0     0.4899    0.5216    0.5052       232\n",
      "\n",
      "    accuracy                         0.5260       500\n",
      "   macro avg     0.5256    0.5257    0.5252       500\n",
      "weighted avg     0.5281    0.5260    0.5266       500\n",
      "\n",
      "Evaluation took 25.36521863937378 seconds\n",
      "Evaluating model roben_1 on bert on word_score_no_ws for task sst_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:56<00:00,  8.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.5630    0.5672    0.5651       268\n",
      "         1.0     0.4957    0.4914    0.4935       232\n",
      "\n",
      "    accuracy                         0.5320       500\n",
      "   macro avg     0.5293    0.5293    0.5293       500\n",
      "weighted avg     0.5317    0.5320    0.5319       500\n",
      "\n",
      "Evaluation took 56.3480019569397 seconds\n",
      "Evaluating model roben_1 on bert on word_score_incl_ws for task sst_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:44<00:00, 11.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.3464    0.3619    0.3540       268\n",
      "         1.0     0.2227    0.2112    0.2168       232\n",
      "\n",
      "    accuracy                         0.2920       500\n",
      "   macro avg     0.2846    0.2866    0.2854       500\n",
      "weighted avg     0.2890    0.2920    0.2904       500\n",
      "\n",
      "Evaluation took 44.69224834442139 seconds\n",
      "Evaluating model roben_2 on bert on clean for task sst_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:02<00:00,  6.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8750    0.7313    0.7967       268\n",
      "         1.0     0.7391    0.8793    0.8031       232\n",
      "\n",
      "    accuracy                         0.8000       500\n",
      "   macro avg     0.8071    0.8053    0.7999       500\n",
      "weighted avg     0.8120    0.8000    0.7997       500\n",
      "\n",
      "Evaluation took 2.615090847015381 seconds\n",
      "Evaluating model roben_2 on bert on stochastic_no_ws for task sst_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:25<00:00,  2.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.7479    0.6754    0.7098       268\n",
      "         1.0     0.6628    0.7371    0.6980       232\n",
      "\n",
      "    accuracy                         0.7040       500\n",
      "   macro avg     0.7054    0.7062    0.7039       500\n",
      "weighted avg     0.7084    0.7040    0.7043       500\n",
      "\n",
      "Evaluation took 25.281092882156372 seconds\n",
      "Evaluating model roben_2 on bert on stochastic_incl_ws for task sst_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:25<00:00,  2.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.6148    0.5896    0.6019       268\n",
      "         1.0     0.5473    0.5733    0.5600       232\n",
      "\n",
      "    accuracy                         0.5820       500\n",
      "   macro avg     0.5811    0.5814    0.5810       500\n",
      "weighted avg     0.5835    0.5820    0.5825       500\n",
      "\n",
      "Evaluation took 25.275885581970215 seconds\n",
      "Evaluating model roben_2 on bert on word_score_no_ws for task sst_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:59<00:00,  8.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.6160    0.6045    0.6102       268\n",
      "         1.0     0.5527    0.5647    0.5586       232\n",
      "\n",
      "    accuracy                         0.5860       500\n",
      "   macro avg     0.5844    0.5846    0.5844       500\n",
      "weighted avg     0.5866    0.5860    0.5863       500\n",
      "\n",
      "Evaluation took 59.88006615638733 seconds\n",
      "Evaluating model roben_2 on bert on word_score_incl_ws for task sst_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:47<00:00, 10.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.3633    0.3619    0.3626       268\n",
      "         1.0     0.2661    0.2672    0.2667       232\n",
      "\n",
      "    accuracy                         0.3180       500\n",
      "   macro avg     0.3147    0.3146    0.3146       500\n",
      "weighted avg     0.3182    0.3180    0.3181       500\n",
      "\n",
      "Evaluation took 47.68703055381775 seconds\n",
      "Evaluating model roben_1_tok on bert on clean for task sst_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:02<00:00,  6.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.7511    0.6418    0.6922       268\n",
      "         1.0     0.6458    0.7543    0.6958       232\n",
      "\n",
      "    accuracy                         0.6940       500\n",
      "   macro avg     0.6984    0.6981    0.6940       500\n",
      "weighted avg     0.7022    0.6940    0.6939       500\n",
      "\n",
      "Evaluation took 2.6620352268218994 seconds\n",
      "Evaluating model roben_1_tok on bert on stochastic_no_ws for task sst_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:25<00:00,  2.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.7237    0.6157    0.6653       268\n",
      "         1.0     0.6213    0.7284    0.6706       232\n",
      "\n",
      "    accuracy                         0.6680       500\n",
      "   macro avg     0.6725    0.6721    0.6680       500\n",
      "weighted avg     0.6762    0.6680    0.6678       500\n",
      "\n",
      "Evaluation took 25.934560537338257 seconds\n",
      "Evaluating model roben_1_tok on bert on stochastic_incl_ws for task sst_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:26<00:00,  2.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.5336    0.5037    0.5182       268\n",
      "         1.0     0.4615    0.4914    0.4760       232\n",
      "\n",
      "    accuracy                         0.4980       500\n",
      "   macro avg     0.4976    0.4976    0.4971       500\n",
      "weighted avg     0.5002    0.4980    0.4986       500\n",
      "\n",
      "Evaluation took 26.063369035720825 seconds\n",
      "Evaluating model roben_1_tok on bert on word_score_no_ws for task sst_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:59<00:00,  8.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.6904    0.6157    0.6509       268\n",
      "         1.0     0.6054    0.6810    0.6410       232\n",
      "\n",
      "    accuracy                         0.6460       500\n",
      "   macro avg     0.6479    0.6484    0.6459       500\n",
      "weighted avg     0.6509    0.6460    0.6463       500\n",
      "\n",
      "Evaluation took 59.04615139961243 seconds\n",
      "Evaluating model roben_1_tok on bert on word_score_incl_ws for task sst_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:41<00:00, 11.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.3221    0.3209    0.3215       268\n",
      "         1.0     0.2189    0.2198    0.2194       232\n",
      "\n",
      "    accuracy                         0.2740       500\n",
      "   macro avg     0.2705    0.2704    0.2704       500\n",
      "weighted avg     0.2742    0.2740    0.2741       500\n",
      "\n",
      "Evaluation took 41.82783341407776 seconds\n",
      "Evaluating model roben_2_tok on bert on clean for task sst_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:02<00:00,  5.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8387    0.6791    0.7505       268\n",
      "         1.0     0.6961    0.8491    0.7650       232\n",
      "\n",
      "    accuracy                         0.7580       500\n",
      "   macro avg     0.7674    0.7641    0.7578       500\n",
      "weighted avg     0.7725    0.7580    0.7573       500\n",
      "\n",
      "Evaluation took 2.7374465465545654 seconds\n",
      "Evaluating model roben_2_tok on bert on stochastic_no_ws for task sst_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:25<00:00,  2.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8318    0.6642    0.7386       268\n",
      "         1.0     0.6853    0.8448    0.7568       232\n",
      "\n",
      "    accuracy                         0.7480       500\n",
      "   macro avg     0.7585    0.7545    0.7477       500\n",
      "weighted avg     0.7638    0.7480    0.7470       500\n",
      "\n",
      "Evaluation took 25.92541480064392 seconds\n",
      "Evaluating model roben_2_tok on bert on stochastic_incl_ws for task sst_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:25<00:00,  2.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.6082    0.5560    0.5809       268\n",
      "         1.0     0.5333    0.5862    0.5585       232\n",
      "\n",
      "    accuracy                         0.5700       500\n",
      "   macro avg     0.5707    0.5711    0.5697       500\n",
      "weighted avg     0.5734    0.5700    0.5705       500\n",
      "\n",
      "Evaluation took 25.92218041419983 seconds\n",
      "Evaluating model roben_2_tok on bert on word_score_no_ws for task sst_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [01:05<00:00,  7.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.7964    0.6567    0.7198       268\n",
      "         1.0     0.6703    0.8060    0.7319       232\n",
      "\n",
      "    accuracy                         0.7260       500\n",
      "   macro avg     0.7333    0.7314    0.7259       500\n",
      "weighted avg     0.7379    0.7260    0.7254       500\n",
      "\n",
      "Evaluation took 65.13420104980469 seconds\n",
      "Evaluating model roben_2_tok on bert on word_score_incl_ws for task sst_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:47<00:00, 10.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.3735    0.3470    0.3598       268\n",
      "         1.0     0.3028    0.3276    0.3147       232\n",
      "\n",
      "    accuracy                         0.3380       500\n",
      "   macro avg     0.3381    0.3373    0.3372       500\n",
      "weighted avg     0.3407    0.3380    0.3389       500\n",
      "\n",
      "Evaluation took 47.52352476119995 seconds\n",
      "Evaluating model 64k_lstm_clean_vanilla on bert on clean for task sst_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:05<00:00,  2.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9240    0.8619    0.8919       268\n",
      "         1.0     0.8520    0.9181    0.8838       232\n",
      "\n",
      "    accuracy                         0.8880       500\n",
      "   macro avg     0.8880    0.8900    0.8879       500\n",
      "weighted avg     0.8906    0.8880    0.8881       500\n",
      "\n",
      "Evaluation took 5.54081392288208 seconds\n",
      "Evaluating model 64k_lstm_clean_vanilla on bert on stochastic_no_ws for task sst_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:54<00:00,  5.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.7490    0.7239    0.7362       268\n",
      "         1.0     0.6929    0.7198    0.7061       232\n",
      "\n",
      "    accuracy                         0.7220       500\n",
      "   macro avg     0.7210    0.7219    0.7212       500\n",
      "weighted avg     0.7230    0.7220    0.7223       500\n",
      "\n",
      "Evaluation took 54.971192598342896 seconds\n",
      "Evaluating model 64k_lstm_clean_vanilla on bert on stochastic_incl_ws for task sst_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:55<00:00,  5.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.7082    0.6791    0.6933       268\n",
      "         1.0     0.6461    0.6767    0.6611       232\n",
      "\n",
      "    accuracy                         0.6780       500\n",
      "   macro avg     0.6771    0.6779    0.6772       500\n",
      "weighted avg     0.6794    0.6780    0.6784       500\n",
      "\n",
      "Evaluation took 55.439828395843506 seconds\n",
      "Evaluating model 64k_lstm_clean_vanilla on bert on word_score_no_ws for task sst_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [02:41<00:00,  3.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.4431    0.4067    0.4241       268\n",
      "         1.0     0.3740    0.4095    0.3909       232\n",
      "\n",
      "    accuracy                         0.4080       500\n",
      "   macro avg     0.4086    0.4081    0.4075       500\n",
      "weighted avg     0.4110    0.4080    0.4087       500\n",
      "\n",
      "Evaluation took 161.7474226951599 seconds\n",
      "Evaluating model 64k_lstm_clean_vanilla on bert on word_score_incl_ws for task sst_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [02:25<00:00,  3.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.3611    0.3396    0.3500       268\n",
      "         1.0     0.2863    0.3060    0.2958       232\n",
      "\n",
      "    accuracy                         0.3240       500\n",
      "   macro avg     0.3237    0.3228    0.3229       500\n",
      "weighted avg     0.3264    0.3240    0.3249       500\n",
      "\n",
      "Evaluation took 145.51855397224426 seconds\n",
      "Evaluating model 64k_lstm_no_whitespace_pert_vanilla on bert on clean for task sst_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:05<00:00,  2.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9016    0.8209    0.8594       268\n",
      "         1.0     0.8125    0.8966    0.8525       232\n",
      "\n",
      "    accuracy                         0.8560       500\n",
      "   macro avg     0.8571    0.8587    0.8559       500\n",
      "weighted avg     0.8603    0.8560    0.8562       500\n",
      "\n",
      "Evaluation took 5.66375994682312 seconds\n",
      "Evaluating model 64k_lstm_no_whitespace_pert_vanilla on bert on stochastic_no_ws for task sst_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:55<00:00,  5.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8638    0.7575    0.8072       268\n",
      "         1.0     0.7547    0.8621    0.8048       232\n",
      "\n",
      "    accuracy                         0.8060       500\n",
      "   macro avg     0.8093    0.8098    0.8060       500\n",
      "weighted avg     0.8132    0.8060    0.8061       500\n",
      "\n",
      "Evaluation took 55.00786900520325 seconds\n",
      "Evaluating model 64k_lstm_no_whitespace_pert_vanilla on bert on stochastic_incl_ws for task sst_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:54<00:00,  5.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.7511    0.6530    0.6986       268\n",
      "         1.0     0.6517    0.7500    0.6974       232\n",
      "\n",
      "    accuracy                         0.6980       500\n",
      "   macro avg     0.7014    0.7015    0.6980       500\n",
      "weighted avg     0.7050    0.6980    0.6980       500\n",
      "\n",
      "Evaluation took 54.50622606277466 seconds\n",
      "Evaluating model 64k_lstm_no_whitespace_pert_vanilla on bert on word_score_no_ws for task sst_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [03:00<00:00,  2.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.6444    0.5410    0.5882       268\n",
      "         1.0     0.5527    0.6552    0.5996       232\n",
      "\n",
      "    accuracy                         0.5940       500\n",
      "   macro avg     0.5986    0.5981    0.5939       500\n",
      "weighted avg     0.6019    0.5940    0.5935       500\n",
      "\n",
      "Evaluation took 180.78644013404846 seconds\n",
      "Evaluating model 64k_lstm_no_whitespace_pert_vanilla on bert on word_score_incl_ws for task sst_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [02:35<00:00,  3.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.4397    0.3806    0.4080       268\n",
      "         1.0     0.3806    0.4397    0.4080       232\n",
      "\n",
      "    accuracy                         0.4080       500\n",
      "   macro avg     0.4101    0.4101    0.4080       500\n",
      "weighted avg     0.4123    0.4080    0.4080       500\n",
      "\n",
      "Evaluation took 155.5572328567505 seconds\n",
      "Evaluating model 64k_lstm_all_pert_vanilla on bert on clean for task sst_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:05<00:00,  2.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9163    0.8172    0.8639       268\n",
      "         1.0     0.8123    0.9138    0.8600       232\n",
      "\n",
      "    accuracy                         0.8620       500\n",
      "   macro avg     0.8643    0.8655    0.8620       500\n",
      "weighted avg     0.8680    0.8620    0.8621       500\n",
      "\n",
      "Evaluation took 5.527689218521118 seconds\n",
      "Evaluating model 64k_lstm_all_pert_vanilla on bert on stochastic_no_ws for task sst_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:53<00:00,  5.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8498    0.7388    0.7904       268\n",
      "         1.0     0.7378    0.8491    0.7896       232\n",
      "\n",
      "    accuracy                         0.7900       500\n",
      "   macro avg     0.7938    0.7940    0.7900       500\n",
      "weighted avg     0.7978    0.7900    0.7900       500\n",
      "\n",
      "Evaluation took 53.93970799446106 seconds\n",
      "Evaluating model 64k_lstm_all_pert_vanilla on bert on stochastic_incl_ws for task sst_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:54<00:00,  5.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8393    0.7015    0.7642       268\n",
      "         1.0     0.7101    0.8448    0.7717       232\n",
      "\n",
      "    accuracy                         0.7680       500\n",
      "   macro avg     0.7747    0.7732    0.7679       500\n",
      "weighted avg     0.7794    0.7680    0.7677       500\n",
      "\n",
      "Evaluation took 54.21471428871155 seconds\n",
      "Evaluating model 64k_lstm_all_pert_vanilla on bert on word_score_no_ws for task sst_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [02:53<00:00,  2.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.6147    0.5299    0.5691       268\n",
      "         1.0     0.5316    0.6164    0.5709       232\n",
      "\n",
      "    accuracy                         0.5700       500\n",
      "   macro avg     0.5732    0.5731    0.5700       500\n",
      "weighted avg     0.5762    0.5700    0.5699       500\n",
      "\n",
      "Evaluation took 173.6905767917633 seconds\n",
      "Evaluating model 64k_lstm_all_pert_vanilla on bert on word_score_incl_ws for task sst_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [02:55<00:00,  2.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.6215    0.4963    0.5519       268\n",
      "         1.0     0.5280    0.6509    0.5830       232\n",
      "\n",
      "    accuracy                         0.5680       500\n",
      "   macro avg     0.5747    0.5736    0.5674       500\n",
      "weighted avg     0.5781    0.5680    0.5663       500\n",
      "\n",
      "Evaluation took 175.5556674003601 seconds\n",
      "Failed loading model 64k_lstm_clean_finetuned on bert for task sst_bin, skipping\n",
      "Failed loading model 64k_lstm_no_whitespace_pert_finetuned on bert for task sst_bin, skipping\n",
      "Evaluating model 64k_lstm_all_pert_finetuned on bert on clean for task sst_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:05<00:00,  2.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9244    0.8209    0.8696       268\n",
      "         1.0     0.8168    0.9224    0.8664       232\n",
      "\n",
      "    accuracy                         0.8680       500\n",
      "   macro avg     0.8706    0.8717    0.8680       500\n",
      "weighted avg     0.8745    0.8680    0.8681       500\n",
      "\n",
      "Evaluation took 5.5547194480896 seconds\n",
      "Evaluating model 64k_lstm_all_pert_finetuned on bert on stochastic_no_ws for task sst_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:54<00:00,  5.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8700    0.7239    0.7902       268\n",
      "         1.0     0.7329    0.8750    0.7976       232\n",
      "\n",
      "    accuracy                         0.7940       500\n",
      "   macro avg     0.8014    0.7994    0.7939       500\n",
      "weighted avg     0.8063    0.7940    0.7937       500\n",
      "\n",
      "Evaluation took 54.890515089035034 seconds\n",
      "Evaluating model 64k_lstm_all_pert_finetuned on bert on stochastic_incl_ws for task sst_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:54<00:00,  5.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8333    0.6903    0.7551       268\n",
      "         1.0     0.7014    0.8405    0.7647       232\n",
      "\n",
      "    accuracy                         0.7600       500\n",
      "   macro avg     0.7674    0.7654    0.7599       500\n",
      "weighted avg     0.7721    0.7600    0.7596       500\n",
      "\n",
      "Evaluation took 54.60873103141785 seconds\n",
      "Evaluating model 64k_lstm_all_pert_finetuned on bert on word_score_no_ws for task sst_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [02:55<00:00,  2.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.6303    0.4963    0.5553       268\n",
      "         1.0     0.5329    0.6638    0.5912       232\n",
      "\n",
      "    accuracy                         0.5740       500\n",
      "   macro avg     0.5816    0.5800    0.5732       500\n",
      "weighted avg     0.5851    0.5740    0.5720       500\n",
      "\n",
      "Evaluation took 175.73686933517456 seconds\n",
      "Evaluating model 64k_lstm_all_pert_finetuned on bert on word_score_incl_ws for task sst_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [02:55<00:00,  2.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.6182    0.5075    0.5574       268\n",
      "         1.0     0.5286    0.6379    0.5781       232\n",
      "\n",
      "    accuracy                         0.5680       500\n",
      "   macro avg     0.5734    0.5727    0.5678       500\n",
      "weighted avg     0.5766    0.5680    0.5670       500\n",
      "\n",
      "Evaluation took 175.80747747421265 seconds\n",
      "Failed loading model 64k_cnn_no_whitespace_pert_finetuned on bert for task sst_bin, skipping\n",
      "Failed loading model 2m_lstm_all_pert_finetuned on bert for task sst_bin, skipping\n",
      "Failed loading model 32k_lstm_all_pert_finetuned_100ep on bert for task sst_bin, skipping\n",
      "Evaluating model baseline on roberta on clean for task sst_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:02<00:00,  6.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9570    0.9142    0.9351       268\n",
      "         1.0     0.9057    0.9526    0.9286       232\n",
      "\n",
      "    accuracy                         0.9320       500\n",
      "   macro avg     0.9314    0.9334    0.9318       500\n",
      "weighted avg     0.9332    0.9320    0.9321       500\n",
      "\n",
      "Evaluation took 2.5529420375823975 seconds\n",
      "Evaluating model baseline on roberta on stochastic_no_ws for task sst_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:25<00:00,  2.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.7586    0.8209    0.7885       268\n",
      "         1.0     0.7714    0.6983    0.7330       232\n",
      "\n",
      "    accuracy                         0.7640       500\n",
      "   macro avg     0.7650    0.7596    0.7608       500\n",
      "weighted avg     0.7646    0.7640    0.7628       500\n",
      "\n",
      "Evaluation took 25.019185543060303 seconds\n",
      "Evaluating model baseline on roberta on stochastic_incl_ws for task sst_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:25<00:00,  2.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.7759    0.8396    0.8065       268\n",
      "         1.0     0.7952    0.7198    0.7557       232\n",
      "\n",
      "    accuracy                         0.7840       500\n",
      "   macro avg     0.7856    0.7797    0.7811       500\n",
      "weighted avg     0.7849    0.7840    0.7829       500\n",
      "\n",
      "Evaluation took 25.069686889648438 seconds\n",
      "Evaluating model baseline on roberta on word_score_no_ws for task sst_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:59<00:00,  8.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.5166    0.6381    0.5710       268\n",
      "         1.0     0.4260    0.3103    0.3591       232\n",
      "\n",
      "    accuracy                         0.4860       500\n",
      "   macro avg     0.4713    0.4742    0.4650       500\n",
      "weighted avg     0.4746    0.4860    0.4727       500\n",
      "\n",
      "Evaluation took 59.93393397331238 seconds\n",
      "Evaluating model baseline on roberta on word_score_incl_ws for task sst_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:58<00:00,  8.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.5031    0.5970    0.5461       268\n",
      "         1.0     0.4066    0.3190    0.3575       232\n",
      "\n",
      "    accuracy                         0.4680       500\n",
      "   macro avg     0.4549    0.4580    0.4518       500\n",
      "weighted avg     0.4583    0.4680    0.4586       500\n",
      "\n",
      "Evaluation took 58.22168469429016 seconds\n",
      "Failed loading model baseline_all_pert on roberta for task sst_bin, skipping\n",
      "Evaluating model roben_1 on roberta on clean for task sst_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:02<00:00,  6.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.7911    0.8619    0.8250       268\n",
      "         1.0     0.8221    0.7371    0.7773       232\n",
      "\n",
      "    accuracy                         0.8040       500\n",
      "   macro avg     0.8066    0.7995    0.8011       500\n",
      "weighted avg     0.8055    0.8040    0.8029       500\n",
      "\n",
      "Evaluation took 2.657008647918701 seconds\n",
      "Evaluating model roben_1 on roberta on stochastic_no_ws for task sst_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:25<00:00,  2.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.6657    0.8172    0.7337       268\n",
      "         1.0     0.7135    0.5259    0.6055       232\n",
      "\n",
      "    accuracy                         0.6820       500\n",
      "   macro avg     0.6896    0.6715    0.6696       500\n",
      "weighted avg     0.6878    0.6820    0.6742       500\n",
      "\n",
      "Evaluation took 25.33419442176819 seconds\n",
      "Evaluating model roben_1 on roberta on stochastic_incl_ws for task sst_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:25<00:00,  2.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.6242    0.7687    0.6890       268\n",
      "         1.0     0.6353    0.4655    0.5373       232\n",
      "\n",
      "    accuracy                         0.6280       500\n",
      "   macro avg     0.6298    0.6171    0.6131       500\n",
      "weighted avg     0.6294    0.6280    0.6186       500\n",
      "\n",
      "Evaluation took 25.472959756851196 seconds\n",
      "Evaluating model roben_1 on roberta on word_score_no_ws for task sst_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:59<00:00,  8.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.5944    0.7985    0.6815       268\n",
      "         1.0     0.6143    0.3707    0.4624       232\n",
      "\n",
      "    accuracy                         0.6000       500\n",
      "   macro avg     0.6044    0.5846    0.5719       500\n",
      "weighted avg     0.6037    0.6000    0.5798       500\n",
      "\n",
      "Evaluation took 59.877885818481445 seconds\n",
      "Evaluating model roben_1 on roberta on word_score_incl_ws for task sst_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:49<00:00, 10.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.4207    0.5149    0.4631       268\n",
      "         1.0     0.2442    0.1810    0.2079       232\n",
      "\n",
      "    accuracy                         0.3600       500\n",
      "   macro avg     0.3325    0.3480    0.3355       500\n",
      "weighted avg     0.3388    0.3600    0.3447       500\n",
      "\n",
      "Evaluation took 49.997939109802246 seconds\n",
      "Evaluating model roben_2 on roberta on clean for task sst_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:02<00:00,  6.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8436    0.8657    0.8545       268\n",
      "         1.0     0.8400    0.8147    0.8271       232\n",
      "\n",
      "    accuracy                         0.8420       500\n",
      "   macro avg     0.8418    0.8402    0.8408       500\n",
      "weighted avg     0.8419    0.8420    0.8418       500\n",
      "\n",
      "Evaluation took 2.571233034133911 seconds\n",
      "Evaluating model roben_2 on roberta on stochastic_no_ws for task sst_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:25<00:00,  2.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.7311    0.8321    0.7784       268\n",
      "         1.0     0.7692    0.6466    0.7026       232\n",
      "\n",
      "    accuracy                         0.7460       500\n",
      "   macro avg     0.7502    0.7393    0.7405       500\n",
      "weighted avg     0.7488    0.7460    0.7432       500\n",
      "\n",
      "Evaluation took 25.9934401512146 seconds\n",
      "Evaluating model roben_2 on roberta on stochastic_incl_ws for task sst_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:25<00:00,  2.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.6720    0.7873    0.7251       268\n",
      "         1.0     0.6935    0.5560    0.6172       232\n",
      "\n",
      "    accuracy                         0.6800       500\n",
      "   macro avg     0.6828    0.6717    0.6712       500\n",
      "weighted avg     0.6820    0.6800    0.6750       500\n",
      "\n",
      "Evaluation took 25.32649564743042 seconds\n",
      "Evaluating model roben_2 on roberta on word_score_no_ws for task sst_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [01:07<00:00,  7.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.6366    0.7910    0.7055       268\n",
      "         1.0     0.6647    0.4784    0.5564       232\n",
      "\n",
      "    accuracy                         0.6460       500\n",
      "   macro avg     0.6507    0.6347    0.6309       500\n",
      "weighted avg     0.6496    0.6460    0.6363       500\n",
      "\n",
      "Evaluation took 67.95787072181702 seconds\n",
      "Evaluating model roben_2 on roberta on word_score_incl_ws for task sst_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:56<00:00,  8.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.4537    0.5672    0.5041       268\n",
      "         1.0     0.2970    0.2112    0.2469       232\n",
      "\n",
      "    accuracy                         0.4020       500\n",
      "   macro avg     0.3754    0.3892    0.3755       500\n",
      "weighted avg     0.3810    0.4020    0.3848       500\n",
      "\n",
      "Evaluation took 56.046173334121704 seconds\n",
      "Evaluating model roben_1_tok on roberta on clean for task sst_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:02<00:00,  5.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.7284    0.8507    0.7849       268\n",
      "         1.0     0.7861    0.6336    0.7017       232\n",
      "\n",
      "    accuracy                         0.7500       500\n",
      "   macro avg     0.7573    0.7422    0.7433       500\n",
      "weighted avg     0.7552    0.7500    0.7463       500\n",
      "\n",
      "Evaluation took 2.807769298553467 seconds\n",
      "Evaluating model roben_1_tok on roberta on stochastic_no_ws for task sst_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:27<00:00,  2.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.7066    0.8358    0.7658       268\n",
      "         1.0     0.7596    0.5991    0.6699       232\n",
      "\n",
      "    accuracy                         0.7260       500\n",
      "   macro avg     0.7331    0.7175    0.7178       500\n",
      "weighted avg     0.7312    0.7260    0.7213       500\n",
      "\n",
      "Evaluation took 27.356130123138428 seconds\n",
      "Evaluating model roben_1_tok on roberta on stochastic_incl_ws for task sst_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:26<00:00,  2.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.5924    0.7537    0.6634       268\n",
      "         1.0     0.5849    0.4009    0.4757       232\n",
      "\n",
      "    accuracy                         0.5900       500\n",
      "   macro avg     0.5886    0.5773    0.5695       500\n",
      "weighted avg     0.5889    0.5900    0.5763       500\n",
      "\n",
      "Evaluation took 26.046791315078735 seconds\n",
      "Evaluating model roben_1_tok on roberta on word_score_no_ws for task sst_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [01:04<00:00,  7.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.6799    0.8321    0.7483       268\n",
      "         1.0     0.7384    0.5474    0.6287       232\n",
      "\n",
      "    accuracy                         0.7000       500\n",
      "   macro avg     0.7091    0.6898    0.6885       500\n",
      "weighted avg     0.7070    0.7000    0.6928       500\n",
      "\n",
      "Evaluation took 64.26963114738464 seconds\n",
      "Evaluating model roben_1_tok on roberta on word_score_incl_ws for task sst_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:47<00:00, 10.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.4317    0.5187    0.4712       268\n",
      "         1.0     0.2753    0.2112    0.2390       232\n",
      "\n",
      "    accuracy                         0.3760       500\n",
      "   macro avg     0.3535    0.3649    0.3551       500\n",
      "weighted avg     0.3591    0.3760    0.3635       500\n",
      "\n",
      "Evaluation took 47.49795055389404 seconds\n",
      "Evaluating model roben_2_tok on roberta on clean for task sst_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:02<00:00,  6.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.7677    0.8507    0.8071       268\n",
      "         1.0     0.8030    0.7026    0.7494       232\n",
      "\n",
      "    accuracy                         0.7820       500\n",
      "   macro avg     0.7853    0.7767    0.7783       500\n",
      "weighted avg     0.7840    0.7820    0.7803       500\n",
      "\n",
      "Evaluation took 2.625157356262207 seconds\n",
      "Evaluating model roben_2_tok on roberta on stochastic_no_ws for task sst_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:26<00:00,  2.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.7559    0.8321    0.7922       268\n",
      "         1.0     0.7805    0.6897    0.7323       232\n",
      "\n",
      "    accuracy                         0.7660       500\n",
      "   macro avg     0.7682    0.7609    0.7622       500\n",
      "weighted avg     0.7673    0.7660    0.7644       500\n",
      "\n",
      "Evaluation took 26.02118754386902 seconds\n",
      "Evaluating model roben_2_tok on roberta on stochastic_incl_ws for task sst_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:25<00:00,  2.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.6469    0.7724    0.7041       268\n",
      "         1.0     0.6611    0.5129    0.5777       232\n",
      "\n",
      "    accuracy                         0.6520       500\n",
      "   macro avg     0.6540    0.6427    0.6409       500\n",
      "weighted avg     0.6535    0.6520    0.6454       500\n",
      "\n",
      "Evaluation took 25.857235431671143 seconds\n",
      "Evaluating model roben_2_tok on roberta on word_score_no_ws for task sst_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [01:06<00:00,  7.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.7336    0.8321    0.7797       268\n",
      "         1.0     0.7704    0.6509    0.7056       232\n",
      "\n",
      "    accuracy                         0.7480       500\n",
      "   macro avg     0.7520    0.7415    0.7427       500\n",
      "weighted avg     0.7507    0.7480    0.7453       500\n",
      "\n",
      "Evaluation took 66.83108067512512 seconds\n",
      "Evaluating model roben_2_tok on roberta on word_score_incl_ws for task sst_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:50<00:00,  9.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.4537    0.5299    0.4888       268\n",
      "         1.0     0.3262    0.2629    0.2912       232\n",
      "\n",
      "    accuracy                         0.4060       500\n",
      "   macro avg     0.3899    0.3964    0.3900       500\n",
      "weighted avg     0.3945    0.4060    0.3971       500\n",
      "\n",
      "Evaluation took 50.31882643699646 seconds\n",
      "Failed loading model 64k_lstm_clean_vanilla on roberta for task sst_bin, skipping\n",
      "Failed loading model 64k_lstm_no_whitespace_pert_vanilla on roberta for task sst_bin, skipping\n",
      "Evaluating model 64k_lstm_all_pert_vanilla on roberta on clean for task sst_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:05<00:00,  2.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8985    0.8918    0.8951       268\n",
      "         1.0     0.8761    0.8836    0.8798       232\n",
      "\n",
      "    accuracy                         0.8880       500\n",
      "   macro avg     0.8873    0.8877    0.8875       500\n",
      "weighted avg     0.8881    0.8880    0.8880       500\n",
      "\n",
      "Evaluation took 5.7604992389678955 seconds\n",
      "Evaluating model 64k_lstm_all_pert_vanilla on roberta on stochastic_no_ws for task sst_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:57<00:00,  5.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8145    0.8358    0.8250       268\n",
      "         1.0     0.8044    0.7802    0.7921       232\n",
      "\n",
      "    accuracy                         0.8100       500\n",
      "   macro avg     0.8095    0.8080    0.8086       500\n",
      "weighted avg     0.8099    0.8100    0.8098       500\n",
      "\n",
      "Evaluation took 57.395200967788696 seconds\n",
      "Evaluating model 64k_lstm_all_pert_vanilla on roberta on stochastic_incl_ws for task sst_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:58<00:00,  5.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8229    0.8321    0.8275       268\n",
      "         1.0     0.8035    0.7931    0.7983       232\n",
      "\n",
      "    accuracy                         0.8140       500\n",
      "   macro avg     0.8132    0.8126    0.8129       500\n",
      "weighted avg     0.8139    0.8140    0.8139       500\n",
      "\n",
      "Evaluation took 58.717193603515625 seconds\n",
      "Evaluating model 64k_lstm_all_pert_vanilla on roberta on word_score_no_ws for task sst_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [03:04<00:00,  2.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.6364    0.6791    0.6570       268\n",
      "         1.0     0.5981    0.5517    0.5740       232\n",
      "\n",
      "    accuracy                         0.6200       500\n",
      "   macro avg     0.6172    0.6154    0.6155       500\n",
      "weighted avg     0.6186    0.6200    0.6185       500\n",
      "\n",
      "Evaluation took 184.77083325386047 seconds\n",
      "Evaluating model 64k_lstm_all_pert_vanilla on roberta on word_score_incl_ws for task sst_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [03:12<00:00,  2.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.6348    0.6940    0.6631       268\n",
      "         1.0     0.6039    0.5388    0.5695       232\n",
      "\n",
      "    accuracy                         0.6220       500\n",
      "   macro avg     0.6193    0.6164    0.6163       500\n",
      "weighted avg     0.6205    0.6220    0.6197       500\n",
      "\n",
      "Evaluation took 192.936678647995 seconds\n",
      "Failed loading model 64k_lstm_clean_finetuned on roberta for task sst_bin, skipping\n",
      "Failed loading model 64k_lstm_no_whitespace_pert_finetuned on roberta for task sst_bin, skipping\n",
      "Evaluating model 64k_lstm_all_pert_finetuned on roberta on clean for task sst_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:06<00:00,  2.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9325    0.8769    0.9038       268\n",
      "         1.0     0.8669    0.9267    0.8958       232\n",
      "\n",
      "    accuracy                         0.9000       500\n",
      "   macro avg     0.8997    0.9018    0.8998       500\n",
      "weighted avg     0.9021    0.9000    0.9001       500\n",
      "\n",
      "Evaluation took 6.301508903503418 seconds\n",
      "Evaluating model 64k_lstm_all_pert_finetuned on roberta on stochastic_no_ws for task sst_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [01:00<00:00,  6.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8537    0.7836    0.8171       268\n",
      "         1.0     0.7717    0.8448    0.8066       232\n",
      "\n",
      "    accuracy                         0.8120       500\n",
      "   macro avg     0.8127    0.8142    0.8119       500\n",
      "weighted avg     0.8156    0.8120    0.8122       500\n",
      "\n",
      "Evaluation took 60.30332326889038 seconds\n",
      "Evaluating model 64k_lstm_all_pert_finetuned on roberta on stochastic_incl_ws for task sst_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:57<00:00,  5.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8583    0.8134    0.8352       268\n",
      "         1.0     0.7967    0.8448    0.8201       232\n",
      "\n",
      "    accuracy                         0.8280       500\n",
      "   macro avg     0.8275    0.8291    0.8277       500\n",
      "weighted avg     0.8297    0.8280    0.8282       500\n",
      "\n",
      "Evaluation took 57.47007870674133 seconds\n",
      "Evaluating model 64k_lstm_all_pert_finetuned on roberta on word_score_no_ws for task sst_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [03:24<00:00,  2.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.6367    0.6082    0.6221       268\n",
      "         1.0     0.5697    0.5991    0.5840       232\n",
      "\n",
      "    accuracy                         0.6040       500\n",
      "   macro avg     0.6032    0.6037    0.6031       500\n",
      "weighted avg     0.6056    0.6040    0.6045       500\n",
      "\n",
      "Evaluation took 204.63213920593262 seconds\n",
      "Evaluating model 64k_lstm_all_pert_finetuned on roberta on word_score_incl_ws for task sst_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [03:10<00:00,  2.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.6513    0.6343    0.6427       268\n",
      "         1.0     0.5900    0.6078    0.5987       232\n",
      "\n",
      "    accuracy                         0.6220       500\n",
      "   macro avg     0.6206    0.6210    0.6207       500\n",
      "weighted avg     0.6229    0.6220    0.6223       500\n",
      "\n",
      "Evaluation took 190.95674324035645 seconds\n",
      "Failed loading model 64k_cnn_no_whitespace_pert_finetuned on roberta for task sst_bin, skipping\n",
      "Failed loading model 2m_lstm_all_pert_finetuned on roberta for task sst_bin, skipping\n",
      "Failed loading model 32k_lstm_all_pert_finetuned_100ep on roberta for task sst_bin, skipping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_task_ids = [ f\"{model}_{type}_{task}\" for task, type, model in itertools.product(tasks, model_types, all_models.keys()) ]\n",
    "\n",
    "accuracy_df = pd.DataFrame(columns=evaluations, index=model_task_ids)\n",
    "f1_df = pd.DataFrame(columns=evaluations, index=model_task_ids)\n",
    "\n",
    "for task, type in itertools.product(tasks, model_types):\n",
    "    for cur_model_name, cur_model_factory in all_models.items():\n",
    "        try:\n",
    "            cur_model = cur_model_factory(task, type)\n",
    "        except:\n",
    "            print(f'Failed loading model {cur_model_name} on {type} for task {task}, skipping')\n",
    "            accuracy_df.drop(f\"{cur_model_name}_{type}_{task}\", inplace=True)\n",
    "            f1_df.drop(f\"{cur_model_name}_{type}_{task}\", inplace=True)\n",
    "            continue\n",
    "        for cur_evaluation in evaluations:\n",
    "            print(f'Evaluating model {cur_model_name} on {type} on {cur_evaluation} for task {task}')\n",
    "            start_time = time.time()\n",
    "            random.seed(11)\n",
    "            if cur_evaluation == 'clean':\n",
    "                acc, f1 = evaluate_model(cur_model, sampled_test_set[task])\n",
    "            elif cur_evaluation.startswith('stochastic_'):\n",
    "                if cur_evaluation == 'stochastic_no_ws':\n",
    "                    acc_list, f1_list = evaluate_model_adv(cur_model, sampled_test_set_adv_no_ws[task])\n",
    "                elif cur_evaluation == 'stochastic_incl_ws':\n",
    "                    acc_list, f1_list = evaluate_model_adv(cur_model, sampled_test_set_adv_incl_ws[task])\n",
    "                acc = acc_list[-1]\n",
    "                f1 = f1_list[-1]\n",
    "                with open(f\"../output/eval/{cur_model_name}_{type}_{task}_{cur_evaluation}_acc_list.json\", \"w\") as f:\n",
    "                    json.dump(acc_list, fp=f)\n",
    "                with open(f\"../output/eval/{cur_model_name}_{type}_{task}_{cur_evaluation}_f1_list.json\", \"w\") as f:\n",
    "                    json.dump(f1_list, fp=f)\n",
    "            elif cur_evaluation.startswith('word_score_'):\n",
    "                if cur_evaluation == 'word_score_no_ws':\n",
    "                    acc, f1 = evaluate_model_word_score(cur_model, sampled_test_set[task], allow_whitespace_pert=False,\n",
    "                                                        report_prefix=f\"../output/eval/{cur_model_name}_{type}_{task}_{cur_evaluation}\",\n",
    "                                                        word_scores_file=f\"../output/{task}_word_scores.json\")\n",
    "                elif cur_evaluation == 'word_score_incl_ws':\n",
    "                    acc, f1 = evaluate_model_word_score(cur_model, sampled_test_set[task], allow_whitespace_pert=True,\n",
    "                                                        report_prefix=f\"../output/eval/{cur_model_name}_{type}_{task}_{cur_evaluation}\",\n",
    "                                                        word_scores_file=f\"../output/{task}_word_scores.json\")\n",
    "\n",
    "            accuracy_df[cur_evaluation][f\"{cur_model_name}_{type}_{task}\"] = acc\n",
    "            f1_df[cur_evaluation][f\"{cur_model_name}_{type}_{task}\"] = f1\n",
    "            end_time = time.time()\n",
    "            print(f\"Evaluation took {end_time-start_time} seconds\")\n",
    "        del cur_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6e229c55",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-01T06:14:51.186588Z",
     "iopub.status.busy": "2022-04-01T06:14:51.184925Z",
     "iopub.status.idle": "2022-04-01T06:14:51.198999Z",
     "shell.execute_reply": "2022-04-01T06:14:51.198401Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean</th>\n",
       "      <th>stochastic_no_ws</th>\n",
       "      <th>stochastic_incl_ws</th>\n",
       "      <th>word_score_no_ws</th>\n",
       "      <th>word_score_incl_ws</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>baseline_bert_sst_bin</th>\n",
       "      <td>0.914</td>\n",
       "      <td>0.708</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.422</td>\n",
       "      <td>0.388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roben_1_bert_sst_bin</th>\n",
       "      <td>0.772</td>\n",
       "      <td>0.654</td>\n",
       "      <td>0.526</td>\n",
       "      <td>0.532</td>\n",
       "      <td>0.292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roben_2_bert_sst_bin</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.704</td>\n",
       "      <td>0.582</td>\n",
       "      <td>0.586</td>\n",
       "      <td>0.318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roben_1_tok_bert_sst_bin</th>\n",
       "      <td>0.694</td>\n",
       "      <td>0.668</td>\n",
       "      <td>0.498</td>\n",
       "      <td>0.646</td>\n",
       "      <td>0.274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roben_2_tok_bert_sst_bin</th>\n",
       "      <td>0.758</td>\n",
       "      <td>0.748</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.726</td>\n",
       "      <td>0.338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64k_lstm_clean_vanilla_bert_sst_bin</th>\n",
       "      <td>0.888</td>\n",
       "      <td>0.722</td>\n",
       "      <td>0.678</td>\n",
       "      <td>0.408</td>\n",
       "      <td>0.324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64k_lstm_no_whitespace_pert_vanilla_bert_sst_bin</th>\n",
       "      <td>0.856</td>\n",
       "      <td>0.806</td>\n",
       "      <td>0.698</td>\n",
       "      <td>0.594</td>\n",
       "      <td>0.408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64k_lstm_all_pert_vanilla_bert_sst_bin</th>\n",
       "      <td>0.862</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.768</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64k_lstm_all_pert_finetuned_bert_sst_bin</th>\n",
       "      <td>0.868</td>\n",
       "      <td>0.794</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.574</td>\n",
       "      <td>0.568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>baseline_roberta_sst_bin</th>\n",
       "      <td>0.932</td>\n",
       "      <td>0.764</td>\n",
       "      <td>0.784</td>\n",
       "      <td>0.486</td>\n",
       "      <td>0.468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roben_1_roberta_sst_bin</th>\n",
       "      <td>0.804</td>\n",
       "      <td>0.682</td>\n",
       "      <td>0.628</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roben_2_roberta_sst_bin</th>\n",
       "      <td>0.842</td>\n",
       "      <td>0.746</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.646</td>\n",
       "      <td>0.402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roben_1_tok_roberta_sst_bin</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.726</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roben_2_tok_roberta_sst_bin</th>\n",
       "      <td>0.782</td>\n",
       "      <td>0.766</td>\n",
       "      <td>0.652</td>\n",
       "      <td>0.748</td>\n",
       "      <td>0.406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64k_lstm_all_pert_vanilla_roberta_sst_bin</th>\n",
       "      <td>0.888</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.814</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64k_lstm_all_pert_finetuned_roberta_sst_bin</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.812</td>\n",
       "      <td>0.828</td>\n",
       "      <td>0.604</td>\n",
       "      <td>0.622</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  clean stochastic_no_ws  \\\n",
       "baseline_bert_sst_bin                             0.914            0.708   \n",
       "roben_1_bert_sst_bin                              0.772            0.654   \n",
       "roben_2_bert_sst_bin                                0.8            0.704   \n",
       "roben_1_tok_bert_sst_bin                          0.694            0.668   \n",
       "roben_2_tok_bert_sst_bin                          0.758            0.748   \n",
       "64k_lstm_clean_vanilla_bert_sst_bin               0.888            0.722   \n",
       "64k_lstm_no_whitespace_pert_vanilla_bert_sst_bin  0.856            0.806   \n",
       "64k_lstm_all_pert_vanilla_bert_sst_bin            0.862             0.79   \n",
       "64k_lstm_all_pert_finetuned_bert_sst_bin          0.868            0.794   \n",
       "baseline_roberta_sst_bin                          0.932            0.764   \n",
       "roben_1_roberta_sst_bin                           0.804            0.682   \n",
       "roben_2_roberta_sst_bin                           0.842            0.746   \n",
       "roben_1_tok_roberta_sst_bin                        0.75            0.726   \n",
       "roben_2_tok_roberta_sst_bin                       0.782            0.766   \n",
       "64k_lstm_all_pert_vanilla_roberta_sst_bin         0.888             0.81   \n",
       "64k_lstm_all_pert_finetuned_roberta_sst_bin         0.9            0.812   \n",
       "\n",
       "                                                 stochastic_incl_ws  \\\n",
       "baseline_bert_sst_bin                                           0.7   \n",
       "roben_1_bert_sst_bin                                          0.526   \n",
       "roben_2_bert_sst_bin                                          0.582   \n",
       "roben_1_tok_bert_sst_bin                                      0.498   \n",
       "roben_2_tok_bert_sst_bin                                       0.57   \n",
       "64k_lstm_clean_vanilla_bert_sst_bin                           0.678   \n",
       "64k_lstm_no_whitespace_pert_vanilla_bert_sst_bin              0.698   \n",
       "64k_lstm_all_pert_vanilla_bert_sst_bin                        0.768   \n",
       "64k_lstm_all_pert_finetuned_bert_sst_bin                       0.76   \n",
       "baseline_roberta_sst_bin                                      0.784   \n",
       "roben_1_roberta_sst_bin                                       0.628   \n",
       "roben_2_roberta_sst_bin                                        0.68   \n",
       "roben_1_tok_roberta_sst_bin                                    0.59   \n",
       "roben_2_tok_roberta_sst_bin                                   0.652   \n",
       "64k_lstm_all_pert_vanilla_roberta_sst_bin                     0.814   \n",
       "64k_lstm_all_pert_finetuned_roberta_sst_bin                   0.828   \n",
       "\n",
       "                                                 word_score_no_ws  \\\n",
       "baseline_bert_sst_bin                                       0.422   \n",
       "roben_1_bert_sst_bin                                        0.532   \n",
       "roben_2_bert_sst_bin                                        0.586   \n",
       "roben_1_tok_bert_sst_bin                                    0.646   \n",
       "roben_2_tok_bert_sst_bin                                    0.726   \n",
       "64k_lstm_clean_vanilla_bert_sst_bin                         0.408   \n",
       "64k_lstm_no_whitespace_pert_vanilla_bert_sst_bin            0.594   \n",
       "64k_lstm_all_pert_vanilla_bert_sst_bin                       0.57   \n",
       "64k_lstm_all_pert_finetuned_bert_sst_bin                    0.574   \n",
       "baseline_roberta_sst_bin                                    0.486   \n",
       "roben_1_roberta_sst_bin                                       0.6   \n",
       "roben_2_roberta_sst_bin                                     0.646   \n",
       "roben_1_tok_roberta_sst_bin                                   0.7   \n",
       "roben_2_tok_roberta_sst_bin                                 0.748   \n",
       "64k_lstm_all_pert_vanilla_roberta_sst_bin                    0.62   \n",
       "64k_lstm_all_pert_finetuned_roberta_sst_bin                 0.604   \n",
       "\n",
       "                                                 word_score_incl_ws  \n",
       "baseline_bert_sst_bin                                         0.388  \n",
       "roben_1_bert_sst_bin                                          0.292  \n",
       "roben_2_bert_sst_bin                                          0.318  \n",
       "roben_1_tok_bert_sst_bin                                      0.274  \n",
       "roben_2_tok_bert_sst_bin                                      0.338  \n",
       "64k_lstm_clean_vanilla_bert_sst_bin                           0.324  \n",
       "64k_lstm_no_whitespace_pert_vanilla_bert_sst_bin              0.408  \n",
       "64k_lstm_all_pert_vanilla_bert_sst_bin                        0.568  \n",
       "64k_lstm_all_pert_finetuned_bert_sst_bin                      0.568  \n",
       "baseline_roberta_sst_bin                                      0.468  \n",
       "roben_1_roberta_sst_bin                                        0.36  \n",
       "roben_2_roberta_sst_bin                                       0.402  \n",
       "roben_1_tok_roberta_sst_bin                                   0.376  \n",
       "roben_2_tok_roberta_sst_bin                                   0.406  \n",
       "64k_lstm_all_pert_vanilla_roberta_sst_bin                     0.622  \n",
       "64k_lstm_all_pert_finetuned_roberta_sst_bin                   0.622  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "79f4cd33",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-01T06:14:51.208980Z",
     "iopub.status.busy": "2022-04-01T06:14:51.208404Z",
     "iopub.status.idle": "2022-04-01T06:14:51.211291Z",
     "shell.execute_reply": "2022-04-01T06:14:51.211757Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean</th>\n",
       "      <th>stochastic_no_ws</th>\n",
       "      <th>stochastic_incl_ws</th>\n",
       "      <th>word_score_no_ws</th>\n",
       "      <th>word_score_incl_ws</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>baseline_bert_sst_bin</th>\n",
       "      <td>0.913876</td>\n",
       "      <td>0.705721</td>\n",
       "      <td>0.697209</td>\n",
       "      <td>0.417693</td>\n",
       "      <td>0.380777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roben_1_bert_sst_bin</th>\n",
       "      <td>0.771942</td>\n",
       "      <td>0.653832</td>\n",
       "      <td>0.525162</td>\n",
       "      <td>0.529281</td>\n",
       "      <td>0.285414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roben_2_bert_sst_bin</th>\n",
       "      <td>0.799949</td>\n",
       "      <td>0.703882</td>\n",
       "      <td>0.580952</td>\n",
       "      <td>0.584402</td>\n",
       "      <td>0.314642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roben_1_tok_bert_sst_bin</th>\n",
       "      <td>0.693989</td>\n",
       "      <td>0.667979</td>\n",
       "      <td>0.497113</td>\n",
       "      <td>0.645931</td>\n",
       "      <td>0.270425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roben_2_tok_bert_sst_bin</th>\n",
       "      <td>0.757782</td>\n",
       "      <td>0.747673</td>\n",
       "      <td>0.569709</td>\n",
       "      <td>0.725867</td>\n",
       "      <td>0.337234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64k_lstm_clean_vanilla_bert_sst_bin</th>\n",
       "      <td>0.887855</td>\n",
       "      <td>0.721187</td>\n",
       "      <td>0.677193</td>\n",
       "      <td>0.407536</td>\n",
       "      <td>0.322917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64k_lstm_no_whitespace_pert_vanilla_bert_sst_bin</th>\n",
       "      <td>0.855917</td>\n",
       "      <td>0.805993</td>\n",
       "      <td>0.697999</td>\n",
       "      <td>0.59392</td>\n",
       "      <td>0.408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64k_lstm_all_pert_vanilla_bert_sst_bin</th>\n",
       "      <td>0.861973</td>\n",
       "      <td>0.789999</td>\n",
       "      <td>0.767941</td>\n",
       "      <td>0.569998</td>\n",
       "      <td>0.567439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64k_lstm_all_pert_finetuned_bert_sst_bin</th>\n",
       "      <td>0.867981</td>\n",
       "      <td>0.793933</td>\n",
       "      <td>0.759904</td>\n",
       "      <td>0.573247</td>\n",
       "      <td>0.567751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>baseline_roberta_sst_bin</th>\n",
       "      <td>0.931843</td>\n",
       "      <td>0.760781</td>\n",
       "      <td>0.781054</td>\n",
       "      <td>0.465027</td>\n",
       "      <td>0.451782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roben_1_roberta_sst_bin</th>\n",
       "      <td>0.801136</td>\n",
       "      <td>0.669564</td>\n",
       "      <td>0.613138</td>\n",
       "      <td>0.571947</td>\n",
       "      <td>0.335504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roben_2_roberta_sst_bin</th>\n",
       "      <td>0.840823</td>\n",
       "      <td>0.740468</td>\n",
       "      <td>0.671155</td>\n",
       "      <td>0.630941</td>\n",
       "      <td>0.375499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roben_1_tok_roberta_sst_bin</th>\n",
       "      <td>0.743262</td>\n",
       "      <td>0.717846</td>\n",
       "      <td>0.569543</td>\n",
       "      <td>0.688518</td>\n",
       "      <td>0.355105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roben_2_tok_roberta_sst_bin</th>\n",
       "      <td>0.778252</td>\n",
       "      <td>0.762225</td>\n",
       "      <td>0.640876</td>\n",
       "      <td>0.742664</td>\n",
       "      <td>0.389991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64k_lstm_all_pert_vanilla_roberta_sst_bin</th>\n",
       "      <td>0.88748</td>\n",
       "      <td>0.808584</td>\n",
       "      <td>0.812861</td>\n",
       "      <td>0.615515</td>\n",
       "      <td>0.616289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64k_lstm_all_pert_finetuned_roberta_sst_bin</th>\n",
       "      <td>0.89984</td>\n",
       "      <td>0.811852</td>\n",
       "      <td>0.827666</td>\n",
       "      <td>0.603086</td>\n",
       "      <td>0.620724</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     clean stochastic_no_ws  \\\n",
       "baseline_bert_sst_bin                             0.913876         0.705721   \n",
       "roben_1_bert_sst_bin                              0.771942         0.653832   \n",
       "roben_2_bert_sst_bin                              0.799949         0.703882   \n",
       "roben_1_tok_bert_sst_bin                          0.693989         0.667979   \n",
       "roben_2_tok_bert_sst_bin                          0.757782         0.747673   \n",
       "64k_lstm_clean_vanilla_bert_sst_bin               0.887855         0.721187   \n",
       "64k_lstm_no_whitespace_pert_vanilla_bert_sst_bin  0.855917         0.805993   \n",
       "64k_lstm_all_pert_vanilla_bert_sst_bin            0.861973         0.789999   \n",
       "64k_lstm_all_pert_finetuned_bert_sst_bin          0.867981         0.793933   \n",
       "baseline_roberta_sst_bin                          0.931843         0.760781   \n",
       "roben_1_roberta_sst_bin                           0.801136         0.669564   \n",
       "roben_2_roberta_sst_bin                           0.840823         0.740468   \n",
       "roben_1_tok_roberta_sst_bin                       0.743262         0.717846   \n",
       "roben_2_tok_roberta_sst_bin                       0.778252         0.762225   \n",
       "64k_lstm_all_pert_vanilla_roberta_sst_bin          0.88748         0.808584   \n",
       "64k_lstm_all_pert_finetuned_roberta_sst_bin        0.89984         0.811852   \n",
       "\n",
       "                                                 stochastic_incl_ws  \\\n",
       "baseline_bert_sst_bin                                      0.697209   \n",
       "roben_1_bert_sst_bin                                       0.525162   \n",
       "roben_2_bert_sst_bin                                       0.580952   \n",
       "roben_1_tok_bert_sst_bin                                   0.497113   \n",
       "roben_2_tok_bert_sst_bin                                   0.569709   \n",
       "64k_lstm_clean_vanilla_bert_sst_bin                        0.677193   \n",
       "64k_lstm_no_whitespace_pert_vanilla_bert_sst_bin           0.697999   \n",
       "64k_lstm_all_pert_vanilla_bert_sst_bin                     0.767941   \n",
       "64k_lstm_all_pert_finetuned_bert_sst_bin                   0.759904   \n",
       "baseline_roberta_sst_bin                                   0.781054   \n",
       "roben_1_roberta_sst_bin                                    0.613138   \n",
       "roben_2_roberta_sst_bin                                    0.671155   \n",
       "roben_1_tok_roberta_sst_bin                                0.569543   \n",
       "roben_2_tok_roberta_sst_bin                                0.640876   \n",
       "64k_lstm_all_pert_vanilla_roberta_sst_bin                  0.812861   \n",
       "64k_lstm_all_pert_finetuned_roberta_sst_bin                0.827666   \n",
       "\n",
       "                                                 word_score_no_ws  \\\n",
       "baseline_bert_sst_bin                                    0.417693   \n",
       "roben_1_bert_sst_bin                                     0.529281   \n",
       "roben_2_bert_sst_bin                                     0.584402   \n",
       "roben_1_tok_bert_sst_bin                                 0.645931   \n",
       "roben_2_tok_bert_sst_bin                                 0.725867   \n",
       "64k_lstm_clean_vanilla_bert_sst_bin                      0.407536   \n",
       "64k_lstm_no_whitespace_pert_vanilla_bert_sst_bin          0.59392   \n",
       "64k_lstm_all_pert_vanilla_bert_sst_bin                   0.569998   \n",
       "64k_lstm_all_pert_finetuned_bert_sst_bin                 0.573247   \n",
       "baseline_roberta_sst_bin                                 0.465027   \n",
       "roben_1_roberta_sst_bin                                  0.571947   \n",
       "roben_2_roberta_sst_bin                                  0.630941   \n",
       "roben_1_tok_roberta_sst_bin                              0.688518   \n",
       "roben_2_tok_roberta_sst_bin                              0.742664   \n",
       "64k_lstm_all_pert_vanilla_roberta_sst_bin                0.615515   \n",
       "64k_lstm_all_pert_finetuned_roberta_sst_bin              0.603086   \n",
       "\n",
       "                                                 word_score_incl_ws  \n",
       "baseline_bert_sst_bin                                      0.380777  \n",
       "roben_1_bert_sst_bin                                       0.285414  \n",
       "roben_2_bert_sst_bin                                       0.314642  \n",
       "roben_1_tok_bert_sst_bin                                   0.270425  \n",
       "roben_2_tok_bert_sst_bin                                   0.337234  \n",
       "64k_lstm_clean_vanilla_bert_sst_bin                        0.322917  \n",
       "64k_lstm_no_whitespace_pert_vanilla_bert_sst_bin              0.408  \n",
       "64k_lstm_all_pert_vanilla_bert_sst_bin                     0.567439  \n",
       "64k_lstm_all_pert_finetuned_bert_sst_bin                   0.567751  \n",
       "baseline_roberta_sst_bin                                   0.451782  \n",
       "roben_1_roberta_sst_bin                                    0.335504  \n",
       "roben_2_roberta_sst_bin                                    0.375499  \n",
       "roben_1_tok_roberta_sst_bin                                0.355105  \n",
       "roben_2_tok_roberta_sst_bin                                0.389991  \n",
       "64k_lstm_all_pert_vanilla_roberta_sst_bin                  0.616289  \n",
       "64k_lstm_all_pert_finetuned_roberta_sst_bin                0.620724  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4b227192",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-01T06:14:51.215426Z",
     "iopub.status.busy": "2022-04-01T06:14:51.214848Z",
     "iopub.status.idle": "2022-04-01T06:14:51.219469Z",
     "shell.execute_reply": "2022-04-01T06:14:51.219961Z"
    }
   },
   "outputs": [],
   "source": [
    "accuracy_df.to_csv(\"../output/grid_accuracy.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "69cb79c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-01T06:14:51.223400Z",
     "iopub.status.busy": "2022-04-01T06:14:51.222326Z",
     "iopub.status.idle": "2022-04-01T06:14:51.226522Z",
     "shell.execute_reply": "2022-04-01T06:14:51.227884Z"
    }
   },
   "outputs": [],
   "source": [
    "f1_df.to_csv(\"../output/grid_f1.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fff8d67",
   "metadata": {},
   "source": [
    "-----"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "2a4bb820c60e40c1ad0f64107d79c7f1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "46a5be577b9e40eeab875a637fb2c738": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4d936e5567d94706bcf6b4ef2236e146": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_cb6ac35c597a4aaaa22afa7869915e6c",
       "placeholder": "​",
       "style": "IPY_MODEL_d449ab3082d846d9bfe6f759ce4b6961",
       "value": "100%"
      }
     },
     "9cbbe48af9c74d1fa2a1dcfd7fedf44c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_4d936e5567d94706bcf6b4ef2236e146",
        "IPY_MODEL_b819c89091db48baa8d383ab5691e161",
        "IPY_MODEL_d88b1744e4b248d4862767ee803c7a82"
       ],
       "layout": "IPY_MODEL_46a5be577b9e40eeab875a637fb2c738"
      }
     },
     "9eb4ae5d3a0e4d26a146082921db36ad": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a961553d4e66474b986f6d9279bc6cfe": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "b819c89091db48baa8d383ab5691e161": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_cf845fb3afc3455384caed6df36f6f45",
       "max": 4,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_a961553d4e66474b986f6d9279bc6cfe",
       "value": 4
      }
     },
     "cb6ac35c597a4aaaa22afa7869915e6c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "cf845fb3afc3455384caed6df36f6f45": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d449ab3082d846d9bfe6f759ce4b6961": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "d88b1744e4b248d4862767ee803c7a82": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_9eb4ae5d3a0e4d26a146082921db36ad",
       "placeholder": "​",
       "style": "IPY_MODEL_2a4bb820c60e40c1ad0f64107d79c7f1",
       "value": " 4/4 [00:00&lt;00:00,  5.44it/s]"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
