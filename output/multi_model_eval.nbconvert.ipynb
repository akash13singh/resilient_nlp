{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67daa863",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-01T19:15:03.925014Z",
     "iopub.status.busy": "2022-04-01T19:15:03.924357Z",
     "iopub.status.idle": "2022-04-01T19:15:06.245743Z",
     "shell.execute_reply": "2022-04-01T19:15:06.244943Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import copy\n",
    "import cProfile\n",
    "from datasets import load_dataset\n",
    "import json\n",
    "import math\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer, DataCollatorWithPadding, \\\n",
    "                         AutoModelForSequenceClassification, BertForSequenceClassification\n",
    "\n",
    "from resilient_nlp.mini_roben import Clustering, ClusterRepRecoverer, ClusterRecovererWithPassthrough\n",
    "from resilient_nlp.models import BertClassifier\n",
    "from resilient_nlp.perturbers import ToyPerturber, WordScramblerPerturber\n",
    "from runner import ExperimentRunner\n",
    "from word_score_attack import BertWordScoreAttack\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ae7a7c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-01T19:15:06.252140Z",
     "iopub.status.busy": "2022-04-01T19:15:06.251562Z",
     "iopub.status.idle": "2022-04-01T19:15:07.486125Z",
     "shell.execute_reply": "2022-04-01T19:15:07.485581Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration artemis13fowl--imdb-f63738dec0d5e230\n",
      "Reusing dataset parquet (/home/ec2-user/.cache/huggingface/datasets/parquet/artemis13fowl--imdb-f63738dec0d5e230/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49d528b4c1e040de960a296e3c6cd4fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# imdb = load_dataset('imdb')\n",
    "imdb = load_dataset('artemis13fowl/imdb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9bc64b56",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-01T19:15:07.528992Z",
     "iopub.status.busy": "2022-04-01T19:15:07.528292Z",
     "iopub.status.idle": "2022-04-01T19:15:07.530253Z",
     "shell.execute_reply": "2022-04-01T19:15:07.530729Z"
    }
   },
   "outputs": [],
   "source": [
    "random.seed(11)\n",
    "sampled_test_set = imdb['attack_eval_truncated']\n",
    "\n",
    "# This is silly but apparently huggingface datasets are immutable?\n",
    "# Representing it as something a bit more sane\n",
    "sampled_test_set_dict = [\n",
    "    {\n",
    "        'text': row['text'],\n",
    "        'label': row['label'],\n",
    "    }\n",
    "    for row in sampled_test_set\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17700b9e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-01T19:15:07.535884Z",
     "iopub.status.busy": "2022-04-01T19:15:07.534049Z",
     "iopub.status.idle": "2022-04-01T19:15:08.459925Z",
     "shell.execute_reply": "2022-04-01T19:15:08.460392Z"
    }
   },
   "outputs": [],
   "source": [
    "checkpoint = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a09ce62d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-01T19:15:08.466415Z",
     "iopub.status.busy": "2022-04-01T19:15:08.465823Z",
     "iopub.status.idle": "2022-04-01T19:15:15.659476Z",
     "shell.execute_reply": "2022-04-01T19:15:15.658922Z"
    }
   },
   "outputs": [],
   "source": [
    "checkpoint_finetuned = \"artemis13fowl/bert-base-uncased-imdb\"\n",
    "model_finetuned = BertForSequenceClassification.from_pretrained(checkpoint_finetuned).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b3c3fb8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-01T19:15:15.663967Z",
     "iopub.status.busy": "2022-04-01T19:15:15.663391Z",
     "iopub.status.idle": "2022-04-01T19:15:59.751906Z",
     "shell.execute_reply": "2022-04-01T19:15:59.751361Z"
    }
   },
   "outputs": [],
   "source": [
    "roben_clustering = Clustering.from_pickle(\"../vocab100000_ed1.pkl\")\n",
    "roben_recoverer = ClusterRecovererWithPassthrough(\"cache\", roben_clustering)\n",
    "roben_clustering2 = Clustering.from_pickle(\"../vocab100000_ed1_gamma0.3.pkl\")\n",
    "roben_recoverer2 = ClusterRecovererWithPassthrough(\"cache\", roben_clustering2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "effea54c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-01T19:15:59.764728Z",
     "iopub.status.busy": "2022-04-01T19:15:59.759620Z",
     "iopub.status.idle": "2022-04-01T19:16:01.105562Z",
     "shell.execute_reply": "2022-04-01T19:16:01.104868Z"
    }
   },
   "outputs": [],
   "source": [
    "random.seed(11)\n",
    "sampled_test_set_adv_no_ws = []\n",
    "wsp = WordScramblerPerturber(perturb_prob=0.1, weight_add=1, weight_drop=1, weight_swap=1,\n",
    "                             weight_split_word=0, weight_merge_words=0)\n",
    "\n",
    "for i in range(10):\n",
    "    test_item = copy.deepcopy(sampled_test_set_dict)\n",
    "\n",
    "    for row in test_item:\n",
    "        row['text'] = wsp.perturb([row['text']])[0][0]\n",
    "    sampled_test_set_adv_no_ws.append(test_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "651ef05f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-01T19:16:01.118345Z",
     "iopub.status.busy": "2022-04-01T19:16:01.113218Z",
     "iopub.status.idle": "2022-04-01T19:16:02.474068Z",
     "shell.execute_reply": "2022-04-01T19:16:02.474541Z"
    }
   },
   "outputs": [],
   "source": [
    "random.seed(11)\n",
    "sampled_test_set_adv_incl_ws = []\n",
    "wsp = WordScramblerPerturber(perturb_prob=0.1, weight_add=1, weight_drop=1, weight_swap=1,\n",
    "                             weight_split_word=1, weight_merge_words=1)\n",
    "\n",
    "for i in range(10):\n",
    "    test_item = copy.deepcopy(sampled_test_set_dict)\n",
    "\n",
    "    for row in test_item:\n",
    "        row['text'] = wsp.perturb([row['text']])[0][0]\n",
    "    sampled_test_set_adv_incl_ws.append(test_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2efe10f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-01T19:16:02.478554Z",
     "iopub.status.busy": "2022-04-01T19:16:02.477990Z",
     "iopub.status.idle": "2022-04-01T19:16:02.480461Z",
     "shell.execute_reply": "2022-04-01T19:16:02.479878Z"
    }
   },
   "outputs": [],
   "source": [
    "max_sequence_length = 128\n",
    "batch_size = 32\n",
    "eval_steps = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b958a5c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-01T19:16:02.487863Z",
     "iopub.status.busy": "2022-04-01T19:16:02.487271Z",
     "iopub.status.idle": "2022-04-01T19:16:02.489695Z",
     "shell.execute_reply": "2022-04-01T19:16:02.489061Z"
    }
   },
   "outputs": [],
   "source": [
    "def standard_model_predict(tokenizer, model, sentences, recoverer, return_pred_tensor, recoverer_tokenize):\n",
    "    if recoverer is not None:\n",
    "        if recoverer_tokenize:\n",
    "            tok = nltk.tokenize.treebank.TreebankWordTokenizer()\n",
    "            sentences = [ \" \".join(tok_list) for tok_list in tok.tokenize_sents(sentences) ]\n",
    "        sentences = [ recoverer.recover(s.lower()) for s in sentences ]\n",
    "        if recoverer_tokenize:\n",
    "            detok = nltk.tokenize.treebank.TreebankWordDetokenizer()\n",
    "            sentences = [ detok.detokenize(s.split(\" \")) for s in sentences]\n",
    "    tokenized = tokenizer(sentences, truncation=True, padding='max_length', max_length=max_sequence_length,\n",
    "                          return_tensors='pt')\n",
    "    tokenized = { k: v.to(device) for k, v in tokenized.items() }\n",
    "    preds = model(**tokenized)\n",
    "    if return_pred_tensor:\n",
    "        return preds\n",
    "    else:\n",
    "        return torch.argmax(preds.logits, dim=1)\n",
    "\n",
    "def wrap_standard_model(tokenizer, model, recoverer=None, return_pred_tensor=True, recoverer_tokenize=False):\n",
    "    return lambda sentences: standard_model_predict(tokenizer, model, sentences, recoverer, return_pred_tensor,\n",
    "                                                    recoverer_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ba7bb36",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-01T19:16:02.497707Z",
     "iopub.status.busy": "2022-04-01T19:16:02.497074Z",
     "iopub.status.idle": "2022-04-01T19:16:02.499521Z",
     "shell.execute_reply": "2022-04-01T19:16:02.499031Z"
    }
   },
   "outputs": [],
   "source": [
    "def mltokenizer_model_predict(runner, model, cls_embedding, sep_embedding, pad_embedding, sentences, return_pred_tensor):\n",
    "    # Truncate and lower case. Truncation is for performance only\n",
    "    sentences = [ s.lower()[:5*max_sequence_length] for s in sentences]\n",
    "    embedding = runner.embed(sentences=sentences,\n",
    "        start_token=cls_embedding, end_token=sep_embedding, pad_token=pad_embedding,\n",
    "        max_tokens=max_sequence_length)\n",
    "    preds = model(inputs_embeds=embedding['inputs_embeds'], attention_mask=embedding['attention_mask'])\n",
    "    if return_pred_tensor:\n",
    "        return preds\n",
    "    else:\n",
    "        return torch.argmax(preds.logits, dim=1)\n",
    "\n",
    "def wrap_mltokenizer_model(mltokenizer_prefix, tokenizer, model, return_pred_tensor=True):\n",
    "    filename = \"../{}.pth\".format(mltokenizer_prefix)\n",
    "    runner = ExperimentRunner(device, model_filename=filename)\n",
    "    cf_embedding = model.base_model.embeddings.word_embeddings\n",
    "    cls_token_id = tokenizer.vocab['[CLS]']\n",
    "    sep_token_id = tokenizer.vocab['[SEP]']\n",
    "    pad_token_id = tokenizer.vocab['[PAD]']\n",
    "    cls_embedding = cf_embedding(torch.tensor([cls_token_id], device=device)).view(-1)\n",
    "    sep_embedding = cf_embedding(torch.tensor([sep_token_id], device=device)).view(-1)\n",
    "    pad_embedding = cf_embedding(torch.tensor([pad_token_id], device=device)).view(-1)\n",
    "    \n",
    "    return lambda sentences: mltokenizer_model_predict(runner, model, cls_embedding, sep_embedding,\n",
    "                                                      pad_embedding, sentences, return_pred_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2033ec30",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-01T19:16:02.505487Z",
     "iopub.status.busy": "2022-04-01T19:16:02.501707Z",
     "iopub.status.idle": "2022-04-01T19:16:02.507689Z",
     "shell.execute_reply": "2022-04-01T19:16:02.507118Z"
    }
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate_model(model, test_set):\n",
    "    num_batches = math.ceil(len(test_set) / batch_size)\n",
    "    \n",
    "    sentences = [ x['text'] for x in test_set ]\n",
    "    labels = [ x['label'] for x in test_set ]\n",
    "    pred_batches = []\n",
    "    \n",
    "    for i in tqdm(range(num_batches)):\n",
    "        bs = i * batch_size\n",
    "        be = bs + batch_size\n",
    "        \n",
    "        output = model(sentences[bs:be])\n",
    "        \n",
    "        pred_batches.append(torch.argmax(output.logits, dim=1).detach().cpu())\n",
    "    preds = torch.cat(pred_batches)\n",
    "    \n",
    "    print(classification_report(labels, preds, digits=4))\n",
    "    \n",
    "    accuracy = accuracy_score(labels, preds)\n",
    "    f1 = f1_score(labels, preds, average='macro')\n",
    "    \n",
    "    return accuracy, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33c8259a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-01T19:16:02.515688Z",
     "iopub.status.busy": "2022-04-01T19:16:02.515095Z",
     "iopub.status.idle": "2022-04-01T19:16:02.517329Z",
     "shell.execute_reply": "2022-04-01T19:16:02.517839Z"
    }
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate_model_adv(model, test_sets):\n",
    "    labels = [ x['label'] for x in test_sets[0] ]\n",
    "    adv_preds = copy.copy(labels)\n",
    "    accuracy_list = []\n",
    "    f1_list = []\n",
    "    \n",
    "    for idx in tqdm(range(len(test_sets))):\n",
    "        test_set = test_sets[idx]\n",
    "        num_batches = math.ceil(len(test_set) / batch_size)\n",
    "    \n",
    "        sentences = [ x['text'] for x in test_set ]\n",
    "        pred_batches = []\n",
    "    \n",
    "        for i in range(num_batches):\n",
    "            bs = i * batch_size\n",
    "            be = bs + batch_size\n",
    "        \n",
    "            output = model(sentences[bs:be])\n",
    "        \n",
    "            pred_batches.append(torch.argmax(output.logits, dim=1).detach().cpu())\n",
    "        preds = torch.cat(pred_batches)\n",
    "        \n",
    "        for i in range(len(adv_preds)):\n",
    "            if labels[i] == 1.0 and preds[i] == 0.0:\n",
    "                adv_preds[i] = 0.0\n",
    "            elif labels[i] == 0.0 and preds[i] == 1.0:\n",
    "                adv_preds[i] = 1.0\n",
    "\n",
    "        accuracy_list.append(accuracy_score(labels, adv_preds))\n",
    "        f1_list.append(f1_score(labels, adv_preds, average='macro'))\n",
    "    \n",
    "    print(classification_report(labels, adv_preds, digits=4))    \n",
    "    \n",
    "    return accuracy_list, f1_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "26be9ad5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-01T19:16:02.524477Z",
     "iopub.status.busy": "2022-04-01T19:16:02.523891Z",
     "iopub.status.idle": "2022-04-01T19:16:02.526236Z",
     "shell.execute_reply": "2022-04-01T19:16:02.525746Z"
    }
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate_model_word_score(model, test_set, allow_whitespace_pert=True, report_prefix=None):\n",
    "    attacker = BertWordScoreAttack(\n",
    "        WordScramblerPerturber(perturb_prob=1, weight_add=1, weight_drop=1, weight_swap=1,\n",
    "                               weight_split_word=int(allow_whitespace_pert),\n",
    "                               weight_merge_words=int(allow_whitespace_pert)),\n",
    "        \"../output/imdb_word_scores.json\", model, tokenizer=None, max_sequence_length=max_sequence_length\n",
    "    )\n",
    "\n",
    "    res = attacker.attack(test_set, max_tokens_to_query=10, max_tries_per_token=4, mode=0, print_summary=False)\n",
    "\n",
    "    if report_prefix is not None:\n",
    "        res.to_csv(f\"{report_prefix}_df.csv\")\n",
    "        with open(f\"{report_prefix}_stats.json\", \"w\") as f:\n",
    "            json.dump(attacker.compute_attack_stats(), fp=f)            \n",
    "    \n",
    "    print(classification_report(res['ground_truth'], res['perturbed_preds'], digits=4))    \n",
    "    \n",
    "    accuracy = accuracy_score(res['ground_truth'], res['perturbed_preds'])\n",
    "    f1 = f1_score(res['ground_truth'], res['perturbed_preds'], average='macro')\n",
    "    \n",
    "    return accuracy, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b537d1f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-01T19:16:02.529859Z",
     "iopub.status.busy": "2022-04-01T19:16:02.529255Z",
     "iopub.status.idle": "2022-04-01T19:16:02.531623Z",
     "shell.execute_reply": "2022-04-01T19:16:02.531040Z"
    }
   },
   "outputs": [],
   "source": [
    "baseline_model = wrap_standard_model(tokenizer, model_finetuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f5364f3b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-01T19:16:02.535142Z",
     "iopub.status.busy": "2022-04-01T19:16:02.534570Z",
     "iopub.status.idle": "2022-04-01T19:16:07.661370Z",
     "shell.execute_reply": "2022-04-01T19:16:07.661946Z"
    }
   },
   "outputs": [],
   "source": [
    "mltok_model = wrap_mltokenizer_model('output/64k_lstm_all_pert_finetuned', tokenizer, model_finetuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6e49764a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-01T19:16:07.666160Z",
     "iopub.status.busy": "2022-04-01T19:16:07.665584Z",
     "iopub.status.idle": "2022-04-01T19:16:07.668008Z",
     "shell.execute_reply": "2022-04-01T19:16:07.667432Z"
    }
   },
   "outputs": [],
   "source": [
    "baseline_roben_model = wrap_standard_model(tokenizer, model_finetuned, roben_recoverer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0b09dca9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-01T19:16:07.671693Z",
     "iopub.status.busy": "2022-04-01T19:16:07.671124Z",
     "iopub.status.idle": "2022-04-01T19:16:07.673482Z",
     "shell.execute_reply": "2022-04-01T19:16:07.672874Z"
    }
   },
   "outputs": [],
   "source": [
    "baseline_roben_model_tok = wrap_standard_model(tokenizer, model_finetuned, roben_recoverer, recoverer_tokenize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0eb23d8c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-01T19:16:07.677024Z",
     "iopub.status.busy": "2022-04-01T19:16:07.676459Z",
     "iopub.status.idle": "2022-04-01T19:16:07.678850Z",
     "shell.execute_reply": "2022-04-01T19:16:07.678330Z"
    }
   },
   "outputs": [],
   "source": [
    "baseline_roben_model2 = wrap_standard_model(tokenizer, model_finetuned, roben_recoverer2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "159e33c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-01T19:16:07.682519Z",
     "iopub.status.busy": "2022-04-01T19:16:07.681940Z",
     "iopub.status.idle": "2022-04-01T19:16:07.684283Z",
     "shell.execute_reply": "2022-04-01T19:16:07.683709Z"
    }
   },
   "outputs": [],
   "source": [
    "baseline_roben_model2_tok = wrap_standard_model(tokenizer, model_finetuned, roben_recoverer2, recoverer_tokenize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3b6fcd6e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-01T19:16:07.688915Z",
     "iopub.status.busy": "2022-04-01T19:16:07.688340Z",
     "iopub.status.idle": "2022-04-01T19:16:40.400133Z",
     "shell.execute_reply": "2022-04-01T19:16:40.400610Z"
    }
   },
   "outputs": [],
   "source": [
    "all_models = {\n",
    "    'baseline': baseline_model,\n",
    "    'roben_1': baseline_roben_model,\n",
    "    'roben_2': baseline_roben_model2,\n",
    "    'roben_1_tok': baseline_roben_model,\n",
    "    'roben_2_tok': baseline_roben_model2_tok,\n",
    "}\n",
    "\n",
    "mltok_model_names = [\n",
    "    '64k_lstm_clean_vanilla',\n",
    "    '64k_lstm_no_whitespace_pert_vanilla',\n",
    "    '64k_lstm_all_pert_vanilla',\n",
    "    '64k_lstm_clean_finetuned',\n",
    "    '64k_lstm_no_whitespace_pert_finetuned',\n",
    "    '64k_lstm_all_pert_finetuned',\n",
    "    '64k_cnn_no_whitespace_pert_finetuned',\n",
    "]\n",
    "\n",
    "for name in mltok_model_names:\n",
    "    all_models[name] = wrap_mltokenizer_model(f'output/{name}', tokenizer, model_finetuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e61f9273",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-01T19:16:40.404956Z",
     "iopub.status.busy": "2022-04-01T19:16:40.404371Z",
     "iopub.status.idle": "2022-04-01T19:16:40.406810Z",
     "shell.execute_reply": "2022-04-01T19:16:40.406342Z"
    }
   },
   "outputs": [],
   "source": [
    "evaluations = [\n",
    "    'clean',\n",
    "    'stochastic_no_ws',\n",
    "    'stochastic_incl_ws',\n",
    "    'word_score_no_ws',\n",
    "    'word_score_incl_ws',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "602a9ff8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-01T19:16:40.418103Z",
     "iopub.status.busy": "2022-04-01T19:16:40.414266Z",
     "iopub.status.idle": "2022-04-02T06:54:04.652954Z",
     "shell.execute_reply": "2022-04-02T06:54:04.652474Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model baseline on clean\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00, 13.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8765    0.8765    0.8765       243\n",
      "           1     0.8833    0.8833    0.8833       257\n",
      "\n",
      "    accuracy                         0.8800       500\n",
      "   macro avg     0.8799    0.8799    0.8799       500\n",
      "weighted avg     0.8800    0.8800    0.8800       500\n",
      "\n",
      "Evaluating model baseline on stochastic_no_ws\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:11<00:00,  1.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6970    0.7572    0.7258       243\n",
      "           1     0.7500    0.6887    0.7181       257\n",
      "\n",
      "    accuracy                         0.7220       500\n",
      "   macro avg     0.7235    0.7230    0.7219       500\n",
      "weighted avg     0.7242    0.7220    0.7218       500\n",
      "\n",
      "Evaluating model baseline on stochastic_incl_ws\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:11<00:00,  1.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6692    0.7160    0.6918       243\n",
      "           1     0.7125    0.6654    0.6881       257\n",
      "\n",
      "    accuracy                         0.6900       500\n",
      "   macro avg     0.6909    0.6907    0.6900       500\n",
      "weighted avg     0.6915    0.6900    0.6899       500\n",
      "\n",
      "Evaluating model baseline on word_score_no_ws\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "500it [04:04,  2.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5878    0.6337    0.6099       243\n",
      "           1     0.6261    0.5798    0.6020       257\n",
      "\n",
      "    accuracy                         0.6060       500\n",
      "   macro avg     0.6069    0.6068    0.6060       500\n",
      "weighted avg     0.6075    0.6060    0.6059       500\n",
      "\n",
      "Evaluating model baseline on word_score_incl_ws\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "500it [04:03,  2.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5843    0.6420    0.6118       243\n",
      "           1     0.6266    0.5681    0.5959       257\n",
      "\n",
      "    accuracy                         0.6040       500\n",
      "   macro avg     0.6054    0.6050    0.6038       500\n",
      "weighted avg     0.6060    0.6040    0.6036       500\n",
      "\n",
      "Evaluating model roben_1 on clean\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00, 11.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8365    0.7160    0.7716       243\n",
      "           1     0.7637    0.8677    0.8124       257\n",
      "\n",
      "    accuracy                         0.7940       500\n",
      "   macro avg     0.8001    0.7919    0.7920       500\n",
      "weighted avg     0.7991    0.7940    0.7926       500\n",
      "\n",
      "Evaluating model roben_1 on stochastic_no_ws\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:13<00:00,  1.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7048    0.6091    0.6534       243\n",
      "           1     0.6724    0.7588    0.7130       257\n",
      "\n",
      "    accuracy                         0.6860       500\n",
      "   macro avg     0.6886    0.6839    0.6832       500\n",
      "weighted avg     0.6881    0.6860    0.6840       500\n",
      "\n",
      "Evaluating model roben_1 on stochastic_incl_ws\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:13<00:00,  1.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5674    0.5021    0.5328       243\n",
      "           1     0.5754    0.6381    0.6052       257\n",
      "\n",
      "    accuracy                         0.5720       500\n",
      "   macro avg     0.5714    0.5701    0.5690       500\n",
      "weighted avg     0.5716    0.5720    0.5700       500\n",
      "\n",
      "Evaluating model roben_1 on word_score_no_ws\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "500it [04:02,  2.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6898    0.5309    0.6000       243\n",
      "           1     0.6358    0.7743    0.6982       257\n",
      "\n",
      "    accuracy                         0.6560       500\n",
      "   macro avg     0.6628    0.6526    0.6491       500\n",
      "weighted avg     0.6621    0.6560    0.6505       500\n",
      "\n",
      "Evaluating model roben_1 on word_score_incl_ws\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "500it [03:38,  2.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5538    0.4239    0.4802       243\n",
      "           1     0.5541    0.6770    0.6095       257\n",
      "\n",
      "    accuracy                         0.5540       500\n",
      "   macro avg     0.5540    0.5505    0.5448       500\n",
      "weighted avg     0.5540    0.5540    0.5466       500\n",
      "\n",
      "Evaluating model roben_2 on clean\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00, 12.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8423    0.7695    0.8043       243\n",
      "           1     0.7986    0.8638    0.8299       257\n",
      "\n",
      "    accuracy                         0.8180       500\n",
      "   macro avg     0.8205    0.8167    0.8171       500\n",
      "weighted avg     0.8198    0.8180    0.8175       500\n",
      "\n",
      "Evaluating model roben_2 on stochastic_no_ws\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:12<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7168    0.6667    0.6908       243\n",
      "           1     0.7044    0.7510    0.7269       257\n",
      "\n",
      "    accuracy                         0.7100       500\n",
      "   macro avg     0.7106    0.7088    0.7089       500\n",
      "weighted avg     0.7104    0.7100    0.7094       500\n",
      "\n",
      "Evaluating model roben_2 on stochastic_incl_ws\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:12<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5778    0.5350    0.5556       243\n",
      "           1     0.5891    0.6304    0.6090       257\n",
      "\n",
      "    accuracy                         0.5840       500\n",
      "   macro avg     0.5834    0.5827    0.5823       500\n",
      "weighted avg     0.5836    0.5840    0.5830       500\n",
      "\n",
      "Evaluating model roben_2 on word_score_no_ws\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "500it [04:15,  1.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7429    0.6420    0.6887       243\n",
      "           1     0.7000    0.7899    0.7422       257\n",
      "\n",
      "    accuracy                         0.7180       500\n",
      "   macro avg     0.7214    0.7159    0.7155       500\n",
      "weighted avg     0.7208    0.7180    0.7162       500\n",
      "\n",
      "Evaluating model roben_2 on word_score_incl_ws\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "500it [03:53,  2.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5936    0.5350    0.5628       243\n",
      "           1     0.5979    0.6537    0.6245       257\n",
      "\n",
      "    accuracy                         0.5960       500\n",
      "   macro avg     0.5957    0.5943    0.5937       500\n",
      "weighted avg     0.5958    0.5960    0.5945       500\n",
      "\n",
      "Evaluating model roben_1_tok on clean\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00, 13.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8365    0.7160    0.7716       243\n",
      "           1     0.7637    0.8677    0.8124       257\n",
      "\n",
      "    accuracy                         0.7940       500\n",
      "   macro avg     0.8001    0.7919    0.7920       500\n",
      "weighted avg     0.7991    0.7940    0.7926       500\n",
      "\n",
      "Evaluating model roben_1_tok on stochastic_no_ws\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:11<00:00,  1.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7048    0.6091    0.6534       243\n",
      "           1     0.6724    0.7588    0.7130       257\n",
      "\n",
      "    accuracy                         0.6860       500\n",
      "   macro avg     0.6886    0.6839    0.6832       500\n",
      "weighted avg     0.6881    0.6860    0.6840       500\n",
      "\n",
      "Evaluating model roben_1_tok on stochastic_incl_ws\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:11<00:00,  1.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5674    0.5021    0.5328       243\n",
      "           1     0.5754    0.6381    0.6052       257\n",
      "\n",
      "    accuracy                         0.5720       500\n",
      "   macro avg     0.5714    0.5701    0.5690       500\n",
      "weighted avg     0.5716    0.5720    0.5700       500\n",
      "\n",
      "Evaluating model roben_1_tok on word_score_no_ws\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "500it [03:53,  2.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6898    0.5309    0.6000       243\n",
      "           1     0.6358    0.7743    0.6982       257\n",
      "\n",
      "    accuracy                         0.6560       500\n",
      "   macro avg     0.6628    0.6526    0.6491       500\n",
      "weighted avg     0.6621    0.6560    0.6505       500\n",
      "\n",
      "Evaluating model roben_1_tok on word_score_incl_ws\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "500it [03:34,  2.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5538    0.4239    0.4802       243\n",
      "           1     0.5541    0.6770    0.6095       257\n",
      "\n",
      "    accuracy                         0.5540       500\n",
      "   macro avg     0.5540    0.5505    0.5448       500\n",
      "weighted avg     0.5540    0.5540    0.5466       500\n",
      "\n",
      "Evaluating model roben_2_tok on clean\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00,  9.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8238    0.7119    0.7638       243\n",
      "           1     0.7586    0.8560    0.8044       257\n",
      "\n",
      "    accuracy                         0.7860       500\n",
      "   macro avg     0.7912    0.7840    0.7841       500\n",
      "weighted avg     0.7903    0.7860    0.7847       500\n",
      "\n",
      "Evaluating model roben_2_tok on stochastic_no_ws\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:16<00:00,  1.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7053    0.6008    0.6489       243\n",
      "           1     0.6689    0.7626    0.7127       257\n",
      "\n",
      "    accuracy                         0.6840       500\n",
      "   macro avg     0.6871    0.6817    0.6808       500\n",
      "weighted avg     0.6866    0.6840    0.6817       500\n",
      "\n",
      "Evaluating model roben_2_tok on stochastic_incl_ws\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:15<00:00,  1.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5880    0.5226    0.5534       243\n",
      "           1     0.5915    0.6537    0.6211       257\n",
      "\n",
      "    accuracy                         0.5900       500\n",
      "   macro avg     0.5898    0.5882    0.5872       500\n",
      "weighted avg     0.5898    0.5900    0.5882       500\n",
      "\n",
      "Evaluating model roben_2_tok on word_score_no_ws\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "500it [04:22,  1.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7610    0.6420    0.6964       243\n",
      "           1     0.7051    0.8093    0.7536       257\n",
      "\n",
      "    accuracy                         0.7280       500\n",
      "   macro avg     0.7330    0.7257    0.7250       500\n",
      "weighted avg     0.7322    0.7280    0.7258       500\n",
      "\n",
      "Evaluating model roben_2_tok on word_score_incl_ws\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "500it [03:56,  2.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6098    0.5144    0.5580       243\n",
      "           1     0.6000    0.6887    0.6413       257\n",
      "\n",
      "    accuracy                         0.6040       500\n",
      "   macro avg     0.6049    0.6016    0.5997       500\n",
      "weighted avg     0.6047    0.6040    0.6008       500\n",
      "\n",
      "Evaluating model 64k_lstm_clean_vanilla on clean\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:20<00:00,  1.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8571    0.8642    0.8607       243\n",
      "           1     0.8706    0.8638    0.8672       257\n",
      "\n",
      "    accuracy                         0.8640       500\n",
      "   macro avg     0.8639    0.8640    0.8639       500\n",
      "weighted avg     0.8641    0.8640    0.8640       500\n",
      "\n",
      "Evaluating model 64k_lstm_clean_vanilla on stochastic_no_ws\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [03:20<00:00, 20.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6858    0.7366    0.7103       243\n",
      "           1     0.7322    0.6809    0.7056       257\n",
      "\n",
      "    accuracy                         0.7080       500\n",
      "   macro avg     0.7090    0.7088    0.7080       500\n",
      "weighted avg     0.7097    0.7080    0.7079       500\n",
      "\n",
      "Evaluating model 64k_lstm_clean_vanilla on stochastic_incl_ws\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [03:26<00:00, 20.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6370    0.7078    0.6706       243\n",
      "           1     0.6913    0.6187    0.6530       257\n",
      "\n",
      "    accuracy                         0.6620       500\n",
      "   macro avg     0.6642    0.6632    0.6618       500\n",
      "weighted avg     0.6649    0.6620    0.6615       500\n",
      "\n",
      "Evaluating model 64k_lstm_clean_vanilla on word_score_no_ws\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "500it [45:24,  5.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5804    0.6091    0.5944       243\n",
      "           1     0.6122    0.5837    0.5976       257\n",
      "\n",
      "    accuracy                         0.5960       500\n",
      "   macro avg     0.5963    0.5964    0.5960       500\n",
      "weighted avg     0.5968    0.5960    0.5960       500\n",
      "\n",
      "Evaluating model 64k_lstm_clean_vanilla on word_score_incl_ws\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "500it [44:15,  5.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5396    0.5885    0.5630       243\n",
      "           1     0.5745    0.5253    0.5488       257\n",
      "\n",
      "    accuracy                         0.5560       500\n",
      "   macro avg     0.5570    0.5569    0.5559       500\n",
      "weighted avg     0.5575    0.5560    0.5557       500\n",
      "\n",
      "Evaluating model 64k_lstm_no_whitespace_pert_vanilla on clean\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:20<00:00,  1.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8653    0.8724    0.8689       243\n",
      "           1     0.8784    0.8716    0.8750       257\n",
      "\n",
      "    accuracy                         0.8720       500\n",
      "   macro avg     0.8719    0.8720    0.8719       500\n",
      "weighted avg     0.8721    0.8720    0.8720       500\n",
      "\n",
      "Evaluating model 64k_lstm_no_whitespace_pert_vanilla on stochastic_no_ws\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [03:21<00:00, 20.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8041    0.8107    0.8074       243\n",
      "           1     0.8196    0.8132    0.8164       257\n",
      "\n",
      "    accuracy                         0.8120       500\n",
      "   macro avg     0.8118    0.8120    0.8119       500\n",
      "weighted avg     0.8121    0.8120    0.8120       500\n",
      "\n",
      "Evaluating model 64k_lstm_no_whitespace_pert_vanilla on stochastic_incl_ws\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [03:22<00:00, 20.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6972    0.7202    0.7085       243\n",
      "           1     0.7269    0.7043    0.7154       257\n",
      "\n",
      "    accuracy                         0.7120       500\n",
      "   macro avg     0.7121    0.7122    0.7120       500\n",
      "weighted avg     0.7125    0.7120    0.7121       500\n",
      "\n",
      "Evaluating model 64k_lstm_no_whitespace_pert_vanilla on word_score_no_ws\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "500it [50:50,  6.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7288    0.7078    0.7182       243\n",
      "           1     0.7311    0.7510    0.7409       257\n",
      "\n",
      "    accuracy                         0.7300       500\n",
      "   macro avg     0.7299    0.7294    0.7295       500\n",
      "weighted avg     0.7300    0.7300    0.7298       500\n",
      "\n",
      "Evaluating model 64k_lstm_no_whitespace_pert_vanilla on word_score_incl_ws\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "500it [48:58,  5.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6638    0.6337    0.6484       243\n",
      "           1     0.6679    0.6965    0.6819       257\n",
      "\n",
      "    accuracy                         0.6660       500\n",
      "   macro avg     0.6659    0.6651    0.6652       500\n",
      "weighted avg     0.6659    0.6660    0.6656       500\n",
      "\n",
      "Evaluating model 64k_lstm_all_pert_vanilla on clean\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:20<00:00,  1.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8734    0.8519    0.8625       243\n",
      "           1     0.8631    0.8833    0.8731       257\n",
      "\n",
      "    accuracy                         0.8680       500\n",
      "   macro avg     0.8683    0.8676    0.8678       500\n",
      "weighted avg     0.8681    0.8680    0.8679       500\n",
      "\n",
      "Evaluating model 64k_lstm_all_pert_vanilla on stochastic_no_ws\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [03:23<00:00, 20.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8162    0.7860    0.8008       243\n",
      "           1     0.8045    0.8327    0.8184       257\n",
      "\n",
      "    accuracy                         0.8100       500\n",
      "   macro avg     0.8104    0.8093    0.8096       500\n",
      "weighted avg     0.8102    0.8100    0.8098       500\n",
      "\n",
      "Evaluating model 64k_lstm_all_pert_vanilla on stochastic_incl_ws\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [03:23<00:00, 20.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8103    0.7737    0.7916       243\n",
      "           1     0.7948    0.8288    0.8114       257\n",
      "\n",
      "    accuracy                         0.8020       500\n",
      "   macro avg     0.8026    0.8012    0.8015       500\n",
      "weighted avg     0.8023    0.8020    0.8018       500\n",
      "\n",
      "Evaluating model 64k_lstm_all_pert_vanilla on word_score_no_ws\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "500it [50:40,  6.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7156    0.6420    0.6768       243\n",
      "           1     0.6915    0.7588    0.7236       257\n",
      "\n",
      "    accuracy                         0.7020       500\n",
      "   macro avg     0.7035    0.7004    0.7002       500\n",
      "weighted avg     0.7032    0.7020    0.7008       500\n",
      "\n",
      "Evaluating model 64k_lstm_all_pert_vanilla on word_score_incl_ws\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "500it [51:17,  6.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6870    0.6502    0.6681       243\n",
      "           1     0.6852    0.7198    0.7021       257\n",
      "\n",
      "    accuracy                         0.6860       500\n",
      "   macro avg     0.6861    0.6850    0.6851       500\n",
      "weighted avg     0.6860    0.6860    0.6856       500\n",
      "\n",
      "Evaluating model 64k_lstm_clean_finetuned on clean\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:20<00:00,  1.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8543    0.8683    0.8612       243\n",
      "           1     0.8735    0.8599    0.8667       257\n",
      "\n",
      "    accuracy                         0.8640       500\n",
      "   macro avg     0.8639    0.8641    0.8639       500\n",
      "weighted avg     0.8642    0.8640    0.8640       500\n",
      "\n",
      "Evaluating model 64k_lstm_clean_finetuned on stochastic_no_ws\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [03:22<00:00, 20.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7092    0.7325    0.7206       243\n",
      "           1     0.7390    0.7160    0.7273       257\n",
      "\n",
      "    accuracy                         0.7240       500\n",
      "   macro avg     0.7241    0.7242    0.7240       500\n",
      "weighted avg     0.7245    0.7240    0.7241       500\n",
      "\n",
      "Evaluating model 64k_lstm_clean_finetuned on stochastic_incl_ws\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [03:22<00:00, 20.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6718    0.7243    0.6970       243\n",
      "           1     0.7185    0.6654    0.6909       257\n",
      "\n",
      "    accuracy                         0.6940       500\n",
      "   macro avg     0.6951    0.6948    0.6940       500\n",
      "weighted avg     0.6958    0.6940    0.6939       500\n",
      "\n",
      "Evaluating model 64k_lstm_clean_finetuned on word_score_no_ws\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "500it [47:36,  5.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5697    0.5885    0.5789       243\n",
      "           1     0.5984    0.5798    0.5889       257\n",
      "\n",
      "    accuracy                         0.5840       500\n",
      "   macro avg     0.5841    0.5841    0.5839       500\n",
      "weighted avg     0.5845    0.5840    0.5841       500\n",
      "\n",
      "Evaluating model 64k_lstm_clean_finetuned on word_score_incl_ws\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "500it [46:00,  5.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5512    0.5761    0.5634       243\n",
      "           1     0.5813    0.5564    0.5686       257\n",
      "\n",
      "    accuracy                         0.5660       500\n",
      "   macro avg     0.5662    0.5663    0.5660       500\n",
      "weighted avg     0.5667    0.5660    0.5661       500\n",
      "\n",
      "Evaluating model 64k_lstm_no_whitespace_pert_finetuned on clean\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:20<00:00,  1.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8514    0.8724    0.8618       243\n",
      "           1     0.8765    0.8560    0.8661       257\n",
      "\n",
      "    accuracy                         0.8640       500\n",
      "   macro avg     0.8639    0.8642    0.8640       500\n",
      "weighted avg     0.8643    0.8640    0.8640       500\n",
      "\n",
      "Evaluating model 64k_lstm_no_whitespace_pert_finetuned on stochastic_no_ws\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [03:20<00:00, 20.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7984    0.8313    0.8145       243\n",
      "           1     0.8340    0.8016    0.8175       257\n",
      "\n",
      "    accuracy                         0.8160       500\n",
      "   macro avg     0.8162    0.8164    0.8160       500\n",
      "weighted avg     0.8167    0.8160    0.8160       500\n",
      "\n",
      "Evaluating model 64k_lstm_no_whitespace_pert_finetuned on stochastic_incl_ws\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [03:20<00:00, 20.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7016    0.7449    0.7226       243\n",
      "           1     0.7438    0.7004    0.7214       257\n",
      "\n",
      "    accuracy                         0.7220       500\n",
      "   macro avg     0.7227    0.7226    0.7220       500\n",
      "weighted avg     0.7233    0.7220    0.7220       500\n",
      "\n",
      "Evaluating model 64k_lstm_no_whitespace_pert_finetuned on word_score_no_ws\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "500it [52:02,  6.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7447    0.7202    0.7322       243\n",
      "           1     0.7434    0.7665    0.7548       257\n",
      "\n",
      "    accuracy                         0.7440       500\n",
      "   macro avg     0.7440    0.7434    0.7435       500\n",
      "weighted avg     0.7440    0.7440    0.7438       500\n",
      "\n",
      "Evaluating model 64k_lstm_no_whitespace_pert_finetuned on word_score_incl_ws\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "500it [50:17,  6.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6694    0.6667    0.6680       243\n",
      "           1     0.6860    0.6887    0.6874       257\n",
      "\n",
      "    accuracy                         0.6780       500\n",
      "   macro avg     0.6777    0.6777    0.6777       500\n",
      "weighted avg     0.6780    0.6780    0.6780       500\n",
      "\n",
      "Evaluating model 64k_lstm_all_pert_finetuned on clean\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:20<00:00,  1.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8601    0.8601    0.8601       243\n",
      "           1     0.8677    0.8677    0.8677       257\n",
      "\n",
      "    accuracy                         0.8640       500\n",
      "   macro avg     0.8639    0.8639    0.8639       500\n",
      "weighted avg     0.8640    0.8640    0.8640       500\n",
      "\n",
      "Evaluating model 64k_lstm_all_pert_finetuned on stochastic_no_ws\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [03:21<00:00, 20.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7912    0.8107    0.8008       243\n",
      "           1     0.8167    0.7977    0.8071       257\n",
      "\n",
      "    accuracy                         0.8040       500\n",
      "   macro avg     0.8039    0.8042    0.8039       500\n",
      "weighted avg     0.8043    0.8040    0.8040       500\n",
      "\n",
      "Evaluating model 64k_lstm_all_pert_finetuned on stochastic_incl_ws\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [03:23<00:00, 20.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7765    0.8148    0.7952       243\n",
      "           1     0.8163    0.7782    0.7968       257\n",
      "\n",
      "    accuracy                         0.7960       500\n",
      "   macro avg     0.7964    0.7965    0.7960       500\n",
      "weighted avg     0.7970    0.7960    0.7960       500\n",
      "\n",
      "Evaluating model 64k_lstm_all_pert_finetuned on word_score_no_ws\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "500it [50:25,  6.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6815    0.6955    0.6884       243\n",
      "           1     0.7063    0.6926    0.6994       257\n",
      "\n",
      "    accuracy                         0.6940       500\n",
      "   macro avg     0.6939    0.6940    0.6939       500\n",
      "weighted avg     0.6942    0.6940    0.6941       500\n",
      "\n",
      "Evaluating model 64k_lstm_all_pert_finetuned on word_score_incl_ws\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "500it [50:29,  6.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6875    0.6790    0.6832       243\n",
      "           1     0.7000    0.7082    0.7041       257\n",
      "\n",
      "    accuracy                         0.6940       500\n",
      "   macro avg     0.6937    0.6936    0.6936       500\n",
      "weighted avg     0.6939    0.6940    0.6939       500\n",
      "\n",
      "Evaluating model 64k_cnn_no_whitespace_pert_finetuned on clean\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:17<00:00,  1.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8333    0.0206    0.0402       243\n",
      "           1     0.5182    0.9961    0.6818       257\n",
      "\n",
      "    accuracy                         0.5220       500\n",
      "   macro avg     0.6758    0.5083    0.3610       500\n",
      "weighted avg     0.6714    0.5220    0.3699       500\n",
      "\n",
      "Evaluating model 64k_cnn_no_whitespace_pert_finetuned on stochastic_no_ws\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [02:55<00:00, 17.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.3333    0.0123    0.0238       243\n",
      "           1     0.5112    0.9767    0.6711       257\n",
      "\n",
      "    accuracy                         0.5080       500\n",
      "   macro avg     0.4223    0.4945    0.3475       500\n",
      "weighted avg     0.4248    0.5080    0.3565       500\n",
      "\n",
      "Evaluating model 64k_cnn_no_whitespace_pert_finetuned on stochastic_incl_ws\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [02:56<00:00, 17.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.1333    0.0082    0.0155       243\n",
      "           1     0.5031    0.9494    0.6577       257\n",
      "\n",
      "    accuracy                         0.4920       500\n",
      "   macro avg     0.3182    0.4788    0.3366       500\n",
      "weighted avg     0.3234    0.4920    0.3456       500\n",
      "\n",
      "Evaluating model 64k_cnn_no_whitespace_pert_finetuned on word_score_no_ws\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "500it [09:23,  1.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.1667    0.0041    0.0080       243\n",
      "           1     0.5101    0.9805    0.6711       257\n",
      "\n",
      "    accuracy                         0.5060       500\n",
      "   macro avg     0.3384    0.4923    0.3396       500\n",
      "weighted avg     0.3432    0.5060    0.3489       500\n",
      "\n",
      "Evaluating model 64k_cnn_no_whitespace_pert_finetuned on word_score_incl_ws\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "500it [08:58,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.1000    0.0041    0.0079       243\n",
      "           1     0.5061    0.9650    0.6640       257\n",
      "\n",
      "    accuracy                         0.4980       500\n",
      "   macro avg     0.3031    0.4845    0.3359       500\n",
      "weighted avg     0.3087    0.4980    0.3451       500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy_df = pd.DataFrame(columns=evaluations, index=all_models.keys())\n",
    "f1_df = pd.DataFrame(columns=evaluations, index=all_models.keys())\n",
    "\n",
    "for cur_model_name, cur_model in all_models.items():\n",
    "    for cur_evaluation in evaluations:\n",
    "        print(f'Evaluating model {cur_model_name} on {cur_evaluation}')\n",
    "        random.seed(11)\n",
    "        if cur_evaluation == 'clean':\n",
    "            acc, f1 = evaluate_model(cur_model, sampled_test_set)\n",
    "        elif cur_evaluation.startswith('stochastic_'):\n",
    "            if cur_evaluation == 'stochastic_no_ws':\n",
    "                acc_list, f1_list = evaluate_model_adv(cur_model, sampled_test_set_adv_no_ws)\n",
    "            elif cur_evaluation == 'stochastic_incl_ws':\n",
    "                acc_list, f1_list = evaluate_model_adv(cur_model, sampled_test_set_adv_incl_ws)\n",
    "            acc = acc_list[-1]\n",
    "            f1 = f1_list[-1]\n",
    "            with open(f\"../output/eval/{cur_model_name}_{cur_evaluation}_acc_list.json\", \"w\") as f:\n",
    "                json.dump(acc_list, fp=f)\n",
    "            with open(f\"../output/eval/{cur_model_name}_{cur_evaluation}_f1_list.json\", \"w\") as f:\n",
    "                json.dump(f1_list, fp=f)\n",
    "        elif cur_evaluation.startswith('word_score_'):\n",
    "            if cur_evaluation == 'word_score_no_ws':\n",
    "                acc, f1 = evaluate_model_word_score(cur_model, sampled_test_set, allow_whitespace_pert=False,\n",
    "                                                    report_prefix=f\"../output/eval/{cur_model_name}_{cur_evaluation}\")\n",
    "            elif cur_evaluation == 'word_score_incl_ws':\n",
    "                acc, f1 = evaluate_model_word_score(cur_model, sampled_test_set, allow_whitespace_pert=True,\n",
    "                                                    report_prefix=f\"../output/eval/{cur_model_name}_{cur_evaluation}\")\n",
    "\n",
    "        accuracy_df[cur_evaluation][cur_model_name] = acc\n",
    "        f1_df[cur_evaluation][cur_model_name] = f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6e229c55",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T06:54:04.661149Z",
     "iopub.status.busy": "2022-04-02T06:54:04.660552Z",
     "iopub.status.idle": "2022-04-02T06:54:04.670551Z",
     "shell.execute_reply": "2022-04-02T06:54:04.670977Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean</th>\n",
       "      <th>stochastic_no_ws</th>\n",
       "      <th>stochastic_incl_ws</th>\n",
       "      <th>word_score_no_ws</th>\n",
       "      <th>word_score_incl_ws</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>baseline</th>\n",
       "      <td>0.88</td>\n",
       "      <td>0.722</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.606</td>\n",
       "      <td>0.604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roben_1</th>\n",
       "      <td>0.794</td>\n",
       "      <td>0.686</td>\n",
       "      <td>0.572</td>\n",
       "      <td>0.656</td>\n",
       "      <td>0.554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roben_2</th>\n",
       "      <td>0.818</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.584</td>\n",
       "      <td>0.718</td>\n",
       "      <td>0.596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roben_1_tok</th>\n",
       "      <td>0.794</td>\n",
       "      <td>0.686</td>\n",
       "      <td>0.572</td>\n",
       "      <td>0.656</td>\n",
       "      <td>0.554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roben_2_tok</th>\n",
       "      <td>0.786</td>\n",
       "      <td>0.684</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.728</td>\n",
       "      <td>0.604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64k_lstm_clean_vanilla</th>\n",
       "      <td>0.864</td>\n",
       "      <td>0.708</td>\n",
       "      <td>0.662</td>\n",
       "      <td>0.596</td>\n",
       "      <td>0.556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64k_lstm_no_whitespace_pert_vanilla</th>\n",
       "      <td>0.872</td>\n",
       "      <td>0.812</td>\n",
       "      <td>0.712</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64k_lstm_all_pert_vanilla</th>\n",
       "      <td>0.868</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.802</td>\n",
       "      <td>0.702</td>\n",
       "      <td>0.686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64k_lstm_clean_finetuned</th>\n",
       "      <td>0.864</td>\n",
       "      <td>0.724</td>\n",
       "      <td>0.694</td>\n",
       "      <td>0.584</td>\n",
       "      <td>0.566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64k_lstm_no_whitespace_pert_finetuned</th>\n",
       "      <td>0.864</td>\n",
       "      <td>0.816</td>\n",
       "      <td>0.722</td>\n",
       "      <td>0.744</td>\n",
       "      <td>0.678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64k_lstm_all_pert_finetuned</th>\n",
       "      <td>0.864</td>\n",
       "      <td>0.804</td>\n",
       "      <td>0.796</td>\n",
       "      <td>0.694</td>\n",
       "      <td>0.694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64k_cnn_no_whitespace_pert_finetuned</th>\n",
       "      <td>0.522</td>\n",
       "      <td>0.508</td>\n",
       "      <td>0.492</td>\n",
       "      <td>0.506</td>\n",
       "      <td>0.498</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       clean stochastic_no_ws  \\\n",
       "baseline                                0.88            0.722   \n",
       "roben_1                                0.794            0.686   \n",
       "roben_2                                0.818             0.71   \n",
       "roben_1_tok                            0.794            0.686   \n",
       "roben_2_tok                            0.786            0.684   \n",
       "64k_lstm_clean_vanilla                 0.864            0.708   \n",
       "64k_lstm_no_whitespace_pert_vanilla    0.872            0.812   \n",
       "64k_lstm_all_pert_vanilla              0.868             0.81   \n",
       "64k_lstm_clean_finetuned               0.864            0.724   \n",
       "64k_lstm_no_whitespace_pert_finetuned  0.864            0.816   \n",
       "64k_lstm_all_pert_finetuned            0.864            0.804   \n",
       "64k_cnn_no_whitespace_pert_finetuned   0.522            0.508   \n",
       "\n",
       "                                      stochastic_incl_ws word_score_no_ws  \\\n",
       "baseline                                            0.69            0.606   \n",
       "roben_1                                            0.572            0.656   \n",
       "roben_2                                            0.584            0.718   \n",
       "roben_1_tok                                        0.572            0.656   \n",
       "roben_2_tok                                         0.59            0.728   \n",
       "64k_lstm_clean_vanilla                             0.662            0.596   \n",
       "64k_lstm_no_whitespace_pert_vanilla                0.712             0.73   \n",
       "64k_lstm_all_pert_vanilla                          0.802            0.702   \n",
       "64k_lstm_clean_finetuned                           0.694            0.584   \n",
       "64k_lstm_no_whitespace_pert_finetuned              0.722            0.744   \n",
       "64k_lstm_all_pert_finetuned                        0.796            0.694   \n",
       "64k_cnn_no_whitespace_pert_finetuned               0.492            0.506   \n",
       "\n",
       "                                      word_score_incl_ws  \n",
       "baseline                                           0.604  \n",
       "roben_1                                            0.554  \n",
       "roben_2                                            0.596  \n",
       "roben_1_tok                                        0.554  \n",
       "roben_2_tok                                        0.604  \n",
       "64k_lstm_clean_vanilla                             0.556  \n",
       "64k_lstm_no_whitespace_pert_vanilla                0.666  \n",
       "64k_lstm_all_pert_vanilla                          0.686  \n",
       "64k_lstm_clean_finetuned                           0.566  \n",
       "64k_lstm_no_whitespace_pert_finetuned              0.678  \n",
       "64k_lstm_all_pert_finetuned                        0.694  \n",
       "64k_cnn_no_whitespace_pert_finetuned               0.498  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "79f4cd33",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T06:54:04.679070Z",
     "iopub.status.busy": "2022-04-02T06:54:04.678299Z",
     "iopub.status.idle": "2022-04-02T06:54:04.682289Z",
     "shell.execute_reply": "2022-04-02T06:54:04.681738Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean</th>\n",
       "      <th>stochastic_no_ws</th>\n",
       "      <th>stochastic_incl_ws</th>\n",
       "      <th>word_score_no_ws</th>\n",
       "      <th>word_score_incl_ws</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>baseline</th>\n",
       "      <td>0.879906</td>\n",
       "      <td>0.721946</td>\n",
       "      <td>0.689989</td>\n",
       "      <td>0.605961</td>\n",
       "      <td>0.603842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roben_1</th>\n",
       "      <td>0.792002</td>\n",
       "      <td>0.683201</td>\n",
       "      <td>0.568959</td>\n",
       "      <td>0.649123</td>\n",
       "      <td>0.544822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roben_2</th>\n",
       "      <td>0.817104</td>\n",
       "      <td>0.708881</td>\n",
       "      <td>0.582289</td>\n",
       "      <td>0.715486</td>\n",
       "      <td>0.593653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roben_1_tok</th>\n",
       "      <td>0.792002</td>\n",
       "      <td>0.683201</td>\n",
       "      <td>0.568959</td>\n",
       "      <td>0.649123</td>\n",
       "      <td>0.544822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roben_2_tok</th>\n",
       "      <td>0.784092</td>\n",
       "      <td>0.680808</td>\n",
       "      <td>0.587224</td>\n",
       "      <td>0.725026</td>\n",
       "      <td>0.59967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64k_lstm_clean_vanilla</th>\n",
       "      <td>0.863922</td>\n",
       "      <td>0.707981</td>\n",
       "      <td>0.661771</td>\n",
       "      <td>0.595994</td>\n",
       "      <td>0.555886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64k_lstm_no_whitespace_pert_vanilla</th>\n",
       "      <td>0.871926</td>\n",
       "      <td>0.811892</td>\n",
       "      <td>0.711959</td>\n",
       "      <td>0.729523</td>\n",
       "      <td>0.665163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64k_lstm_all_pert_vanilla</th>\n",
       "      <td>0.867788</td>\n",
       "      <td>0.809597</td>\n",
       "      <td>0.801504</td>\n",
       "      <td>0.700176</td>\n",
       "      <td>0.685082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64k_lstm_clean_finetuned</th>\n",
       "      <td>0.863946</td>\n",
       "      <td>0.72396</td>\n",
       "      <td>0.693969</td>\n",
       "      <td>0.58394</td>\n",
       "      <td>0.565984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64k_lstm_no_whitespace_pert_finetuned</th>\n",
       "      <td>0.863965</td>\n",
       "      <td>0.815988</td>\n",
       "      <td>0.721999</td>\n",
       "      <td>0.743503</td>\n",
       "      <td>0.67771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64k_lstm_all_pert_finetuned</th>\n",
       "      <td>0.863893</td>\n",
       "      <td>0.80395</td>\n",
       "      <td>0.795997</td>\n",
       "      <td>0.693901</td>\n",
       "      <td>0.693646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64k_cnn_no_whitespace_pert_finetuned</th>\n",
       "      <td>0.360959</td>\n",
       "      <td>0.347466</td>\n",
       "      <td>0.336593</td>\n",
       "      <td>0.339569</td>\n",
       "      <td>0.335947</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          clean stochastic_no_ws  \\\n",
       "baseline                               0.879906         0.721946   \n",
       "roben_1                                0.792002         0.683201   \n",
       "roben_2                                0.817104         0.708881   \n",
       "roben_1_tok                            0.792002         0.683201   \n",
       "roben_2_tok                            0.784092         0.680808   \n",
       "64k_lstm_clean_vanilla                 0.863922         0.707981   \n",
       "64k_lstm_no_whitespace_pert_vanilla    0.871926         0.811892   \n",
       "64k_lstm_all_pert_vanilla              0.867788         0.809597   \n",
       "64k_lstm_clean_finetuned               0.863946          0.72396   \n",
       "64k_lstm_no_whitespace_pert_finetuned  0.863965         0.815988   \n",
       "64k_lstm_all_pert_finetuned            0.863893          0.80395   \n",
       "64k_cnn_no_whitespace_pert_finetuned   0.360959         0.347466   \n",
       "\n",
       "                                      stochastic_incl_ws word_score_no_ws  \\\n",
       "baseline                                        0.689989         0.605961   \n",
       "roben_1                                         0.568959         0.649123   \n",
       "roben_2                                         0.582289         0.715486   \n",
       "roben_1_tok                                     0.568959         0.649123   \n",
       "roben_2_tok                                     0.587224         0.725026   \n",
       "64k_lstm_clean_vanilla                          0.661771         0.595994   \n",
       "64k_lstm_no_whitespace_pert_vanilla             0.711959         0.729523   \n",
       "64k_lstm_all_pert_vanilla                       0.801504         0.700176   \n",
       "64k_lstm_clean_finetuned                        0.693969          0.58394   \n",
       "64k_lstm_no_whitespace_pert_finetuned           0.721999         0.743503   \n",
       "64k_lstm_all_pert_finetuned                     0.795997         0.693901   \n",
       "64k_cnn_no_whitespace_pert_finetuned            0.336593         0.339569   \n",
       "\n",
       "                                      word_score_incl_ws  \n",
       "baseline                                        0.603842  \n",
       "roben_1                                         0.544822  \n",
       "roben_2                                         0.593653  \n",
       "roben_1_tok                                     0.544822  \n",
       "roben_2_tok                                      0.59967  \n",
       "64k_lstm_clean_vanilla                          0.555886  \n",
       "64k_lstm_no_whitespace_pert_vanilla             0.665163  \n",
       "64k_lstm_all_pert_vanilla                       0.685082  \n",
       "64k_lstm_clean_finetuned                        0.565984  \n",
       "64k_lstm_no_whitespace_pert_finetuned            0.67771  \n",
       "64k_lstm_all_pert_finetuned                     0.693646  \n",
       "64k_cnn_no_whitespace_pert_finetuned            0.335947  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4b227192",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T06:54:04.685935Z",
     "iopub.status.busy": "2022-04-02T06:54:04.685341Z",
     "iopub.status.idle": "2022-04-02T06:54:04.688641Z",
     "shell.execute_reply": "2022-04-02T06:54:04.688199Z"
    }
   },
   "outputs": [],
   "source": [
    "accuracy_df.to_csv(\"../output/grid_accuracy.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "69cb79c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-02T06:54:04.692207Z",
     "iopub.status.busy": "2022-04-02T06:54:04.691668Z",
     "iopub.status.idle": "2022-04-02T06:54:04.695140Z",
     "shell.execute_reply": "2022-04-02T06:54:04.694643Z"
    }
   },
   "outputs": [],
   "source": [
    "f1_df.to_csv(\"../output/grid_f1.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "1a5ecf0bc1e7463aa57845e57880c364": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3aa07c2c223d4bbf8579f0e7ed932ee9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_e4914274579d4a10adea970305d5ccf0",
       "placeholder": "​",
       "style": "IPY_MODEL_e079e7c433d84d548c3913408d9910e4",
       "value": " 4/4 [00:00&lt;00:00, 156.71it/s]"
      }
     },
     "49d528b4c1e040de960a296e3c6cd4fa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_d0730198d69a4293abf38a2a90109c36",
        "IPY_MODEL_cc5b135144e64a6bb2e82f6b47108380",
        "IPY_MODEL_3aa07c2c223d4bbf8579f0e7ed932ee9"
       ],
       "layout": "IPY_MODEL_9e4164566fee4db49c2384166d25cde4"
      }
     },
     "6492cdd47fb54909a18f35f7f1104662": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "9e4164566fee4db49c2384166d25cde4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a889245538f04fc19c19dcc398225668": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "cc5b135144e64a6bb2e82f6b47108380": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_f21749340f8d49a78db8a21f285a5e49",
       "max": 4.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_6492cdd47fb54909a18f35f7f1104662",
       "value": 4.0
      }
     },
     "d0730198d69a4293abf38a2a90109c36": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_1a5ecf0bc1e7463aa57845e57880c364",
       "placeholder": "​",
       "style": "IPY_MODEL_a889245538f04fc19c19dcc398225668",
       "value": "100%"
      }
     },
     "e079e7c433d84d548c3913408d9910e4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "e4914274579d4a10adea970305d5ccf0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f21749340f8d49a78db8a21f285a5e49": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
