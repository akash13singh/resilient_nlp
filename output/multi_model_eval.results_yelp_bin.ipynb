{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "027f446b",
   "metadata": {},
   "source": [
    "# Multi Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67daa863",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T17:37:11.549957Z",
     "iopub.status.busy": "2022-03-31T17:37:11.549161Z",
     "iopub.status.idle": "2022-03-31T17:38:55.687241Z",
     "shell.execute_reply": "2022-03-31T17:38:55.687845Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import copy\n",
    "import cProfile\n",
    "from datasets import load_dataset\n",
    "import itertools\n",
    "import json\n",
    "import math\n",
    "import nltk\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "import time\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer, DataCollatorWithPadding, \\\n",
    "                         AutoModelForSequenceClassification, BertForSequenceClassification, \\\n",
    "                         BertModel, RobertaForSequenceClassification, RobertaModel\n",
    "\n",
    "from resilient_nlp.mini_roben import Clustering, ClusterRepRecoverer, ClusterRecovererWithPassthrough\n",
    "from resilient_nlp.models import BertClassifier\n",
    "from resilient_nlp.perturbers import ToyPerturber, WordScramblerPerturber\n",
    "from runner import ExperimentRunner\n",
    "from word_score_attack import BertWordScoreAttack\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5745bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tasks = ('imdb', 'sst', 'sst_bin', 'yelp_bin', 'yelp_full')\n",
    "#tasks = ('sst_bin', 'yelp_bin', 'yelp_full')\n",
    "tasks = ('yelp_bin',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08b0399e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_types = ('bert', 'roberta')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920f47fc",
   "metadata": {},
   "source": [
    "Config for final evaluation on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4efd0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_set_size = 500\n",
    "use_dev_set = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67326e3",
   "metadata": {},
   "source": [
    "Config for evaluation on dev set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5e1860e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#eval_set_size = 113\n",
    "#use_dev_set = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08d28b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_raw_length = 826\n",
    "preprocess = lambda row: { 'text': row['text'].lower()[:max_raw_length]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c824af5",
   "metadata": {},
   "source": [
    "## IMDb Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0903049b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_test_set = {}\n",
    "sampled_test_set_dict = {}\n",
    "sampled_test_set_adv_no_ws = {}\n",
    "sampled_test_set_adv_incl_ws = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ae7a7c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T17:38:55.696962Z",
     "iopub.status.busy": "2022-03-31T17:38:55.696275Z",
     "iopub.status.idle": "2022-03-31T17:38:57.375270Z",
     "shell.execute_reply": "2022-03-31T17:38:57.375885Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration artemis13fowl--imdb-f63738dec0d5e230\n",
      "Reusing dataset parquet (/home/jasko/.cache/huggingface/datasets/parquet/artemis13fowl--imdb-f63738dec0d5e230/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5a4ce911be24986996b87bd6c727fdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "imdb = load_dataset('artemis13fowl/imdb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9bc64b56",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T17:38:57.393928Z",
     "iopub.status.busy": "2022-03-31T17:38:57.393247Z",
     "iopub.status.idle": "2022-03-31T17:38:57.432347Z",
     "shell.execute_reply": "2022-03-31T17:38:57.432870Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/jasko/.cache/huggingface/datasets/parquet/artemis13fowl--imdb-f63738dec0d5e230/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901/cache-b45d493b37ab1dc7.arrow\n"
     ]
    }
   ],
   "source": [
    "random.seed(11)\n",
    "if use_dev_set:\n",
    "    sampled_test_set['imdb'] = imdb['dev'].select(random.choices(range(len(imdb['dev'])), k=eval_set_size)).map(preprocess)\n",
    "else:\n",
    "    sampled_test_set['imdb'] = imdb['attack_eval_truncated'].select(range(eval_set_size)).map(preprocess)\n",
    "\n",
    "\n",
    "# This is silly but apparently huggingface datasets are immutable?\n",
    "# Representing it as something a bit more sane\n",
    "sampled_test_set_dict['imdb'] = [\n",
    "    {\n",
    "        'text': row['text'],\n",
    "        'label': row['label'],\n",
    "    }\n",
    "    for row in sampled_test_set['imdb']\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34d21ea",
   "metadata": {},
   "source": [
    "## SST-5 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38106401",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No config specified, defaulting to: sst/default\n",
      "Reusing dataset sst (/home/jasko/.cache/huggingface/datasets/sst/default/1.0.0/b8a7889ef01c5d3ae8c379b84cc4080f8aad3ac2bc538701cbe0ac6416fb76ff)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ff845ba7706430d8e80cb33eaeff983",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/jasko/.cache/huggingface/datasets/sst/default/1.0.0/b8a7889ef01c5d3ae8c379b84cc4080f8aad3ac2bc538701cbe0ac6416fb76ff/cache-3c142acdab53f98c.arrow\n",
      "Loading cached processed dataset at /home/jasko/.cache/huggingface/datasets/sst/default/1.0.0/b8a7889ef01c5d3ae8c379b84cc4080f8aad3ac2bc538701cbe0ac6416fb76ff/cache-0bf56ce0086915ee.arrow\n",
      "Loading cached processed dataset at /home/jasko/.cache/huggingface/datasets/sst/default/1.0.0/b8a7889ef01c5d3ae8c379b84cc4080f8aad3ac2bc538701cbe0ac6416fb76ff/cache-19fdf8d124be4ba7.arrow\n",
      "Loading cached processed dataset at /home/jasko/.cache/huggingface/datasets/sst/default/1.0.0/b8a7889ef01c5d3ae8c379b84cc4080f8aad3ac2bc538701cbe0ac6416fb76ff/cache-fc3e75429c3f7637.arrow\n"
     ]
    }
   ],
   "source": [
    "treebank_detok = TreebankWordDetokenizer()\n",
    "\n",
    "sst = load_dataset('sst').map(\n",
    "    lambda row: {\n",
    "        \"text\": treebank_detok.detokenize(row[\"sentence\"].split()),\n",
    "        \"label\": min(math.floor(row[\"label\"] / 0.2), 4.0),\n",
    "    }, remove_columns=['sentence', 'tokens', 'tree']\n",
    ")\n",
    "\n",
    "random.seed(11)\n",
    "if use_dev_set:\n",
    "    sampled_test_set['sst'] = sst['validation'].select(random.choices(range(len(sst['validation'])), k=eval_set_size)).map(preprocess)\n",
    "else:\n",
    "    sampled_test_set['sst'] = sst['test'].select(random.choices(range(len(sst['test'])), k=eval_set_size)).map(preprocess)\n",
    "\n",
    "sampled_test_set_dict['sst'] = [\n",
    "    {\n",
    "        'text': row['text'],\n",
    "        'label': row['label'],\n",
    "    }\n",
    "    for row in sampled_test_set['sst']\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3bae186",
   "metadata": {},
   "source": [
    "## SST-2 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f1e5046",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No config specified, defaulting to: sst/default\n",
      "Reusing dataset sst (/home/jasko/.cache/huggingface/datasets/sst/default/1.0.0/b8a7889ef01c5d3ae8c379b84cc4080f8aad3ac2bc538701cbe0ac6416fb76ff)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc0a2fb5e5a3441581d56f80c17613c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/jasko/.cache/huggingface/datasets/sst/default/1.0.0/b8a7889ef01c5d3ae8c379b84cc4080f8aad3ac2bc538701cbe0ac6416fb76ff/cache-f4f1ada73617d193.arrow\n",
      "Loading cached processed dataset at /home/jasko/.cache/huggingface/datasets/sst/default/1.0.0/b8a7889ef01c5d3ae8c379b84cc4080f8aad3ac2bc538701cbe0ac6416fb76ff/cache-6279b6f0f8a08f9a.arrow\n",
      "Loading cached processed dataset at /home/jasko/.cache/huggingface/datasets/sst/default/1.0.0/b8a7889ef01c5d3ae8c379b84cc4080f8aad3ac2bc538701cbe0ac6416fb76ff/cache-6c5f77e5aefdd0e2.arrow\n",
      "Loading cached processed dataset at /home/jasko/.cache/huggingface/datasets/sst/default/1.0.0/b8a7889ef01c5d3ae8c379b84cc4080f8aad3ac2bc538701cbe0ac6416fb76ff/cache-c46f07c913633b4d.arrow\n",
      "Loading cached processed dataset at /home/jasko/.cache/huggingface/datasets/sst/default/1.0.0/b8a7889ef01c5d3ae8c379b84cc4080f8aad3ac2bc538701cbe0ac6416fb76ff/cache-87779081ead23eae.arrow\n",
      "Loading cached processed dataset at /home/jasko/.cache/huggingface/datasets/sst/default/1.0.0/b8a7889ef01c5d3ae8c379b84cc4080f8aad3ac2bc538701cbe0ac6416fb76ff/cache-7813af5c6a05de02.arrow\n",
      "Loading cached processed dataset at /home/jasko/.cache/huggingface/datasets/sst/default/1.0.0/b8a7889ef01c5d3ae8c379b84cc4080f8aad3ac2bc538701cbe0ac6416fb76ff/cache-8a65da8df1dcb8ac.arrow\n"
     ]
    }
   ],
   "source": [
    "treebank_detok = TreebankWordDetokenizer()\n",
    "\n",
    "sst_bin = load_dataset('sst').filter(\n",
    "        lambda row: row[\"label\"] < 0.4 or row[\"label\"] >= 0.6\n",
    "    ).map(\n",
    "    lambda row: {\n",
    "        \"text\": treebank_detok.detokenize(row[\"sentence\"].split()),\n",
    "        \"label\": min(math.floor(row[\"label\"] / 0.5), 1.0),\n",
    "    }\n",
    ")\n",
    "\n",
    "random.seed(11)\n",
    "if use_dev_set:\n",
    "    sampled_test_set['sst_bin'] = sst_bin['validation'].select(random.choices(range(len(sst_bin['validation'])), k=eval_set_size)).map(preprocess)\n",
    "else:\n",
    "    sampled_test_set['sst_bin'] = sst_bin['test'].select(random.choices(range(len(sst_bin['test'])), k=eval_set_size)).map(preprocess)\n",
    "\n",
    "sampled_test_set_dict['sst_bin'] = [\n",
    "    {\n",
    "        'text': row['text'],\n",
    "        'label': row['label'],\n",
    "    }\n",
    "    for row in sampled_test_set['sst_bin']\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b096c3f",
   "metadata": {},
   "source": [
    "## Yelp-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ccfe1b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset yelp_polarity (/home/jasko/.cache/huggingface/datasets/yelp_polarity/plain_text/1.0.0/a770787b2526bdcbfc29ac2d9beb8e820fbc15a03afd3ebc4fb9d8529de57544)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cea5438caaba49fdb017992a67b34640",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/jasko/.cache/huggingface/datasets/yelp_polarity/plain_text/1.0.0/a770787b2526bdcbfc29ac2d9beb8e820fbc15a03afd3ebc4fb9d8529de57544/cache-103b3f679d53323c.arrow\n"
     ]
    }
   ],
   "source": [
    "yelp_bin = load_dataset('yelp_polarity')\n",
    "\n",
    "random.seed(11)\n",
    "sampled_test_set['yelp_bin'] = yelp_bin['test'].select(random.choices(range(len(sst['test'])), k=eval_set_size)).map(preprocess)\n",
    "\n",
    "sampled_test_set_dict['yelp_bin'] = [\n",
    "    {\n",
    "        'text': row['text'],\n",
    "        'label': row['label'],\n",
    "    }\n",
    "    for row in sampled_test_set['yelp_bin']\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f2fc43",
   "metadata": {},
   "source": [
    "## Yelp-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "92deac75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset yelp_polarity (/home/jasko/.cache/huggingface/datasets/yelp_polarity/plain_text/1.0.0/a770787b2526bdcbfc29ac2d9beb8e820fbc15a03afd3ebc4fb9d8529de57544)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afd4c42122224e96a0206d4f9ad6c1c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/jasko/.cache/huggingface/datasets/yelp_polarity/plain_text/1.0.0/a770787b2526bdcbfc29ac2d9beb8e820fbc15a03afd3ebc4fb9d8529de57544/cache-103b3f679d53323c.arrow\n"
     ]
    }
   ],
   "source": [
    "yelp_full = load_dataset('yelp_polarity')\n",
    "\n",
    "random.seed(11)\n",
    "sampled_test_set['yelp_full'] = yelp_bin['test'].select(random.choices(range(len(sst['test'])), k=eval_set_size)).map(preprocess)\n",
    "\n",
    "sampled_test_set_dict['yelp_full'] = [\n",
    "    {\n",
    "        'text': row['text'],\n",
    "        'label': row['label'],\n",
    "    }\n",
    "    for row in sampled_test_set['yelp_full']\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5ec74a",
   "metadata": {},
   "source": [
    "### Perturbations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cb0dab9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_perturbed_multiset(input, wsp):\n",
    "    random.seed(11)\n",
    "    result = []\n",
    "\n",
    "    for i in range(10):\n",
    "        test_item = copy.deepcopy(input)\n",
    "\n",
    "        for row in test_item:\n",
    "            row['text'] = wsp.perturb([row['text']])[0][0]\n",
    "        result.append(test_item)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf674fa6",
   "metadata": {},
   "source": [
    "Perturbed set with no whitespace modifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8712401f",
   "metadata": {},
   "outputs": [],
   "source": [
    "wsp = WordScramblerPerturber(perturb_prob=0.1, weight_add=1, weight_drop=1, weight_swap=1,\n",
    "                             weight_split_word=0, weight_merge_words=0)\n",
    "\n",
    "for task in tasks:\n",
    "    sampled_test_set_adv_no_ws[task] = generate_perturbed_multiset(sampled_test_set_dict[task], wsp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc4acd0",
   "metadata": {},
   "source": [
    "Perturbed set with whitespace modifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "72861511",
   "metadata": {},
   "outputs": [],
   "source": [
    "wsp = WordScramblerPerturber(perturb_prob=0.1, weight_add=1, weight_drop=1, weight_swap=1,\n",
    "                             weight_split_word=1, weight_merge_words=1)\n",
    "\n",
    "for task in tasks:\n",
    "    sampled_test_set_adv_incl_ws[task] = generate_perturbed_multiset(sampled_test_set_dict[task], wsp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6454c2",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370b1cdb",
   "metadata": {},
   "source": [
    "### BERT, including finetuned variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3573bce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = {}\n",
    "model_base = {}\n",
    "model_finetuned = { type: {} for type in model_types }\n",
    "model_finetuned_all_pert = { type: {} for type in model_types }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "17700b9e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T17:38:57.438989Z",
     "iopub.status.busy": "2022-03-31T17:38:57.436437Z",
     "iopub.status.idle": "2022-03-31T17:38:58.316850Z",
     "shell.execute_reply": "2022-03-31T17:38:58.316245Z"
    }
   },
   "outputs": [],
   "source": [
    "bert_checkpoint = \"bert-base-uncased\"\n",
    "tokenizer['bert'] = AutoTokenizer.from_pretrained(bert_checkpoint)\n",
    "model_base['bert'] = BertModel.from_pretrained(bert_checkpoint).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a09ce62d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T17:38:58.323968Z",
     "iopub.status.busy": "2022-03-31T17:38:58.321059Z",
     "iopub.status.idle": "2022-03-31T17:41:02.742864Z",
     "shell.execute_reply": "2022-03-31T17:41:02.743367Z"
    }
   },
   "outputs": [],
   "source": [
    "bert_checkpoint_finetuned_imdb = \"artemis13fowl/bert-base-uncased-imdb\"\n",
    "if 'bert' in model_types and 'imdb' in tasks:\n",
    "    model_finetuned['bert']['imdb'] = BertForSequenceClassification.from_pretrained(bert_checkpoint_finetuned_imdb).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e0bc679c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_checkpoint_finetuned_imdb_all_pert = \"jjezabek/bert-base-uncased-imdb-all-pert\"\n",
    "if 'bert' in model_types and 'imdb' in tasks:\n",
    "    model_finetuned_all_pert['bert']['imdb'] = BertForSequenceClassification.from_pretrained(bert_checkpoint_finetuned_imdb_all_pert).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2454c4ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T17:38:58.323968Z",
     "iopub.status.busy": "2022-03-31T17:38:58.321059Z",
     "iopub.status.idle": "2022-03-31T17:41:02.742864Z",
     "shell.execute_reply": "2022-03-31T17:41:02.743367Z"
    }
   },
   "outputs": [],
   "source": [
    "bert_checkpoint_finetuned_sst = \"jjezabek/bert-base-uncased-sst\"\n",
    "if 'bert' in model_types and 'sst' in tasks:\n",
    "    model_finetuned['bert']['sst'] = BertForSequenceClassification.from_pretrained(bert_checkpoint_finetuned_sst).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "af9a1b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_checkpoint_finetuned_sst_bin = '/home/jasko/resilient_nlp/output/bert-base-uncased-sst_bin/checkpoint-800'\n",
    "if 'bert' in model_types and 'sst_bin' in tasks:\n",
    "    model_finetuned['bert']['sst_bin'] = BertForSequenceClassification.from_pretrained(bert_checkpoint_finetuned_sst_bin).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a6c66b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_checkpoint_finetuned_yelp_bin = '/home/jasko/resilient_nlp/output/bert-base-uncased-yelp_bin/checkpoint-3500'\n",
    "if 'bert' in model_types and 'yelp_bin' in tasks:\n",
    "    model_finetuned['bert']['yelp_bin'] = BertForSequenceClassification.from_pretrained(bert_checkpoint_finetuned_yelp_bin).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ad769b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_checkpoint_finetuned_yelp_full = '/home/jasko/resilient_nlp/output/bert-base-uncased-yelp_full/checkpoint-1500'\n",
    "if 'bert' in model_types and 'yelp_full' in tasks:\n",
    "    model_finetuned['bert']['yelp_full'] = BertForSequenceClassification.from_pretrained(bert_checkpoint_finetuned_yelp_full).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "084978a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T17:38:57.438989Z",
     "iopub.status.busy": "2022-03-31T17:38:57.436437Z",
     "iopub.status.idle": "2022-03-31T17:38:58.316850Z",
     "shell.execute_reply": "2022-03-31T17:38:58.316245Z"
    }
   },
   "outputs": [],
   "source": [
    "roberta_checkpoint = \"roberta-base\"\n",
    "tokenizer['roberta'] = AutoTokenizer.from_pretrained(roberta_checkpoint)\n",
    "model_base['roberta'] = RobertaModel.from_pretrained(roberta_checkpoint).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6a93a042",
   "metadata": {},
   "outputs": [],
   "source": [
    "roberta_checkpoint_finetuned_imdb = \"jjezabek/roberta-base-imdb\"\n",
    "if 'roberta' in model_types and 'imdb' in tasks:\n",
    "    model_finetuned['roberta']['imdb'] = RobertaForSequenceClassification.from_pretrained(roberta_checkpoint_finetuned_imdb).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8ae40370",
   "metadata": {},
   "outputs": [],
   "source": [
    "roberta_checkpoint_finetuned_sst = '/home/jasko/resilient_nlp/output/roberta-base-sst/checkpoint-900'\n",
    "if 'roberta' in model_types and 'sst' in tasks:\n",
    "    model_finetuned['roberta']['sst'] = RobertaForSequenceClassification.from_pretrained(roberta_checkpoint_finetuned_sst).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dfd9fc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "roberta_checkpoint_finetuned_sst_bin = '/home/jasko/resilient_nlp/output/roberta-base-sst_bin/checkpoint-700'\n",
    "if 'roberta' in model_types and 'sst_bin' in tasks:\n",
    "    model_finetuned['roberta']['sst_bin'] = RobertaForSequenceClassification.from_pretrained(roberta_checkpoint_finetuned_sst_bin).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "328428ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "roberta_checkpoint_finetuned_yelp_bin = '/home/jasko/resilient_nlp/output/roberta-base-yelp_bin/checkpoint-2200'\n",
    "if 'roberta' in model_types and 'yelp_bin' in tasks:\n",
    "    model_finetuned['roberta']['yelp_bin'] = RobertaForSequenceClassification.from_pretrained(roberta_checkpoint_finetuned_yelp_bin).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bb218742",
   "metadata": {},
   "outputs": [],
   "source": [
    "roberta_checkpoint_finetuned_yelp_full = '/home/jasko/resilient_nlp/output/roberta-base-yelp_full/checkpoint-7500'\n",
    "if 'roberta' in model_types and 'yelp_full' in tasks:\n",
    "    model_finetuned['roberta']['yelp_full'] = RobertaForSequenceClassification.from_pretrained(roberta_checkpoint_finetuned_yelp_full).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63dab18",
   "metadata": {},
   "source": [
    "### RobEn clusterings (as baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5758ab39",
   "metadata": {},
   "source": [
    "The first clustering is ConnComp (which very aggressively merges clusters). The second is AggClust, which uses a cost function to better preserve fidelity. The second one should generally be better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8b3c3fb8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T17:41:02.748232Z",
     "iopub.status.busy": "2022-03-31T17:41:02.747612Z",
     "iopub.status.idle": "2022-03-31T17:43:45.925467Z",
     "shell.execute_reply": "2022-03-31T17:43:45.924906Z"
    }
   },
   "outputs": [],
   "source": [
    "roben_clustering = Clustering.from_pickle(\"../vocab100000_ed1.pkl\")\n",
    "roben_recoverer = ClusterRecovererWithPassthrough(\"cache\", roben_clustering)\n",
    "roben_clustering2 = Clustering.from_pickle(\"../vocab100000_ed1_gamma0.3.pkl\")\n",
    "roben_recoverer2 = ClusterRecovererWithPassthrough(\"cache\", roben_clustering2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17aaf07",
   "metadata": {},
   "source": [
    "## Model Prediction Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a2efe10f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T17:43:49.085047Z",
     "iopub.status.busy": "2022-03-31T17:43:49.084381Z",
     "iopub.status.idle": "2022-03-31T17:43:49.087081Z",
     "shell.execute_reply": "2022-03-31T17:43:49.086570Z"
    }
   },
   "outputs": [],
   "source": [
    "max_sequence_length = 128\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cebe273",
   "metadata": {},
   "source": [
    "These are wrappers for standard (possibly finetuned) Huggingface models, using their normal tokenizers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7b958a5c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T17:43:49.094914Z",
     "iopub.status.busy": "2022-03-31T17:43:49.094323Z",
     "iopub.status.idle": "2022-03-31T17:43:49.096390Z",
     "shell.execute_reply": "2022-03-31T17:43:49.096869Z"
    }
   },
   "outputs": [],
   "source": [
    "def standard_model_predict(tokenizer, model, sentences, recoverer, return_pred_tensor, recoverer_tokenize):\n",
    "    if recoverer is not None:\n",
    "        if recoverer_tokenize:\n",
    "            tok = nltk.tokenize.treebank.TreebankWordTokenizer()\n",
    "            sentences = [ \" \".join(tok_list) for tok_list in tok.tokenize_sents(sentences) ]\n",
    "        sentences = [ recoverer.recover(s.lower()) for s in sentences ]\n",
    "        if recoverer_tokenize:\n",
    "            detok = nltk.tokenize.treebank.TreebankWordDetokenizer()\n",
    "            sentences = [ detok.detokenize(s.split(\" \")) for s in sentences]\n",
    "    tokenized = tokenizer(sentences, truncation=True, padding='max_length', max_length=max_sequence_length,\n",
    "                          return_tensors='pt')\n",
    "    tokenized = { k: v.to(device) for k, v in tokenized.items() }\n",
    "    preds = model(**tokenized)\n",
    "    if return_pred_tensor:\n",
    "        return preds\n",
    "    else:\n",
    "        return torch.argmax(preds.logits, dim=1)\n",
    "\n",
    "def wrap_standard_model(tokenizer, model, recoverer=None, return_pred_tensor=True, recoverer_tokenize=False):\n",
    "    return lambda sentences: standard_model_predict(tokenizer, model, sentences, recoverer, return_pred_tensor,\n",
    "                                                    recoverer_tokenize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3cfccf9",
   "metadata": {},
   "source": [
    "This is a wrapper for the machine trained tokenizer+embedder (aka MockingBERT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0ba7bb36",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T17:43:49.104843Z",
     "iopub.status.busy": "2022-03-31T17:43:49.104249Z",
     "iopub.status.idle": "2022-03-31T17:43:49.106973Z",
     "shell.execute_reply": "2022-03-31T17:43:49.107449Z"
    }
   },
   "outputs": [],
   "source": [
    "def mltokenizer_model_predict(runner, model, cls_embedding, sep_embedding, pad_embedding, sentences, return_pred_tensor):\n",
    "    # Truncate and lower case. Truncation is for performance only\n",
    "    sentences = [ s.lower()[:8*max_sequence_length] for s in sentences]\n",
    "    embedding = runner.embed(sentences=sentences,\n",
    "        start_token=cls_embedding, end_token=sep_embedding, pad_token=pad_embedding,\n",
    "        max_tokens=max_sequence_length)\n",
    "    preds = model(inputs_embeds=embedding['inputs_embeds'], attention_mask=embedding['attention_mask'])\n",
    "    if return_pred_tensor:\n",
    "        return preds\n",
    "    else:\n",
    "        return torch.argmax(preds.logits, dim=1)\n",
    "\n",
    "def wrap_mltokenizer_model(mltokenizer_prefix, tokenizer, model, cf_embedding, type, return_pred_tensor=True):\n",
    "    filename = \"../{}.pth\".format(mltokenizer_prefix)\n",
    "    runner = ExperimentRunner(device, model_filename=filename)\n",
    "    if type == 'bert':\n",
    "        cls_token_id = tokenizer.vocab['[CLS]']\n",
    "        sep_token_id = tokenizer.vocab['[SEP]']\n",
    "        pad_token_id = tokenizer.vocab['[PAD]']\n",
    "    elif type == 'roberta':\n",
    "        cls_token_id = tokenizer.vocab['<s>']\n",
    "        sep_token_id = tokenizer.vocab['</s>']\n",
    "        pad_token_id = tokenizer.vocab['<pad>']\n",
    "    cls_embedding = cf_embedding(torch.tensor([cls_token_id], device=device)).view(-1)\n",
    "    sep_embedding = cf_embedding(torch.tensor([sep_token_id], device=device)).view(-1)\n",
    "    pad_embedding = cf_embedding(torch.tensor([pad_token_id], device=device)).view(-1)\n",
    "    \n",
    "    return lambda sentences: mltokenizer_model_predict(runner, model, cls_embedding, sep_embedding,\n",
    "                                                      pad_embedding, sentences, return_pred_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1da87ea",
   "metadata": {},
   "source": [
    "## Evaluation Helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a4b8cf",
   "metadata": {},
   "source": [
    "Evaluates a wrapped model on a test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2033ec30",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T17:43:49.113921Z",
     "iopub.status.busy": "2022-03-31T17:43:49.113314Z",
     "iopub.status.idle": "2022-03-31T17:43:49.115410Z",
     "shell.execute_reply": "2022-03-31T17:43:49.115943Z"
    }
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate_model(model, test_set):\n",
    "    num_batches = math.ceil(len(test_set) / batch_size)\n",
    "    \n",
    "    sentences = [ x['text'] for x in test_set ]\n",
    "    labels = [ x['label'] for x in test_set ]\n",
    "    pred_batches = []\n",
    "    \n",
    "    for i in tqdm(range(num_batches)):\n",
    "        bs = i * batch_size\n",
    "        be = bs + batch_size\n",
    "        \n",
    "        output = model(sentences[bs:be])\n",
    "        \n",
    "        pred_batches.append(torch.argmax(output.logits, dim=1).detach().cpu())\n",
    "    preds = torch.cat(pred_batches)\n",
    "    \n",
    "    print(classification_report(labels, preds, digits=4))\n",
    "    \n",
    "    accuracy = accuracy_score(labels, preds)\n",
    "    f1 = f1_score(labels, preds, average='macro')\n",
    "    \n",
    "    return accuracy, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac39aaf",
   "metadata": {},
   "source": [
    "Evaluates a wrapped model on a stochastic, pseudo-adversarial test set. This means that each input sentence is replicated x times (typically 10) with randomized perturbations, and an attack is considered successful if *any* of the predictions is incorrect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "33c8259a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T17:43:49.124562Z",
     "iopub.status.busy": "2022-03-31T17:43:49.123971Z",
     "iopub.status.idle": "2022-03-31T17:43:49.125916Z",
     "shell.execute_reply": "2022-03-31T17:43:49.126467Z"
    }
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate_model_adv(model, test_sets):\n",
    "    labels = [ x['label'] for x in test_sets[0] ]\n",
    "    adv_preds = copy.copy(labels)\n",
    "    accuracy_list = []\n",
    "    f1_list = []\n",
    "    \n",
    "    for idx in tqdm(range(len(test_sets))):\n",
    "        test_set = test_sets[idx]\n",
    "        num_batches = math.ceil(len(test_set) / batch_size)\n",
    "    \n",
    "        sentences = [ x['text'] for x in test_set ]\n",
    "        pred_batches = []\n",
    "    \n",
    "        for i in range(num_batches):\n",
    "            bs = i * batch_size\n",
    "            be = bs + batch_size\n",
    "        \n",
    "            output = model(sentences[bs:be])\n",
    "        \n",
    "            pred_batches.append(torch.argmax(output.logits, dim=1).detach().cpu())\n",
    "        preds = torch.cat(pred_batches)\n",
    "        \n",
    "        for i in range(len(adv_preds)):\n",
    "            if labels[i] != preds[i]:\n",
    "                adv_preds[i] = preds[i]\n",
    "\n",
    "        accuracy_list.append(accuracy_score(labels, adv_preds))\n",
    "        f1_list.append(f1_score(labels, adv_preds, average='macro'))\n",
    "    \n",
    "    print(classification_report(labels, adv_preds, digits=4))    \n",
    "    \n",
    "    return accuracy_list, f1_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1bba12b",
   "metadata": {},
   "source": [
    "Evaluates a model using WordScoreAttack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "26be9ad5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T17:43:49.132768Z",
     "iopub.status.busy": "2022-03-31T17:43:49.132187Z",
     "iopub.status.idle": "2022-03-31T17:43:49.134404Z",
     "shell.execute_reply": "2022-03-31T17:43:49.134865Z"
    }
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate_model_word_score(model, test_set, allow_whitespace_pert=True, report_prefix=None, word_scores_file=None):\n",
    "    attacker = BertWordScoreAttack(\n",
    "        WordScramblerPerturber(perturb_prob=1, weight_add=1, weight_drop=1, weight_swap=1,\n",
    "                               weight_split_word=int(allow_whitespace_pert),\n",
    "                               weight_merge_words=0),\n",
    "        word_scores_file, model, tokenizer=None, max_sequence_length=max_sequence_length,\n",
    "        attack_whitespace=allow_whitespace_pert,\n",
    "    )\n",
    "\n",
    "    res = attacker.attack(test_set, max_tokens_to_perturb=10, max_tries_per_token=4, mode=0, print_summary=False)\n",
    "\n",
    "    if report_prefix is not None:\n",
    "        res.to_csv(f\"{report_prefix}_df.csv\")\n",
    "        with open(f\"{report_prefix}_stats.json\", \"w\") as f:\n",
    "            json.dump(attacker.compute_attack_stats(), fp=f)            \n",
    "    \n",
    "    print(classification_report(res['ground_truth'], res['perturbed_preds'], digits=4))    \n",
    "    \n",
    "    accuracy = accuracy_score(res['ground_truth'], res['perturbed_preds'])\n",
    "    f1 = f1_score(res['ground_truth'], res['perturbed_preds'], average='macro')\n",
    "    \n",
    "    return accuracy, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3b6fcd6e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T17:44:32.712568Z",
     "iopub.status.busy": "2022-03-31T17:44:32.711928Z",
     "iopub.status.idle": "2022-03-31T17:45:57.105422Z",
     "shell.execute_reply": "2022-03-31T17:45:57.104806Z"
    }
   },
   "outputs": [],
   "source": [
    "all_models = {\n",
    "    'baseline': lambda task, type: wrap_standard_model(tokenizer[type], model_finetuned[type][task]),\n",
    "    'baseline_all_pert': lambda task, type: wrap_standard_model(tokenizer[type], model_finetuned_all_pert[type][task]),\n",
    "    'roben_1': lambda task, type: wrap_standard_model(tokenizer[type], model_finetuned[type][task], roben_recoverer),\n",
    "    'roben_2': lambda task, type: wrap_standard_model(tokenizer[type], model_finetuned[type][task], roben_recoverer2),\n",
    "    'roben_1_tok': lambda task, type: wrap_standard_model(tokenizer[type], model_finetuned[type][task], roben_recoverer, recoverer_tokenize=True),\n",
    "    'roben_2_tok': lambda task, type: wrap_standard_model(tokenizer[type], model_finetuned[type][task], roben_recoverer2, recoverer_tokenize=True),\n",
    "}\n",
    "\n",
    "mltok_model_names = [\n",
    "    '64k_lstm_clean_vanilla',\n",
    "    '64k_lstm_no_whitespace_pert_vanilla',\n",
    "    '64k_lstm_all_pert_vanilla',\n",
    "    '64k_lstm_clean_finetuned',\n",
    "    '64k_lstm_no_whitespace_pert_finetuned',\n",
    "    '64k_lstm_all_pert_finetuned',\n",
    "    '64k_cnn_no_whitespace_pert_finetuned',\n",
    "    '2m_lstm_all_pert_finetuned',\n",
    "    '32k_lstm_all_pert_finetuned_100ep',\n",
    "]\n",
    "\n",
    "for name in mltok_model_names:\n",
    "    if name.endswith('_vanilla'):\n",
    "        cf_embedding = lambda task, type: model_base[type].embeddings.word_embeddings\n",
    "        filename = lambda task, type, name: f'output/{type}_{name}'\n",
    "    else:\n",
    "        cf_embedding = lambda task, type: model_finetuned[type][task].base_model.embeddings.word_embeddings\n",
    "        filename = lambda task, type, name: f'output/{type}_{name}_{task}'\n",
    "    # name=name is a hack to avoid Python late binding\n",
    "    all_models[name] = lambda task, type, name=name, filename=filename, cf_embedding=cf_embedding: wrap_mltokenizer_model(filename(task, type, name), tokenizer[type], model_finetuned[type][task], cf_embedding(task, type), type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e61f9273",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T17:45:57.109658Z",
     "iopub.status.busy": "2022-03-31T17:45:57.109097Z",
     "iopub.status.idle": "2022-03-31T17:45:57.111181Z",
     "shell.execute_reply": "2022-03-31T17:45:57.111650Z"
    }
   },
   "outputs": [],
   "source": [
    "evaluations = [\n",
    "    'clean',\n",
    "    'stochastic_no_ws',\n",
    "    'stochastic_incl_ws',\n",
    "    'word_score_no_ws',\n",
    "    'word_score_incl_ws',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "602a9ff8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T17:45:57.146612Z",
     "iopub.status.busy": "2022-03-31T17:45:57.142921Z",
     "iopub.status.idle": "2022-04-01T06:14:51.176862Z",
     "shell.execute_reply": "2022-04-01T06:14:51.177399Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model baseline on bert on clean for task yelp_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:02<00:00,  6.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9511    0.9620    0.9565       263\n",
      "           1     0.9573    0.9451    0.9512       237\n",
      "\n",
      "    accuracy                         0.9540       500\n",
      "   macro avg     0.9542    0.9536    0.9538       500\n",
      "weighted avg     0.9540    0.9540    0.9540       500\n",
      "\n",
      "Evaluation took 2.617372512817383 seconds\n",
      "Evaluating model baseline on bert on stochastic_no_ws for task yelp_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:25<00:00,  2.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8783    0.8783    0.8783       263\n",
      "           1     0.8650    0.8650    0.8650       237\n",
      "\n",
      "    accuracy                         0.8720       500\n",
      "   macro avg     0.8717    0.8717    0.8717       500\n",
      "weighted avg     0.8720    0.8720    0.8720       500\n",
      "\n",
      "Evaluation took 25.811915159225464 seconds\n",
      "Evaluating model baseline on bert on stochastic_incl_ws for task yelp_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:25<00:00,  2.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8556    0.8783    0.8668       263\n",
      "           1     0.8609    0.8354    0.8480       237\n",
      "\n",
      "    accuracy                         0.8580       500\n",
      "   macro avg     0.8582    0.8569    0.8574       500\n",
      "weighted avg     0.8581    0.8580    0.8579       500\n",
      "\n",
      "Evaluation took 25.952208995819092 seconds\n",
      "Evaluating model baseline on bert on word_score_no_ws for task yelp_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [01:34<00:00,  5.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7567    0.7567    0.7567       263\n",
      "           1     0.7300    0.7300    0.7300       237\n",
      "\n",
      "    accuracy                         0.7440       500\n",
      "   macro avg     0.7433    0.7433    0.7433       500\n",
      "weighted avg     0.7440    0.7440    0.7440       500\n",
      "\n",
      "Evaluation took 94.53224587440491 seconds\n",
      "Evaluating model baseline on bert on word_score_incl_ws for task yelp_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [01:34<00:00,  5.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7101    0.7452    0.7273       263\n",
      "           1     0.7009    0.6624    0.6811       237\n",
      "\n",
      "    accuracy                         0.7060       500\n",
      "   macro avg     0.7055    0.7038    0.7042       500\n",
      "weighted avg     0.7058    0.7060    0.7054       500\n",
      "\n",
      "Evaluation took 94.23304080963135 seconds\n",
      "Failed loading model baseline_all_pert on bert for task yelp_bin, skipping\n",
      "Evaluating model roben_1 on bert on clean for task yelp_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:02<00:00,  5.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8493    0.9430    0.8937       263\n",
      "           1     0.9279    0.8143    0.8674       237\n",
      "\n",
      "    accuracy                         0.8820       500\n",
      "   macro avg     0.8886    0.8787    0.8806       500\n",
      "weighted avg     0.8866    0.8820    0.8812       500\n",
      "\n",
      "Evaluation took 2.9076454639434814 seconds\n",
      "Evaluating model roben_1 on bert on stochastic_no_ws for task yelp_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:28<00:00,  2.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7833    0.8935    0.8348       263\n",
      "           1     0.8600    0.7257    0.7872       237\n",
      "\n",
      "    accuracy                         0.8140       500\n",
      "   macro avg     0.8217    0.8096    0.8110       500\n",
      "weighted avg     0.8197    0.8140    0.8122       500\n",
      "\n",
      "Evaluation took 28.50887155532837 seconds\n",
      "Evaluating model roben_1 on bert on stochastic_incl_ws for task yelp_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:28<00:00,  2.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7320    0.8517    0.7873       263\n",
      "           1     0.7990    0.6540    0.7193       237\n",
      "\n",
      "    accuracy                         0.7580       500\n",
      "   macro avg     0.7655    0.7529    0.7533       500\n",
      "weighted avg     0.7638    0.7580    0.7551       500\n",
      "\n",
      "Evaluation took 28.603731155395508 seconds\n",
      "Evaluating model roben_1 on bert on word_score_no_ws for task yelp_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [01:35<00:00,  5.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7372    0.8745    0.8000       263\n",
      "           1     0.8245    0.6540    0.7294       237\n",
      "\n",
      "    accuracy                         0.7700       500\n",
      "   macro avg     0.7808    0.7643    0.7647       500\n",
      "weighted avg     0.7786    0.7700    0.7665       500\n",
      "\n",
      "Evaluation took 95.15999341011047 seconds\n",
      "Evaluating model roben_1 on bert on word_score_incl_ws for task yelp_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [01:27<00:00,  5.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6301    0.7643    0.6907       263\n",
      "           1     0.6575    0.5021    0.5694       237\n",
      "\n",
      "    accuracy                         0.6400       500\n",
      "   macro avg     0.6438    0.6332    0.6300       500\n",
      "weighted avg     0.6431    0.6400    0.6332       500\n",
      "\n",
      "Evaluation took 87.36890649795532 seconds\n",
      "Evaluating model roben_2 on bert on clean for task yelp_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:02<00:00,  5.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8881    0.9354    0.9111       263\n",
      "           1     0.9238    0.8692    0.8957       237\n",
      "\n",
      "    accuracy                         0.9040       500\n",
      "   macro avg     0.9059    0.9023    0.9034       500\n",
      "weighted avg     0.9050    0.9040    0.9038       500\n",
      "\n",
      "Evaluation took 2.8601675033569336 seconds\n",
      "Evaluating model roben_2 on bert on stochastic_no_ws for task yelp_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:28<00:00,  2.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8380    0.9049    0.8702       263\n",
      "           1     0.8843    0.8059    0.8433       237\n",
      "\n",
      "    accuracy                         0.8580       500\n",
      "   macro avg     0.8611    0.8554    0.8567       500\n",
      "weighted avg     0.8599    0.8580    0.8574       500\n",
      "\n",
      "Evaluation took 28.1508629322052 seconds\n",
      "Evaluating model roben_2 on bert on stochastic_incl_ws for task yelp_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:28<00:00,  2.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7700    0.8403    0.8036       263\n",
      "           1     0.8028    0.7215    0.7600       237\n",
      "\n",
      "    accuracy                         0.7840       500\n",
      "   macro avg     0.7864    0.7809    0.7818       500\n",
      "weighted avg     0.7856    0.7840    0.7830       500\n",
      "\n",
      "Evaluation took 28.1719970703125 seconds\n",
      "Evaluating model roben_2 on bert on word_score_no_ws for task yelp_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [01:37<00:00,  5.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8097    0.8897    0.8478       263\n",
      "           1     0.8626    0.7679    0.8125       237\n",
      "\n",
      "    accuracy                         0.8320       500\n",
      "   macro avg     0.8361    0.8288    0.8302       500\n",
      "weighted avg     0.8347    0.8320    0.8311       500\n",
      "\n",
      "Evaluation took 97.92685461044312 seconds\n",
      "Evaluating model roben_2 on bert on word_score_incl_ws for task yelp_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [01:30<00:00,  5.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6788    0.7795    0.7257       263\n",
      "           1     0.7071    0.5907    0.6437       237\n",
      "\n",
      "    accuracy                         0.6900       500\n",
      "   macro avg     0.6929    0.6851    0.6847       500\n",
      "weighted avg     0.6922    0.6900    0.6868       500\n",
      "\n",
      "Evaluation took 90.94003105163574 seconds\n",
      "Evaluating model roben_1_tok on bert on clean for task yelp_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:03<00:00,  5.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8237    0.9240    0.8710       263\n",
      "           1     0.9024    0.7806    0.8371       237\n",
      "\n",
      "    accuracy                         0.8560       500\n",
      "   macro avg     0.8631    0.8523    0.8540       500\n",
      "weighted avg     0.8610    0.8560    0.8549       500\n",
      "\n",
      "Evaluation took 3.0526790618896484 seconds\n",
      "Evaluating model roben_1_tok on bert on stochastic_no_ws for task yelp_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:30<00:00,  3.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7855    0.9049    0.8410       263\n",
      "           1     0.8731    0.7257    0.7926       237\n",
      "\n",
      "    accuracy                         0.8200       500\n",
      "   macro avg     0.8293    0.8153    0.8168       500\n",
      "weighted avg     0.8270    0.8200    0.8181       500\n",
      "\n",
      "Evaluation took 30.849148273468018 seconds\n",
      "Evaluating model roben_1_tok on bert on stochastic_incl_ws for task yelp_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:30<00:00,  3.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6854    0.8365    0.7534       263\n",
      "           1     0.7598    0.5738    0.6538       237\n",
      "\n",
      "    accuracy                         0.7120       500\n",
      "   macro avg     0.7226    0.7052    0.7036       500\n",
      "weighted avg     0.7206    0.7120    0.7062       500\n",
      "\n",
      "Evaluation took 30.45531463623047 seconds\n",
      "Evaluating model roben_1_tok on bert on word_score_no_ws for task yelp_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [01:43<00:00,  4.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7508    0.8935    0.8160       263\n",
      "           1     0.8503    0.6709    0.7500       237\n",
      "\n",
      "    accuracy                         0.7880       500\n",
      "   macro avg     0.8005    0.7822    0.7830       500\n",
      "weighted avg     0.7979    0.7880    0.7847       500\n",
      "\n",
      "Evaluation took 103.16852831840515 seconds\n",
      "Evaluating model roben_1_tok on bert on word_score_incl_ws for task yelp_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [01:33<00:00,  5.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6204    0.7643    0.6848       263\n",
      "           1     0.6477    0.4810    0.5521       237\n",
      "\n",
      "    accuracy                         0.6300       500\n",
      "   macro avg     0.6340    0.6226    0.6184       500\n",
      "weighted avg     0.6333    0.6300    0.6219       500\n",
      "\n",
      "Evaluation took 93.12048006057739 seconds\n",
      "Evaluating model roben_2_tok on bert on clean for task yelp_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:03<00:00,  5.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8732    0.9163    0.8942       263\n",
      "           1     0.9018    0.8523    0.8764       237\n",
      "\n",
      "    accuracy                         0.8860       500\n",
      "   macro avg     0.8875    0.8843    0.8853       500\n",
      "weighted avg     0.8867    0.8860    0.8858       500\n",
      "\n",
      "Evaluation took 3.05865740776062 seconds\n",
      "Evaluating model roben_2_tok on bert on stochastic_no_ws for task yelp_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:30<00:00,  3.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8429    0.8973    0.8692       263\n",
      "           1     0.8773    0.8143    0.8446       237\n",
      "\n",
      "    accuracy                         0.8580       500\n",
      "   macro avg     0.8601    0.8558    0.8569       500\n",
      "weighted avg     0.8592    0.8580    0.8576       500\n",
      "\n",
      "Evaluation took 30.11723017692566 seconds\n",
      "Evaluating model roben_2_tok on bert on stochastic_incl_ws for task yelp_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:30<00:00,  3.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7568    0.8517    0.8014       263\n",
      "           1     0.8088    0.6962    0.7483       237\n",
      "\n",
      "    accuracy                         0.7780       500\n",
      "   macro avg     0.7828    0.7740    0.7749       500\n",
      "weighted avg     0.7814    0.7780    0.7762       500\n",
      "\n",
      "Evaluation took 30.10861039161682 seconds\n",
      "Evaluating model roben_2_tok on bert on word_score_no_ws for task yelp_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [01:45<00:00,  4.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8127    0.8745    0.8425       263\n",
      "           1     0.8479    0.7764    0.8106       237\n",
      "\n",
      "    accuracy                         0.8280       500\n",
      "   macro avg     0.8303    0.8254    0.8265       500\n",
      "weighted avg     0.8294    0.8280    0.8274       500\n",
      "\n",
      "Evaluation took 105.05119395256042 seconds\n",
      "Evaluating model roben_2_tok on bert on word_score_incl_ws for task yelp_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [01:36<00:00,  5.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6645    0.7757    0.7158       263\n",
      "           1     0.6943    0.5654    0.6233       237\n",
      "\n",
      "    accuracy                         0.6760       500\n",
      "   macro avg     0.6794    0.6705    0.6695       500\n",
      "weighted avg     0.6786    0.6760    0.6719       500\n",
      "\n",
      "Evaluation took 96.61831998825073 seconds\n",
      "Evaluating model 64k_lstm_clean_vanilla on bert on clean for task yelp_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:25<00:00,  1.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9513    0.9658    0.9585       263\n",
      "           1     0.9614    0.9451    0.9532       237\n",
      "\n",
      "    accuracy                         0.9560       500\n",
      "   macro avg     0.9563    0.9555    0.9558       500\n",
      "weighted avg     0.9561    0.9560    0.9560       500\n",
      "\n",
      "Evaluation took 25.528133630752563 seconds\n",
      "Evaluating model 64k_lstm_clean_vanilla on bert on stochastic_no_ws for task yelp_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [04:13<00:00, 25.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9102    0.8859    0.8979       263\n",
      "           1     0.8770    0.9030    0.8898       237\n",
      "\n",
      "    accuracy                         0.8940       500\n",
      "   macro avg     0.8936    0.8944    0.8938       500\n",
      "weighted avg     0.8945    0.8940    0.8941       500\n",
      "\n",
      "Evaluation took 253.67984700202942 seconds\n",
      "Evaluating model 64k_lstm_clean_vanilla on bert on stochastic_incl_ws for task yelp_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [04:05<00:00, 24.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8933    0.8593    0.8760       263\n",
      "           1     0.8502    0.8861    0.8678       237\n",
      "\n",
      "    accuracy                         0.8720       500\n",
      "   macro avg     0.8717    0.8727    0.8719       500\n",
      "weighted avg     0.8729    0.8720    0.8721       500\n",
      "\n",
      "Evaluation took 245.9354429244995 seconds\n",
      "Evaluating model 64k_lstm_clean_vanilla on bert on word_score_no_ws for task yelp_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [15:34<00:00,  1.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7967    0.7452    0.7701       263\n",
      "           1     0.7362    0.7890    0.7617       237\n",
      "\n",
      "    accuracy                         0.7660       500\n",
      "   macro avg     0.7665    0.7671    0.7659       500\n",
      "weighted avg     0.7681    0.7660    0.7661       500\n",
      "\n",
      "Evaluation took 934.6562955379486 seconds\n",
      "Evaluating model 64k_lstm_clean_vanilla on bert on word_score_incl_ws for task yelp_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [12:37<00:00,  1.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7410    0.7072    0.7237       263\n",
      "           1     0.6908    0.7257    0.7078       237\n",
      "\n",
      "    accuracy                         0.7160       500\n",
      "   macro avg     0.7159    0.7165    0.7158       500\n",
      "weighted avg     0.7172    0.7160    0.7162       500\n",
      "\n",
      "Evaluation took 757.9176194667816 seconds\n",
      "Evaluating model 64k_lstm_no_whitespace_pert_vanilla on bert on clean for task yelp_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:21<00:00,  1.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9620    0.9620    0.9620       263\n",
      "           1     0.9578    0.9578    0.9578       237\n",
      "\n",
      "    accuracy                         0.9600       500\n",
      "   macro avg     0.9599    0.9599    0.9599       500\n",
      "weighted avg     0.9600    0.9600    0.9600       500\n",
      "\n",
      "Evaluation took 21.861830711364746 seconds\n",
      "Evaluating model 64k_lstm_no_whitespace_pert_vanilla on bert on stochastic_no_ws for task yelp_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [03:40<00:00, 22.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9280    0.9316    0.9298       263\n",
      "           1     0.9237    0.9198    0.9218       237\n",
      "\n",
      "    accuracy                         0.9260       500\n",
      "   macro avg     0.9259    0.9257    0.9258       500\n",
      "weighted avg     0.9260    0.9260    0.9260       500\n",
      "\n",
      "Evaluation took 220.85825777053833 seconds\n",
      "Evaluating model 64k_lstm_no_whitespace_pert_vanilla on bert on stochastic_incl_ws for task yelp_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [03:38<00:00, 21.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9008    0.8973    0.8990       263\n",
      "           1     0.8866    0.8903    0.8884       237\n",
      "\n",
      "    accuracy                         0.8940       500\n",
      "   macro avg     0.8937    0.8938    0.8937       500\n",
      "weighted avg     0.8940    0.8940    0.8940       500\n",
      "\n",
      "Evaluation took 218.22774028778076 seconds\n",
      "Evaluating model 64k_lstm_no_whitespace_pert_vanilla on bert on word_score_no_ws for task yelp_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [13:47<00:00,  1.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8959    0.9163    0.9060       263\n",
      "           1     0.9048    0.8819    0.8932       237\n",
      "\n",
      "    accuracy                         0.9000       500\n",
      "   macro avg     0.9003    0.8991    0.8996       500\n",
      "weighted avg     0.9001    0.9000    0.8999       500\n",
      "\n",
      "Evaluation took 827.7421262264252 seconds\n",
      "Evaluating model 64k_lstm_no_whitespace_pert_vanilla on bert on word_score_incl_ws for task yelp_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [13:08<00:00,  1.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8016    0.7833    0.7923       263\n",
      "           1     0.7654    0.7848    0.7750       237\n",
      "\n",
      "    accuracy                         0.7840       500\n",
      "   macro avg     0.7835    0.7840    0.7837       500\n",
      "weighted avg     0.7844    0.7840    0.7841       500\n",
      "\n",
      "Evaluation took 788.0917520523071 seconds\n",
      "Evaluating model 64k_lstm_all_pert_vanilla on bert on clean for task yelp_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:21<00:00,  1.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9656    0.9620    0.9638       263\n",
      "           1     0.9580    0.9620    0.9600       237\n",
      "\n",
      "    accuracy                         0.9620       500\n",
      "   macro avg     0.9618    0.9620    0.9619       500\n",
      "weighted avg     0.9620    0.9620    0.9620       500\n",
      "\n",
      "Evaluation took 21.981257915496826 seconds\n",
      "Evaluating model 64k_lstm_all_pert_vanilla on bert on stochastic_no_ws for task yelp_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [03:39<00:00, 21.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9462    0.9354    0.9407       263\n",
      "           1     0.9292    0.9409    0.9350       237\n",
      "\n",
      "    accuracy                         0.9380       500\n",
      "   macro avg     0.9377    0.9381    0.9379       500\n",
      "weighted avg     0.9381    0.9380    0.9380       500\n",
      "\n",
      "Evaluation took 219.8661594390869 seconds\n",
      "Evaluating model 64k_lstm_all_pert_vanilla on bert on stochastic_incl_ws for task yelp_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [03:38<00:00, 21.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9421    0.9278    0.9349       263\n",
      "           1     0.9212    0.9367    0.9289       237\n",
      "\n",
      "    accuracy                         0.9320       500\n",
      "   macro avg     0.9316    0.9322    0.9319       500\n",
      "weighted avg     0.9322    0.9320    0.9320       500\n",
      "\n",
      "Evaluation took 218.93701577186584 seconds\n",
      "Evaluating model 64k_lstm_all_pert_vanilla on bert on word_score_no_ws for task yelp_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [13:27<00:00,  1.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8755    0.8289    0.8516       263\n",
      "           1     0.8207    0.8692    0.8443       237\n",
      "\n",
      "    accuracy                         0.8480       500\n",
      "   macro avg     0.8481    0.8490    0.8479       500\n",
      "weighted avg     0.8495    0.8480    0.8481       500\n",
      "\n",
      "Evaluation took 807.3517551422119 seconds\n",
      "Evaluating model 64k_lstm_all_pert_vanilla on bert on word_score_incl_ws for task yelp_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [13:38<00:00,  1.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8833    0.8631    0.8731       263\n",
      "           1     0.8519    0.8734    0.8625       237\n",
      "\n",
      "    accuracy                         0.8680       500\n",
      "   macro avg     0.8676    0.8683    0.8678       500\n",
      "weighted avg     0.8684    0.8680    0.8681       500\n",
      "\n",
      "Evaluation took 818.8644361495972 seconds\n",
      "Failed loading model 64k_lstm_clean_finetuned on bert for task yelp_bin, skipping\n",
      "Failed loading model 64k_lstm_no_whitespace_pert_finetuned on bert for task yelp_bin, skipping\n",
      "Evaluating model 64k_lstm_all_pert_finetuned on bert on clean for task yelp_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:21<00:00,  1.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9620    0.9620    0.9620       263\n",
      "           1     0.9578    0.9578    0.9578       237\n",
      "\n",
      "    accuracy                         0.9600       500\n",
      "   macro avg     0.9599    0.9599    0.9599       500\n",
      "weighted avg     0.9600    0.9600    0.9600       500\n",
      "\n",
      "Evaluation took 21.827037811279297 seconds\n",
      "Evaluating model 64k_lstm_all_pert_finetuned on bert on stochastic_no_ws for task yelp_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [03:40<00:00, 22.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9466    0.9430    0.9448       263\n",
      "           1     0.9370    0.9409    0.9389       237\n",
      "\n",
      "    accuracy                         0.9420       500\n",
      "   macro avg     0.9418    0.9419    0.9419       500\n",
      "weighted avg     0.9420    0.9420    0.9420       500\n",
      "\n",
      "Evaluation took 220.98148798942566 seconds\n",
      "Evaluating model 64k_lstm_all_pert_finetuned on bert on stochastic_incl_ws for task yelp_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [03:39<00:00, 21.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9356    0.9392    0.9374       263\n",
      "           1     0.9322    0.9283    0.9302       237\n",
      "\n",
      "    accuracy                         0.9340       500\n",
      "   macro avg     0.9339    0.9337    0.9338       500\n",
      "weighted avg     0.9340    0.9340    0.9340       500\n",
      "\n",
      "Evaluation took 219.90367007255554 seconds\n",
      "Evaluating model 64k_lstm_all_pert_finetuned on bert on word_score_no_ws for task yelp_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [13:46<00:00,  1.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8919    0.8783    0.8851       263\n",
      "           1     0.8672    0.8819    0.8745       237\n",
      "\n",
      "    accuracy                         0.8800       500\n",
      "   macro avg     0.8796    0.8801    0.8798       500\n",
      "weighted avg     0.8802    0.8800    0.8800       500\n",
      "\n",
      "Evaluation took 826.4246244430542 seconds\n",
      "Evaluating model 64k_lstm_all_pert_finetuned on bert on word_score_incl_ws for task yelp_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [13:49<00:00,  1.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8902    0.8631    0.8764       263\n",
      "           1     0.8531    0.8819    0.8672       237\n",
      "\n",
      "    accuracy                         0.8720       500\n",
      "   macro avg     0.8716    0.8725    0.8718       500\n",
      "weighted avg     0.8726    0.8720    0.8721       500\n",
      "\n",
      "Evaluation took 829.1796503067017 seconds\n",
      "Failed loading model 64k_cnn_no_whitespace_pert_finetuned on bert for task yelp_bin, skipping\n",
      "Failed loading model 2m_lstm_all_pert_finetuned on bert for task yelp_bin, skipping\n",
      "Failed loading model 32k_lstm_all_pert_finetuned_100ep on bert for task yelp_bin, skipping\n",
      "Evaluating model baseline on roberta on clean for task yelp_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:02<00:00,  6.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9583    0.9620    0.9602       263\n",
      "           1     0.9576    0.9536    0.9556       237\n",
      "\n",
      "    accuracy                         0.9580       500\n",
      "   macro avg     0.9580    0.9578    0.9579       500\n",
      "weighted avg     0.9580    0.9580    0.9580       500\n",
      "\n",
      "Evaluation took 2.6168811321258545 seconds\n",
      "Evaluating model baseline on roberta on stochastic_no_ws for task yelp_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:25<00:00,  2.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9109    0.8935    0.9021       263\n",
      "           1     0.8843    0.9030    0.8935       237\n",
      "\n",
      "    accuracy                         0.8980       500\n",
      "   macro avg     0.8976    0.8982    0.8978       500\n",
      "weighted avg     0.8983    0.8980    0.8980       500\n",
      "\n",
      "Evaluation took 25.30278491973877 seconds\n",
      "Evaluating model baseline on roberta on stochastic_incl_ws for task yelp_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:25<00:00,  2.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8876    0.9011    0.8943       263\n",
      "           1     0.8884    0.8734    0.8809       237\n",
      "\n",
      "    accuracy                         0.8880       500\n",
      "   macro avg     0.8880    0.8873    0.8876       500\n",
      "weighted avg     0.8880    0.8880    0.8879       500\n",
      "\n",
      "Evaluation took 25.35331630706787 seconds\n",
      "Evaluating model baseline on roberta on word_score_no_ws for task yelp_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [01:28<00:00,  5.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7553    0.8099    0.7817       263\n",
      "           1     0.7706    0.7089    0.7385       237\n",
      "\n",
      "    accuracy                         0.7620       500\n",
      "   macro avg     0.7630    0.7594    0.7601       500\n",
      "weighted avg     0.7626    0.7620    0.7612       500\n",
      "\n",
      "Evaluation took 88.31887221336365 seconds\n",
      "Evaluating model baseline on roberta on word_score_incl_ws for task yelp_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [01:28<00:00,  5.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7571    0.8061    0.7808       263\n",
      "           1     0.7682    0.7131    0.7396       237\n",
      "\n",
      "    accuracy                         0.7620       500\n",
      "   macro avg     0.7627    0.7596    0.7602       500\n",
      "weighted avg     0.7624    0.7620    0.7613       500\n",
      "\n",
      "Evaluation took 88.58341717720032 seconds\n",
      "Failed loading model baseline_all_pert on roberta for task yelp_bin, skipping\n",
      "Evaluating model roben_1 on roberta on clean for task yelp_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:02<00:00,  6.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8961    0.9506    0.9225       263\n",
      "           1     0.9412    0.8776    0.9083       237\n",
      "\n",
      "    accuracy                         0.9160       500\n",
      "   macro avg     0.9186    0.9141    0.9154       500\n",
      "weighted avg     0.9174    0.9160    0.9158       500\n",
      "\n",
      "Evaluation took 2.593519449234009 seconds\n",
      "Evaluating model roben_1 on roberta on stochastic_no_ws for task yelp_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:25<00:00,  2.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8380    0.9049    0.8702       263\n",
      "           1     0.8843    0.8059    0.8433       237\n",
      "\n",
      "    accuracy                         0.8580       500\n",
      "   macro avg     0.8611    0.8554    0.8567       500\n",
      "weighted avg     0.8599    0.8580    0.8574       500\n",
      "\n",
      "Evaluation took 25.367953300476074 seconds\n",
      "Evaluating model roben_1 on roberta on stochastic_incl_ws for task yelp_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:25<00:00,  2.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7945    0.8821    0.8360       263\n",
      "           1     0.8510    0.7468    0.7955       237\n",
      "\n",
      "    accuracy                         0.8180       500\n",
      "   macro avg     0.8227    0.8145    0.8158       500\n",
      "weighted avg     0.8213    0.8180    0.8168       500\n",
      "\n",
      "Evaluation took 25.379795789718628 seconds\n",
      "Evaluating model roben_1 on roberta on word_score_no_ws for task yelp_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [01:29<00:00,  5.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7793    0.8859    0.8292       263\n",
      "           1     0.8507    0.7215    0.7808       237\n",
      "\n",
      "    accuracy                         0.8080       500\n",
      "   macro avg     0.8150    0.8037    0.8050       500\n",
      "weighted avg     0.8131    0.8080    0.8063       500\n",
      "\n",
      "Evaluation took 90.01756143569946 seconds\n",
      "Evaluating model roben_1 on roberta on word_score_incl_ws for task yelp_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [01:23<00:00,  6.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6562    0.7985    0.7204       263\n",
      "           1     0.7056    0.5359    0.6091       237\n",
      "\n",
      "    accuracy                         0.6740       500\n",
      "   macro avg     0.6809    0.6672    0.6648       500\n",
      "weighted avg     0.6796    0.6740    0.6677       500\n",
      "\n",
      "Evaluation took 83.2600610256195 seconds\n",
      "Evaluating model roben_2 on roberta on clean for task yelp_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:02<00:00,  6.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9000    0.9240    0.9118       263\n",
      "           1     0.9130    0.8861    0.8994       237\n",
      "\n",
      "    accuracy                         0.9060       500\n",
      "   macro avg     0.9065    0.9050    0.9056       500\n",
      "weighted avg     0.9062    0.9060    0.9059       500\n",
      "\n",
      "Evaluation took 2.5954816341400146 seconds\n",
      "Evaluating model roben_2 on roberta on stochastic_no_ws for task yelp_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:25<00:00,  2.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8727    0.8859    0.8792       263\n",
      "           1     0.8712    0.8565    0.8638       237\n",
      "\n",
      "    accuracy                         0.8720       500\n",
      "   macro avg     0.8720    0.8712    0.8715       500\n",
      "weighted avg     0.8720    0.8720    0.8719       500\n",
      "\n",
      "Evaluation took 25.37122106552124 seconds\n",
      "Evaluating model roben_2 on roberta on stochastic_incl_ws for task yelp_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:25<00:00,  2.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8233    0.8859    0.8535       263\n",
      "           1     0.8618    0.7890    0.8238       237\n",
      "\n",
      "    accuracy                         0.8400       500\n",
      "   macro avg     0.8425    0.8375    0.8386       500\n",
      "weighted avg     0.8415    0.8400    0.8394       500\n",
      "\n",
      "Evaluation took 25.391633987426758 seconds\n",
      "Evaluating model roben_2 on roberta on word_score_no_ws for task yelp_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [01:30<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8185    0.8745    0.8456       263\n",
      "           1     0.8493    0.7848    0.8158       237\n",
      "\n",
      "    accuracy                         0.8320       500\n",
      "   macro avg     0.8339    0.8297    0.8307       500\n",
      "weighted avg     0.8331    0.8320    0.8315       500\n",
      "\n",
      "Evaluation took 90.37223887443542 seconds\n",
      "Evaluating model roben_2 on roberta on word_score_incl_ws for task yelp_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [01:25<00:00,  5.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7003    0.8175    0.7544       263\n",
      "           1     0.7513    0.6118    0.6744       237\n",
      "\n",
      "    accuracy                         0.7200       500\n",
      "   macro avg     0.7258    0.7147    0.7144       500\n",
      "weighted avg     0.7245    0.7200    0.7165       500\n",
      "\n",
      "Evaluation took 85.21417427062988 seconds\n",
      "Evaluating model roben_1_tok on roberta on clean for task yelp_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:02<00:00,  5.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8781    0.9316    0.9041       263\n",
      "           1     0.9186    0.8565    0.8865       237\n",
      "\n",
      "    accuracy                         0.8960       500\n",
      "   macro avg     0.8983    0.8940    0.8953       500\n",
      "weighted avg     0.8973    0.8960    0.8957       500\n",
      "\n",
      "Evaluation took 2.7857654094696045 seconds\n",
      "Evaluating model roben_1_tok on roberta on stochastic_no_ws for task yelp_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:27<00:00,  2.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8194    0.8973    0.8566       263\n",
      "           1     0.8726    0.7806    0.8241       237\n",
      "\n",
      "    accuracy                         0.8420       500\n",
      "   macro avg     0.8460    0.8390    0.8403       500\n",
      "weighted avg     0.8447    0.8420    0.8412       500\n",
      "\n",
      "Evaluation took 27.25647521018982 seconds\n",
      "Evaluating model roben_1_tok on roberta on stochastic_incl_ws for task yelp_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:27<00:00,  2.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7721    0.8631    0.8151       263\n",
      "           1     0.8252    0.7173    0.7675       237\n",
      "\n",
      "    accuracy                         0.7940       500\n",
      "   macro avg     0.7987    0.7902    0.7913       500\n",
      "weighted avg     0.7973    0.7940    0.7925       500\n",
      "\n",
      "Evaluation took 27.258527994155884 seconds\n",
      "Evaluating model roben_1_tok on roberta on word_score_no_ws for task yelp_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [01:35<00:00,  5.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8034    0.8859    0.8427       263\n",
      "           1     0.8571    0.7595    0.8054       237\n",
      "\n",
      "    accuracy                         0.8260       500\n",
      "   macro avg     0.8303    0.8227    0.8240       500\n",
      "weighted avg     0.8289    0.8260    0.8250       500\n",
      "\n",
      "Evaluation took 95.7079222202301 seconds\n",
      "Evaluating model roben_1_tok on roberta on word_score_incl_ws for task yelp_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [01:29<00:00,  5.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6543    0.8061    0.7223       263\n",
      "           1     0.7102    0.5274    0.6053       237\n",
      "\n",
      "    accuracy                         0.6740       500\n",
      "   macro avg     0.6823    0.6668    0.6638       500\n",
      "weighted avg     0.6808    0.6740    0.6669       500\n",
      "\n",
      "Evaluation took 89.03521203994751 seconds\n",
      "Evaluating model roben_2_tok on roberta on clean for task yelp_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:02<00:00,  5.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9139    0.9278    0.9208       263\n",
      "           1     0.9185    0.9030    0.9106       237\n",
      "\n",
      "    accuracy                         0.9160       500\n",
      "   macro avg     0.9162    0.9154    0.9157       500\n",
      "weighted avg     0.9160    0.9160    0.9160       500\n",
      "\n",
      "Evaluation took 2.7871503829956055 seconds\n",
      "Evaluating model roben_2_tok on roberta on stochastic_no_ws for task yelp_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:27<00:00,  2.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8745    0.9011    0.8876       263\n",
      "           1     0.8865    0.8565    0.8712       237\n",
      "\n",
      "    accuracy                         0.8800       500\n",
      "   macro avg     0.8805    0.8788    0.8794       500\n",
      "weighted avg     0.8802    0.8800    0.8799       500\n",
      "\n",
      "Evaluation took 27.24778127670288 seconds\n",
      "Evaluating model roben_2_tok on roberta on stochastic_incl_ws for task yelp_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:27<00:00,  2.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8229    0.9011    0.8603       263\n",
      "           1     0.8774    0.7848    0.8285       237\n",
      "\n",
      "    accuracy                         0.8460       500\n",
      "   macro avg     0.8501    0.8430    0.8444       500\n",
      "weighted avg     0.8487    0.8460    0.8452       500\n",
      "\n",
      "Evaluation took 27.256755113601685 seconds\n",
      "Evaluating model roben_2_tok on roberta on word_score_no_ws for task yelp_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [01:38<00:00,  5.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8566    0.8859    0.8710       263\n",
      "           1     0.8684    0.8354    0.8516       237\n",
      "\n",
      "    accuracy                         0.8620       500\n",
      "   macro avg     0.8625    0.8607    0.8613       500\n",
      "weighted avg     0.8622    0.8620    0.8618       500\n",
      "\n",
      "Evaluation took 98.68831968307495 seconds\n",
      "Evaluating model roben_2_tok on roberta on word_score_incl_ws for task yelp_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [01:31<00:00,  5.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7010    0.8289    0.7596       263\n",
      "           1     0.7619    0.6076    0.6761       237\n",
      "\n",
      "    accuracy                         0.7240       500\n",
      "   macro avg     0.7314    0.7182    0.7178       500\n",
      "weighted avg     0.7299    0.7240    0.7200       500\n",
      "\n",
      "Evaluation took 91.6050672531128 seconds\n",
      "Failed loading model 64k_lstm_clean_vanilla on roberta for task yelp_bin, skipping\n",
      "Failed loading model 64k_lstm_no_whitespace_pert_vanilla on roberta for task yelp_bin, skipping\n",
      "Evaluating model 64k_lstm_all_pert_vanilla on roberta on clean for task yelp_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:21<00:00,  1.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9405    0.9620    0.9511       263\n",
      "           1     0.9567    0.9325    0.9444       237\n",
      "\n",
      "    accuracy                         0.9480       500\n",
      "   macro avg     0.9486    0.9472    0.9478       500\n",
      "weighted avg     0.9482    0.9480    0.9480       500\n",
      "\n",
      "Evaluation took 21.743806838989258 seconds\n",
      "Evaluating model 64k_lstm_all_pert_vanilla on roberta on stochastic_no_ws for task yelp_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [03:39<00:00, 21.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9127    0.9544    0.9331       263\n",
      "           1     0.9467    0.8987    0.9221       237\n",
      "\n",
      "    accuracy                         0.9280       500\n",
      "   macro avg     0.9297    0.9266    0.9276       500\n",
      "weighted avg     0.9288    0.9280    0.9279       500\n",
      "\n",
      "Evaluation took 219.63570499420166 seconds\n",
      "Evaluating model 64k_lstm_all_pert_vanilla on roberta on stochastic_incl_ws for task yelp_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [03:39<00:00, 21.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9022    0.9468    0.9239       263\n",
      "           1     0.9375    0.8861    0.9111       237\n",
      "\n",
      "    accuracy                         0.9180       500\n",
      "   macro avg     0.9198    0.9164    0.9175       500\n",
      "weighted avg     0.9189    0.9180    0.9178       500\n",
      "\n",
      "Evaluation took 219.77753233909607 seconds\n",
      "Evaluating model 64k_lstm_all_pert_vanilla on roberta on word_score_no_ws for task yelp_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [13:33<00:00,  1.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8432    0.9202    0.8800       263\n",
      "           1     0.9014    0.8101    0.8533       237\n",
      "\n",
      "    accuracy                         0.8680       500\n",
      "   macro avg     0.8723    0.8651    0.8667       500\n",
      "weighted avg     0.8708    0.8680    0.8674       500\n",
      "\n",
      "Evaluation took 813.4523239135742 seconds\n",
      "Evaluating model 64k_lstm_all_pert_vanilla on roberta on word_score_incl_ws for task yelp_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [13:42<00:00,  1.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8592    0.9049    0.8815       263\n",
      "           1     0.8879    0.8354    0.8609       237\n",
      "\n",
      "    accuracy                         0.8720       500\n",
      "   macro avg     0.8735    0.8702    0.8712       500\n",
      "weighted avg     0.8728    0.8720    0.8717       500\n",
      "\n",
      "Evaluation took 822.9476583003998 seconds\n",
      "Failed loading model 64k_lstm_clean_finetuned on roberta for task yelp_bin, skipping\n",
      "Failed loading model 64k_lstm_no_whitespace_pert_finetuned on roberta for task yelp_bin, skipping\n",
      "Evaluating model 64k_lstm_all_pert_finetuned on roberta on clean for task yelp_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:21<00:00,  1.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9478    0.9658    0.9567       263\n",
      "           1     0.9612    0.9409    0.9510       237\n",
      "\n",
      "    accuracy                         0.9540       500\n",
      "   macro avg     0.9545    0.9534    0.9538       500\n",
      "weighted avg     0.9541    0.9540    0.9540       500\n",
      "\n",
      "Evaluation took 21.79786252975464 seconds\n",
      "Evaluating model 64k_lstm_all_pert_finetuned on roberta on stochastic_no_ws for task yelp_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [03:40<00:00, 22.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9259    0.9506    0.9381       263\n",
      "           1     0.9435    0.9156    0.9293       237\n",
      "\n",
      "    accuracy                         0.9340       500\n",
      "   macro avg     0.9347    0.9331    0.9337       500\n",
      "weighted avg     0.9342    0.9340    0.9339       500\n",
      "\n",
      "Evaluation took 220.82987427711487 seconds\n",
      "Evaluating model 64k_lstm_all_pert_finetuned on roberta on stochastic_incl_ws for task yelp_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [03:39<00:00, 21.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9191    0.9506    0.9346       263\n",
      "           1     0.9430    0.9072    0.9247       237\n",
      "\n",
      "    accuracy                         0.9300       500\n",
      "   macro avg     0.9311    0.9289    0.9297       500\n",
      "weighted avg     0.9304    0.9300    0.9299       500\n",
      "\n",
      "Evaluation took 219.33505630493164 seconds\n",
      "Evaluating model 64k_lstm_all_pert_finetuned on roberta on word_score_no_ws for task yelp_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [13:25<00:00,  1.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8521    0.9202    0.8848       263\n",
      "           1     0.9028    0.8228    0.8609       237\n",
      "\n",
      "    accuracy                         0.8740       500\n",
      "   macro avg     0.8774    0.8715    0.8729       500\n",
      "weighted avg     0.8761    0.8740    0.8735       500\n",
      "\n",
      "Evaluation took 805.4878494739532 seconds\n",
      "Evaluating model 64k_lstm_all_pert_finetuned on roberta on word_score_incl_ws for task yelp_bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [13:37<00:00,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8659    0.9087    0.8868       263\n",
      "           1     0.8929    0.8439    0.8677       237\n",
      "\n",
      "    accuracy                         0.8780       500\n",
      "   macro avg     0.8794    0.8763    0.8773       500\n",
      "weighted avg     0.8787    0.8780    0.8778       500\n",
      "\n",
      "Evaluation took 817.88609790802 seconds\n",
      "Failed loading model 64k_cnn_no_whitespace_pert_finetuned on roberta for task yelp_bin, skipping\n",
      "Failed loading model 2m_lstm_all_pert_finetuned on roberta for task yelp_bin, skipping\n",
      "Failed loading model 32k_lstm_all_pert_finetuned_100ep on roberta for task yelp_bin, skipping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_task_ids = [ f\"{model}_{type}_{task}\" for task, type, model in itertools.product(tasks, model_types, all_models.keys()) ]\n",
    "\n",
    "accuracy_df = pd.DataFrame(columns=evaluations, index=model_task_ids)\n",
    "f1_df = pd.DataFrame(columns=evaluations, index=model_task_ids)\n",
    "\n",
    "for task, type in itertools.product(tasks, model_types):\n",
    "    for cur_model_name, cur_model_factory in all_models.items():\n",
    "        try:\n",
    "            cur_model = cur_model_factory(task, type)\n",
    "        except:\n",
    "            print(f'Failed loading model {cur_model_name} on {type} for task {task}, skipping')\n",
    "            accuracy_df.drop(f\"{cur_model_name}_{type}_{task}\", inplace=True)\n",
    "            f1_df.drop(f\"{cur_model_name}_{type}_{task}\", inplace=True)\n",
    "            continue\n",
    "        for cur_evaluation in evaluations:\n",
    "            print(f'Evaluating model {cur_model_name} on {type} on {cur_evaluation} for task {task}')\n",
    "            start_time = time.time()\n",
    "            random.seed(11)\n",
    "            if cur_evaluation == 'clean':\n",
    "                acc, f1 = evaluate_model(cur_model, sampled_test_set[task])\n",
    "            elif cur_evaluation.startswith('stochastic_'):\n",
    "                if cur_evaluation == 'stochastic_no_ws':\n",
    "                    acc_list, f1_list = evaluate_model_adv(cur_model, sampled_test_set_adv_no_ws[task])\n",
    "                elif cur_evaluation == 'stochastic_incl_ws':\n",
    "                    acc_list, f1_list = evaluate_model_adv(cur_model, sampled_test_set_adv_incl_ws[task])\n",
    "                acc = acc_list[-1]\n",
    "                f1 = f1_list[-1]\n",
    "                with open(f\"../output/eval/{cur_model_name}_{type}_{task}_{cur_evaluation}_acc_list.json\", \"w\") as f:\n",
    "                    json.dump(acc_list, fp=f)\n",
    "                with open(f\"../output/eval/{cur_model_name}_{type}_{task}_{cur_evaluation}_f1_list.json\", \"w\") as f:\n",
    "                    json.dump(f1_list, fp=f)\n",
    "            elif cur_evaluation.startswith('word_score_'):\n",
    "                if cur_evaluation == 'word_score_no_ws':\n",
    "                    acc, f1 = evaluate_model_word_score(cur_model, sampled_test_set[task], allow_whitespace_pert=False,\n",
    "                                                        report_prefix=f\"../output/eval/{cur_model_name}_{type}_{task}_{cur_evaluation}\",\n",
    "                                                        word_scores_file=f\"../output/{task}_word_scores.json\")\n",
    "                elif cur_evaluation == 'word_score_incl_ws':\n",
    "                    acc, f1 = evaluate_model_word_score(cur_model, sampled_test_set[task], allow_whitespace_pert=True,\n",
    "                                                        report_prefix=f\"../output/eval/{cur_model_name}_{type}_{task}_{cur_evaluation}\",\n",
    "                                                        word_scores_file=f\"../output/{task}_word_scores.json\")\n",
    "\n",
    "            accuracy_df[cur_evaluation][f\"{cur_model_name}_{type}_{task}\"] = acc\n",
    "            f1_df[cur_evaluation][f\"{cur_model_name}_{type}_{task}\"] = f1\n",
    "            end_time = time.time()\n",
    "            print(f\"Evaluation took {end_time-start_time} seconds\")\n",
    "        del cur_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6e229c55",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-01T06:14:51.186588Z",
     "iopub.status.busy": "2022-04-01T06:14:51.184925Z",
     "iopub.status.idle": "2022-04-01T06:14:51.198999Z",
     "shell.execute_reply": "2022-04-01T06:14:51.198401Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean</th>\n",
       "      <th>stochastic_no_ws</th>\n",
       "      <th>stochastic_incl_ws</th>\n",
       "      <th>word_score_no_ws</th>\n",
       "      <th>word_score_incl_ws</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>baseline_bert_yelp_bin</th>\n",
       "      <td>0.954</td>\n",
       "      <td>0.872</td>\n",
       "      <td>0.858</td>\n",
       "      <td>0.744</td>\n",
       "      <td>0.706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roben_1_bert_yelp_bin</th>\n",
       "      <td>0.882</td>\n",
       "      <td>0.814</td>\n",
       "      <td>0.758</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roben_2_bert_yelp_bin</th>\n",
       "      <td>0.904</td>\n",
       "      <td>0.858</td>\n",
       "      <td>0.784</td>\n",
       "      <td>0.832</td>\n",
       "      <td>0.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roben_1_tok_bert_yelp_bin</th>\n",
       "      <td>0.856</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.712</td>\n",
       "      <td>0.788</td>\n",
       "      <td>0.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roben_2_tok_bert_yelp_bin</th>\n",
       "      <td>0.886</td>\n",
       "      <td>0.858</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.828</td>\n",
       "      <td>0.676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64k_lstm_clean_vanilla_bert_yelp_bin</th>\n",
       "      <td>0.956</td>\n",
       "      <td>0.894</td>\n",
       "      <td>0.872</td>\n",
       "      <td>0.766</td>\n",
       "      <td>0.716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64k_lstm_no_whitespace_pert_vanilla_bert_yelp_bin</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.926</td>\n",
       "      <td>0.894</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64k_lstm_all_pert_vanilla_bert_yelp_bin</th>\n",
       "      <td>0.962</td>\n",
       "      <td>0.938</td>\n",
       "      <td>0.932</td>\n",
       "      <td>0.848</td>\n",
       "      <td>0.868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64k_lstm_all_pert_finetuned_bert_yelp_bin</th>\n",
       "      <td>0.96</td>\n",
       "      <td>0.942</td>\n",
       "      <td>0.934</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>baseline_roberta_yelp_bin</th>\n",
       "      <td>0.958</td>\n",
       "      <td>0.898</td>\n",
       "      <td>0.888</td>\n",
       "      <td>0.762</td>\n",
       "      <td>0.762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roben_1_roberta_yelp_bin</th>\n",
       "      <td>0.916</td>\n",
       "      <td>0.858</td>\n",
       "      <td>0.818</td>\n",
       "      <td>0.808</td>\n",
       "      <td>0.674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roben_2_roberta_yelp_bin</th>\n",
       "      <td>0.906</td>\n",
       "      <td>0.872</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.832</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roben_1_tok_roberta_yelp_bin</th>\n",
       "      <td>0.896</td>\n",
       "      <td>0.842</td>\n",
       "      <td>0.794</td>\n",
       "      <td>0.826</td>\n",
       "      <td>0.674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roben_2_tok_roberta_yelp_bin</th>\n",
       "      <td>0.916</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.846</td>\n",
       "      <td>0.862</td>\n",
       "      <td>0.724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64k_lstm_all_pert_vanilla_roberta_yelp_bin</th>\n",
       "      <td>0.948</td>\n",
       "      <td>0.928</td>\n",
       "      <td>0.918</td>\n",
       "      <td>0.868</td>\n",
       "      <td>0.872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64k_lstm_all_pert_finetuned_roberta_yelp_bin</th>\n",
       "      <td>0.954</td>\n",
       "      <td>0.934</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.874</td>\n",
       "      <td>0.878</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   clean stochastic_no_ws  \\\n",
       "baseline_bert_yelp_bin                             0.954            0.872   \n",
       "roben_1_bert_yelp_bin                              0.882            0.814   \n",
       "roben_2_bert_yelp_bin                              0.904            0.858   \n",
       "roben_1_tok_bert_yelp_bin                          0.856             0.82   \n",
       "roben_2_tok_bert_yelp_bin                          0.886            0.858   \n",
       "64k_lstm_clean_vanilla_bert_yelp_bin               0.956            0.894   \n",
       "64k_lstm_no_whitespace_pert_vanilla_bert_yelp_bin   0.96            0.926   \n",
       "64k_lstm_all_pert_vanilla_bert_yelp_bin            0.962            0.938   \n",
       "64k_lstm_all_pert_finetuned_bert_yelp_bin           0.96            0.942   \n",
       "baseline_roberta_yelp_bin                          0.958            0.898   \n",
       "roben_1_roberta_yelp_bin                           0.916            0.858   \n",
       "roben_2_roberta_yelp_bin                           0.906            0.872   \n",
       "roben_1_tok_roberta_yelp_bin                       0.896            0.842   \n",
       "roben_2_tok_roberta_yelp_bin                       0.916             0.88   \n",
       "64k_lstm_all_pert_vanilla_roberta_yelp_bin         0.948            0.928   \n",
       "64k_lstm_all_pert_finetuned_roberta_yelp_bin       0.954            0.934   \n",
       "\n",
       "                                                  stochastic_incl_ws  \\\n",
       "baseline_bert_yelp_bin                                         0.858   \n",
       "roben_1_bert_yelp_bin                                          0.758   \n",
       "roben_2_bert_yelp_bin                                          0.784   \n",
       "roben_1_tok_bert_yelp_bin                                      0.712   \n",
       "roben_2_tok_bert_yelp_bin                                      0.778   \n",
       "64k_lstm_clean_vanilla_bert_yelp_bin                           0.872   \n",
       "64k_lstm_no_whitespace_pert_vanilla_bert_yelp_bin              0.894   \n",
       "64k_lstm_all_pert_vanilla_bert_yelp_bin                        0.932   \n",
       "64k_lstm_all_pert_finetuned_bert_yelp_bin                      0.934   \n",
       "baseline_roberta_yelp_bin                                      0.888   \n",
       "roben_1_roberta_yelp_bin                                       0.818   \n",
       "roben_2_roberta_yelp_bin                                        0.84   \n",
       "roben_1_tok_roberta_yelp_bin                                   0.794   \n",
       "roben_2_tok_roberta_yelp_bin                                   0.846   \n",
       "64k_lstm_all_pert_vanilla_roberta_yelp_bin                     0.918   \n",
       "64k_lstm_all_pert_finetuned_roberta_yelp_bin                    0.93   \n",
       "\n",
       "                                                  word_score_no_ws  \\\n",
       "baseline_bert_yelp_bin                                       0.744   \n",
       "roben_1_bert_yelp_bin                                         0.77   \n",
       "roben_2_bert_yelp_bin                                        0.832   \n",
       "roben_1_tok_bert_yelp_bin                                    0.788   \n",
       "roben_2_tok_bert_yelp_bin                                    0.828   \n",
       "64k_lstm_clean_vanilla_bert_yelp_bin                         0.766   \n",
       "64k_lstm_no_whitespace_pert_vanilla_bert_yelp_bin              0.9   \n",
       "64k_lstm_all_pert_vanilla_bert_yelp_bin                      0.848   \n",
       "64k_lstm_all_pert_finetuned_bert_yelp_bin                     0.88   \n",
       "baseline_roberta_yelp_bin                                    0.762   \n",
       "roben_1_roberta_yelp_bin                                     0.808   \n",
       "roben_2_roberta_yelp_bin                                     0.832   \n",
       "roben_1_tok_roberta_yelp_bin                                 0.826   \n",
       "roben_2_tok_roberta_yelp_bin                                 0.862   \n",
       "64k_lstm_all_pert_vanilla_roberta_yelp_bin                   0.868   \n",
       "64k_lstm_all_pert_finetuned_roberta_yelp_bin                 0.874   \n",
       "\n",
       "                                                  word_score_incl_ws  \n",
       "baseline_bert_yelp_bin                                         0.706  \n",
       "roben_1_bert_yelp_bin                                           0.64  \n",
       "roben_2_bert_yelp_bin                                           0.69  \n",
       "roben_1_tok_bert_yelp_bin                                       0.63  \n",
       "roben_2_tok_bert_yelp_bin                                      0.676  \n",
       "64k_lstm_clean_vanilla_bert_yelp_bin                           0.716  \n",
       "64k_lstm_no_whitespace_pert_vanilla_bert_yelp_bin              0.784  \n",
       "64k_lstm_all_pert_vanilla_bert_yelp_bin                        0.868  \n",
       "64k_lstm_all_pert_finetuned_bert_yelp_bin                      0.872  \n",
       "baseline_roberta_yelp_bin                                      0.762  \n",
       "roben_1_roberta_yelp_bin                                       0.674  \n",
       "roben_2_roberta_yelp_bin                                        0.72  \n",
       "roben_1_tok_roberta_yelp_bin                                   0.674  \n",
       "roben_2_tok_roberta_yelp_bin                                   0.724  \n",
       "64k_lstm_all_pert_vanilla_roberta_yelp_bin                     0.872  \n",
       "64k_lstm_all_pert_finetuned_roberta_yelp_bin                   0.878  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "79f4cd33",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-01T06:14:51.208980Z",
     "iopub.status.busy": "2022-04-01T06:14:51.208404Z",
     "iopub.status.idle": "2022-04-01T06:14:51.211291Z",
     "shell.execute_reply": "2022-04-01T06:14:51.211757Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean</th>\n",
       "      <th>stochastic_no_ws</th>\n",
       "      <th>stochastic_incl_ws</th>\n",
       "      <th>word_score_no_ws</th>\n",
       "      <th>word_score_incl_ws</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>baseline_bert_yelp_bin</th>\n",
       "      <td>0.953845</td>\n",
       "      <td>0.871653</td>\n",
       "      <td>0.857379</td>\n",
       "      <td>0.743306</td>\n",
       "      <td>0.7042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roben_1_bert_yelp_bin</th>\n",
       "      <td>0.880555</td>\n",
       "      <td>0.810999</td>\n",
       "      <td>0.753302</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.63005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roben_2_bert_yelp_bin</th>\n",
       "      <td>0.903382</td>\n",
       "      <td>0.856734</td>\n",
       "      <td>0.781818</td>\n",
       "      <td>0.830163</td>\n",
       "      <td>0.684671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roben_1_tok_bert_yelp_bin</th>\n",
       "      <td>0.854036</td>\n",
       "      <td>0.816808</td>\n",
       "      <td>0.703635</td>\n",
       "      <td>0.782986</td>\n",
       "      <td>0.618448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roben_2_tok_bert_yelp_bin</th>\n",
       "      <td>0.885302</td>\n",
       "      <td>0.856942</td>\n",
       "      <td>0.774865</td>\n",
       "      <td>0.826532</td>\n",
       "      <td>0.669523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64k_lstm_clean_vanilla_bert_yelp_bin</th>\n",
       "      <td>0.955841</td>\n",
       "      <td>0.893847</td>\n",
       "      <td>0.871869</td>\n",
       "      <td>0.765924</td>\n",
       "      <td>0.715777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64k_lstm_no_whitespace_pert_vanilla_bert_yelp_bin</th>\n",
       "      <td>0.959892</td>\n",
       "      <td>0.925784</td>\n",
       "      <td>0.893734</td>\n",
       "      <td>0.899589</td>\n",
       "      <td>0.783654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64k_lstm_all_pert_vanilla_bert_yelp_bin</th>\n",
       "      <td>0.961905</td>\n",
       "      <td>0.937869</td>\n",
       "      <td>0.931868</td>\n",
       "      <td>0.847912</td>\n",
       "      <td>0.867788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64k_lstm_all_pert_finetuned_bert_yelp_bin</th>\n",
       "      <td>0.959892</td>\n",
       "      <td>0.941855</td>\n",
       "      <td>0.933807</td>\n",
       "      <td>0.879767</td>\n",
       "      <td>0.871834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>baseline_roberta_yelp_bin</th>\n",
       "      <td>0.957877</td>\n",
       "      <td>0.89782</td>\n",
       "      <td>0.887595</td>\n",
       "      <td>0.760056</td>\n",
       "      <td>0.760227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roben_1_roberta_yelp_bin</th>\n",
       "      <td>0.915403</td>\n",
       "      <td>0.856734</td>\n",
       "      <td>0.815771</td>\n",
       "      <td>0.805002</td>\n",
       "      <td>0.664762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roben_2_roberta_yelp_bin</th>\n",
       "      <td>0.905589</td>\n",
       "      <td>0.871538</td>\n",
       "      <td>0.838634</td>\n",
       "      <td>0.830689</td>\n",
       "      <td>0.714402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roben_1_tok_roberta_yelp_bin</th>\n",
       "      <td>0.895261</td>\n",
       "      <td>0.840339</td>\n",
       "      <td>0.791288</td>\n",
       "      <td>0.824023</td>\n",
       "      <td>0.663822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roben_2_tok_roberta_yelp_bin</th>\n",
       "      <td>0.915697</td>\n",
       "      <td>0.879443</td>\n",
       "      <td>0.844381</td>\n",
       "      <td>0.86132</td>\n",
       "      <td>0.717819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64k_lstm_all_pert_vanilla_roberta_yelp_bin</th>\n",
       "      <td>0.947786</td>\n",
       "      <td>0.927582</td>\n",
       "      <td>0.917498</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.871176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64k_lstm_all_pert_finetuned_roberta_yelp_bin</th>\n",
       "      <td>0.953822</td>\n",
       "      <td>0.933711</td>\n",
       "      <td>0.929655</td>\n",
       "      <td>0.872877</td>\n",
       "      <td>0.877253</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      clean stochastic_no_ws  \\\n",
       "baseline_bert_yelp_bin                             0.953845         0.871653   \n",
       "roben_1_bert_yelp_bin                              0.880555         0.810999   \n",
       "roben_2_bert_yelp_bin                              0.903382         0.856734   \n",
       "roben_1_tok_bert_yelp_bin                          0.854036         0.816808   \n",
       "roben_2_tok_bert_yelp_bin                          0.885302         0.856942   \n",
       "64k_lstm_clean_vanilla_bert_yelp_bin               0.955841         0.893847   \n",
       "64k_lstm_no_whitespace_pert_vanilla_bert_yelp_bin  0.959892         0.925784   \n",
       "64k_lstm_all_pert_vanilla_bert_yelp_bin            0.961905         0.937869   \n",
       "64k_lstm_all_pert_finetuned_bert_yelp_bin          0.959892         0.941855   \n",
       "baseline_roberta_yelp_bin                          0.957877          0.89782   \n",
       "roben_1_roberta_yelp_bin                           0.915403         0.856734   \n",
       "roben_2_roberta_yelp_bin                           0.905589         0.871538   \n",
       "roben_1_tok_roberta_yelp_bin                       0.895261         0.840339   \n",
       "roben_2_tok_roberta_yelp_bin                       0.915697         0.879443   \n",
       "64k_lstm_all_pert_vanilla_roberta_yelp_bin         0.947786         0.927582   \n",
       "64k_lstm_all_pert_finetuned_roberta_yelp_bin       0.953822         0.933711   \n",
       "\n",
       "                                                  stochastic_incl_ws  \\\n",
       "baseline_bert_yelp_bin                                      0.857379   \n",
       "roben_1_bert_yelp_bin                                       0.753302   \n",
       "roben_2_bert_yelp_bin                                       0.781818   \n",
       "roben_1_tok_bert_yelp_bin                                   0.703635   \n",
       "roben_2_tok_bert_yelp_bin                                   0.774865   \n",
       "64k_lstm_clean_vanilla_bert_yelp_bin                        0.871869   \n",
       "64k_lstm_no_whitespace_pert_vanilla_bert_yelp_bin           0.893734   \n",
       "64k_lstm_all_pert_vanilla_bert_yelp_bin                     0.931868   \n",
       "64k_lstm_all_pert_finetuned_bert_yelp_bin                   0.933807   \n",
       "baseline_roberta_yelp_bin                                   0.887595   \n",
       "roben_1_roberta_yelp_bin                                    0.815771   \n",
       "roben_2_roberta_yelp_bin                                    0.838634   \n",
       "roben_1_tok_roberta_yelp_bin                                0.791288   \n",
       "roben_2_tok_roberta_yelp_bin                                0.844381   \n",
       "64k_lstm_all_pert_vanilla_roberta_yelp_bin                  0.917498   \n",
       "64k_lstm_all_pert_finetuned_roberta_yelp_bin                0.929655   \n",
       "\n",
       "                                                  word_score_no_ws  \\\n",
       "baseline_bert_yelp_bin                                    0.743306   \n",
       "roben_1_bert_yelp_bin                                     0.764706   \n",
       "roben_2_bert_yelp_bin                                     0.830163   \n",
       "roben_1_tok_bert_yelp_bin                                 0.782986   \n",
       "roben_2_tok_bert_yelp_bin                                 0.826532   \n",
       "64k_lstm_clean_vanilla_bert_yelp_bin                      0.765924   \n",
       "64k_lstm_no_whitespace_pert_vanilla_bert_yelp_bin         0.899589   \n",
       "64k_lstm_all_pert_vanilla_bert_yelp_bin                   0.847912   \n",
       "64k_lstm_all_pert_finetuned_bert_yelp_bin                 0.879767   \n",
       "baseline_roberta_yelp_bin                                 0.760056   \n",
       "roben_1_roberta_yelp_bin                                  0.805002   \n",
       "roben_2_roberta_yelp_bin                                  0.830689   \n",
       "roben_1_tok_roberta_yelp_bin                              0.824023   \n",
       "roben_2_tok_roberta_yelp_bin                               0.86132   \n",
       "64k_lstm_all_pert_vanilla_roberta_yelp_bin                0.866667   \n",
       "64k_lstm_all_pert_finetuned_roberta_yelp_bin              0.872877   \n",
       "\n",
       "                                                  word_score_incl_ws  \n",
       "baseline_bert_yelp_bin                                        0.7042  \n",
       "roben_1_bert_yelp_bin                                        0.63005  \n",
       "roben_2_bert_yelp_bin                                       0.684671  \n",
       "roben_1_tok_bert_yelp_bin                                   0.618448  \n",
       "roben_2_tok_bert_yelp_bin                                   0.669523  \n",
       "64k_lstm_clean_vanilla_bert_yelp_bin                        0.715777  \n",
       "64k_lstm_no_whitespace_pert_vanilla_bert_yelp_bin           0.783654  \n",
       "64k_lstm_all_pert_vanilla_bert_yelp_bin                     0.867788  \n",
       "64k_lstm_all_pert_finetuned_bert_yelp_bin                   0.871834  \n",
       "baseline_roberta_yelp_bin                                   0.760227  \n",
       "roben_1_roberta_yelp_bin                                    0.664762  \n",
       "roben_2_roberta_yelp_bin                                    0.714402  \n",
       "roben_1_tok_roberta_yelp_bin                                0.663822  \n",
       "roben_2_tok_roberta_yelp_bin                                0.717819  \n",
       "64k_lstm_all_pert_vanilla_roberta_yelp_bin                  0.871176  \n",
       "64k_lstm_all_pert_finetuned_roberta_yelp_bin                0.877253  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4b227192",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-01T06:14:51.215426Z",
     "iopub.status.busy": "2022-04-01T06:14:51.214848Z",
     "iopub.status.idle": "2022-04-01T06:14:51.219469Z",
     "shell.execute_reply": "2022-04-01T06:14:51.219961Z"
    }
   },
   "outputs": [],
   "source": [
    "accuracy_df.to_csv(\"../output/grid_accuracy.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "69cb79c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-01T06:14:51.223400Z",
     "iopub.status.busy": "2022-04-01T06:14:51.222326Z",
     "iopub.status.idle": "2022-04-01T06:14:51.226522Z",
     "shell.execute_reply": "2022-04-01T06:14:51.227884Z"
    }
   },
   "outputs": [],
   "source": [
    "f1_df.to_csv(\"../output/grid_f1.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fff8d67",
   "metadata": {},
   "source": [
    "-----"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "2a4bb820c60e40c1ad0f64107d79c7f1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "46a5be577b9e40eeab875a637fb2c738": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4d936e5567d94706bcf6b4ef2236e146": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_cb6ac35c597a4aaaa22afa7869915e6c",
       "placeholder": "​",
       "style": "IPY_MODEL_d449ab3082d846d9bfe6f759ce4b6961",
       "value": "100%"
      }
     },
     "9cbbe48af9c74d1fa2a1dcfd7fedf44c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_4d936e5567d94706bcf6b4ef2236e146",
        "IPY_MODEL_b819c89091db48baa8d383ab5691e161",
        "IPY_MODEL_d88b1744e4b248d4862767ee803c7a82"
       ],
       "layout": "IPY_MODEL_46a5be577b9e40eeab875a637fb2c738"
      }
     },
     "9eb4ae5d3a0e4d26a146082921db36ad": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a961553d4e66474b986f6d9279bc6cfe": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "b819c89091db48baa8d383ab5691e161": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_cf845fb3afc3455384caed6df36f6f45",
       "max": 4,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_a961553d4e66474b986f6d9279bc6cfe",
       "value": 4
      }
     },
     "cb6ac35c597a4aaaa22afa7869915e6c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "cf845fb3afc3455384caed6df36f6f45": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d449ab3082d846d9bfe6f759ce4b6961": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "d88b1744e4b248d4862767ee803c7a82": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_9eb4ae5d3a0e4d26a146082921db36ad",
       "placeholder": "​",
       "style": "IPY_MODEL_2a4bb820c60e40c1ad0f64107d79c7f1",
       "value": " 4/4 [00:00&lt;00:00,  5.44it/s]"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
