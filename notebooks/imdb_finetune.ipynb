{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5c2c607-62c8-4664-a080-af75495d11a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, DatasetDict, load_from_disk\n",
    "from transformers import AutoTokenizer, DataCollatorWithPadding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9256c35-71ed-47ec-8277-3b9d9adcf275",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb = load_from_disk(\"../data/imdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94b44124-64c6-440b-ba32-b54ac43f270e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    dev: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 24000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "407124c2-ead7-4dad-91d5-dfd0a103d09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2db2dd12-4c11-436c-ae8f-53b2af4facf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sequence_length = 128\n",
    "batch_size = 32\n",
    "eval_steps = 100\n",
    "learning_rate=2e-05\n",
    "num_train_epochs=5\n",
    "output_dir = \"../output/\"\n",
    "model_dir = \"../models/\"\n",
    "early_stopping_patience = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f78eba3-68ce-4841-b914-0d417c304de1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97858d750bc844628b992d50b4a45be4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19bc168767344385b9a4fabdc2257f16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d9f01eb6dfc4c9490d46fff87748da3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenize_function(example):\n",
    "    return tokenizer(example[\"text\"],  truncation=True, padding=\"max_length\", max_length=max_sequence_length )\n",
    "\n",
    "\n",
    "tokenized_datasets = imdb.map(tokenize_function, batched=True)\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e52c5fe-b83a-4242-a348-ac7bad7c9106",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['labels', 'input_ids', 'token_type_ids', 'attention_mask']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets = tokenized_datasets.remove_columns([\"text\", ])\n",
    "tokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")\n",
    "tokenized_datasets.set_format(\"torch\")\n",
    "tokenized_datasets[\"train\"].column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96f35ad9-bc7e-47c1-9269-92b22219bcb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.utils.data import DataLoader\n",
    "\n",
    "# train_dataloader = DataLoader(\n",
    "#     tokenized_datasets[\"train\"], shuffle=True, batch_size=16, collate_fn=data_collator\n",
    "# )\n",
    "# dev_dataloader = DataLoader(\n",
    "#     tokenized_datasets[\"dev\"], batch_size=16, collate_fn=data_collator\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87c413aa-a1e4-453d-acf8-ac1142be187f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for batch in train_dataloader:\n",
    "#     break\n",
    "# {k: v.shape for k, v in batch.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c6191ceb-b598-44f7-9af2-84b72dcc59a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, BertForSequenceClassification\n",
    "model = BertForSequenceClassification.from_pretrained(checkpoint, num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10b83c3a-dacd-4074-a33b-8937c54681f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "79bfacb1-1098-450f-a752-54ab607d0d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compute_metrics(eval_preds):\n",
    "#     metric = load_metric(\"imdb)\n",
    "#     logits, labels = eval_preds\n",
    "#     predictions = np.argmax(logits, axis=-1)\n",
    "#     return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "def compute_metrics(p):    \n",
    "    pred, labels = p\n",
    "    pred = np.argmax(pred, axis=1)\n",
    "    accuracy = accuracy_score(y_true=labels, y_pred=pred)\n",
    "    recall = recall_score(y_true=labels, y_pred=pred)\n",
    "    precision = precision_score(y_true=labels, y_pred=pred)\n",
    "    f1 = f1_score(y_true=labels, y_pred=pred)    \n",
    "    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a2dbeb9-6f17-40ba-8d4c-52456aba5a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# training_args = TrainingArguments('bert-base-uncased-imdb', \n",
    "#                                   learning_rate=2e-05,\n",
    "#                                   per_device_train_batch_size =batch_size, \n",
    "#                                   per_device_eval_batch_size =batch_size,\n",
    "\n",
    "#                           )\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "   output_dir+\"bert-base-uncased-imdb\",\n",
    "   evaluation_strategy ='steps',\n",
    "   eval_steps = eval_steps , # Evaluation and Save happens every eval_steps steps\n",
    "   save_total_limit = 1, # Only last  model is saved. Older ones are deleted.\n",
    "   learning_rate=learning_rate,\n",
    "   per_device_train_batch_size=batch_size,\n",
    "   per_device_eval_batch_size=batch_size,\n",
    "   num_train_epochs=num_train_epochs,\n",
    "   metric_for_best_model = 'f1',\n",
    "   load_best_model_at_end=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5c9d9210-6305-4776-aea7-984968dca108",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, EarlyStoppingCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6cc9cffc-2ebc-4b96-b5e8-2925f88c33f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"dev\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    callbacks = [EarlyStoppingCallback(early_stopping_patience=early_stopping_patience)],\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "85e142b9-9a3a-4d18-a73d-9ab3e2951f76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='2700' max='3910' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2700/3910 1:11:43 < 32:09, 0.63 it/s, Epoch 3/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.371974</td>\n",
       "      <td>0.845000</td>\n",
       "      <td>0.798942</td>\n",
       "      <td>0.917004</td>\n",
       "      <td>0.853911</td>\n",
       "      <td>15.256900</td>\n",
       "      <td>65.544000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.349631</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.873913</td>\n",
       "      <td>0.813765</td>\n",
       "      <td>0.842767</td>\n",
       "      <td>15.288600</td>\n",
       "      <td>65.408000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.359376</td>\n",
       "      <td>0.845000</td>\n",
       "      <td>0.869281</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.837356</td>\n",
       "      <td>15.303900</td>\n",
       "      <td>65.343000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.307613</td>\n",
       "      <td>0.870000</td>\n",
       "      <td>0.851351</td>\n",
       "      <td>0.892713</td>\n",
       "      <td>0.871542</td>\n",
       "      <td>15.358400</td>\n",
       "      <td>65.111000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.364500</td>\n",
       "      <td>0.309362</td>\n",
       "      <td>0.856000</td>\n",
       "      <td>0.807018</td>\n",
       "      <td>0.931174</td>\n",
       "      <td>0.864662</td>\n",
       "      <td>15.326100</td>\n",
       "      <td>65.248000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.364500</td>\n",
       "      <td>0.302709</td>\n",
       "      <td>0.867000</td>\n",
       "      <td>0.881607</td>\n",
       "      <td>0.844130</td>\n",
       "      <td>0.862461</td>\n",
       "      <td>15.324400</td>\n",
       "      <td>65.255000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.364500</td>\n",
       "      <td>0.300102</td>\n",
       "      <td>0.871000</td>\n",
       "      <td>0.894168</td>\n",
       "      <td>0.838057</td>\n",
       "      <td>0.865204</td>\n",
       "      <td>15.474900</td>\n",
       "      <td>64.621000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.364500</td>\n",
       "      <td>0.383784</td>\n",
       "      <td>0.866000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.910931</td>\n",
       "      <td>0.870406</td>\n",
       "      <td>15.380100</td>\n",
       "      <td>65.019000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.364500</td>\n",
       "      <td>0.309934</td>\n",
       "      <td>0.874000</td>\n",
       "      <td>0.881743</td>\n",
       "      <td>0.860324</td>\n",
       "      <td>0.870902</td>\n",
       "      <td>15.358900</td>\n",
       "      <td>65.109000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.254600</td>\n",
       "      <td>0.332236</td>\n",
       "      <td>0.872000</td>\n",
       "      <td>0.894397</td>\n",
       "      <td>0.840081</td>\n",
       "      <td>0.866388</td>\n",
       "      <td>15.442700</td>\n",
       "      <td>64.756000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.254600</td>\n",
       "      <td>0.330807</td>\n",
       "      <td>0.871000</td>\n",
       "      <td>0.877847</td>\n",
       "      <td>0.858300</td>\n",
       "      <td>0.867963</td>\n",
       "      <td>15.410900</td>\n",
       "      <td>64.889000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.254600</td>\n",
       "      <td>0.352724</td>\n",
       "      <td>0.872000</td>\n",
       "      <td>0.925581</td>\n",
       "      <td>0.805668</td>\n",
       "      <td>0.861472</td>\n",
       "      <td>15.272800</td>\n",
       "      <td>65.476000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.254600</td>\n",
       "      <td>0.278529</td>\n",
       "      <td>0.881000</td>\n",
       "      <td>0.891441</td>\n",
       "      <td>0.864372</td>\n",
       "      <td>0.877698</td>\n",
       "      <td>15.408200</td>\n",
       "      <td>64.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.254600</td>\n",
       "      <td>0.291371</td>\n",
       "      <td>0.878000</td>\n",
       "      <td>0.854962</td>\n",
       "      <td>0.906883</td>\n",
       "      <td>0.880157</td>\n",
       "      <td>15.427400</td>\n",
       "      <td>64.820000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.208400</td>\n",
       "      <td>0.324827</td>\n",
       "      <td>0.869000</td>\n",
       "      <td>0.904232</td>\n",
       "      <td>0.821862</td>\n",
       "      <td>0.861082</td>\n",
       "      <td>15.338600</td>\n",
       "      <td>65.195000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.208400</td>\n",
       "      <td>0.377024</td>\n",
       "      <td>0.884000</td>\n",
       "      <td>0.898734</td>\n",
       "      <td>0.862348</td>\n",
       "      <td>0.880165</td>\n",
       "      <td>15.414500</td>\n",
       "      <td>64.874000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.208400</td>\n",
       "      <td>0.375274</td>\n",
       "      <td>0.885000</td>\n",
       "      <td>0.881288</td>\n",
       "      <td>0.886640</td>\n",
       "      <td>0.883956</td>\n",
       "      <td>15.367200</td>\n",
       "      <td>65.073000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.208400</td>\n",
       "      <td>0.378904</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.877016</td>\n",
       "      <td>0.880567</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>15.363900</td>\n",
       "      <td>65.088000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.208400</td>\n",
       "      <td>0.410517</td>\n",
       "      <td>0.874000</td>\n",
       "      <td>0.866534</td>\n",
       "      <td>0.880567</td>\n",
       "      <td>0.873494</td>\n",
       "      <td>15.324700</td>\n",
       "      <td>65.254000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.130800</td>\n",
       "      <td>0.404030</td>\n",
       "      <td>0.876000</td>\n",
       "      <td>0.888655</td>\n",
       "      <td>0.856275</td>\n",
       "      <td>0.872165</td>\n",
       "      <td>15.414200</td>\n",
       "      <td>64.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.130800</td>\n",
       "      <td>0.390763</td>\n",
       "      <td>0.883000</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.880567</td>\n",
       "      <td>0.881459</td>\n",
       "      <td>15.341500</td>\n",
       "      <td>65.183000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.130800</td>\n",
       "      <td>0.417967</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.875502</td>\n",
       "      <td>0.882591</td>\n",
       "      <td>0.879032</td>\n",
       "      <td>15.351300</td>\n",
       "      <td>65.141000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.130800</td>\n",
       "      <td>0.390974</td>\n",
       "      <td>0.883000</td>\n",
       "      <td>0.898520</td>\n",
       "      <td>0.860324</td>\n",
       "      <td>0.879007</td>\n",
       "      <td>15.396100</td>\n",
       "      <td>64.952000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.130800</td>\n",
       "      <td>0.479739</td>\n",
       "      <td>0.874000</td>\n",
       "      <td>0.856589</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.875248</td>\n",
       "      <td>15.460500</td>\n",
       "      <td>64.681000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.098400</td>\n",
       "      <td>0.473215</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.883576</td>\n",
       "      <td>0.860324</td>\n",
       "      <td>0.871795</td>\n",
       "      <td>15.392200</td>\n",
       "      <td>64.968000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.098400</td>\n",
       "      <td>0.532294</td>\n",
       "      <td>0.872000</td>\n",
       "      <td>0.889362</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.867220</td>\n",
       "      <td>15.364100</td>\n",
       "      <td>65.087000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.098400</td>\n",
       "      <td>0.536664</td>\n",
       "      <td>0.881000</td>\n",
       "      <td>0.880325</td>\n",
       "      <td>0.878543</td>\n",
       "      <td>0.879433</td>\n",
       "      <td>15.351100</td>\n",
       "      <td>65.142000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2700, training_loss=0.2004435383832013, metrics={'train_runtime': 4304.5331, 'train_samples_per_second': 0.908, 'total_flos': 7258763970957312, 'epoch': 3.45})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4145d88f-d2f0-442e-9c9d-c42b12fe9a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(model_dir+\"bert-base-uncased-imdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4095160f-a46a-4868-9af5-0df727f998b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='750' max='750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [750/750 06:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24000, 2) (24000,)\n"
     ]
    }
   ],
   "source": [
    "predictions = trainer.predict(tokenized_datasets[\"test\"])\n",
    "print(predictions.predictions.shape, predictions.label_ids.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0b3932f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "preds = np.argmax(predictions.predictions, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "03cc8359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.87      0.89     11994\n",
      "           1       0.87      0.90      0.89     12006\n",
      "\n",
      "    accuracy                           0.89     24000\n",
      "   macro avg       0.89      0.89      0.89     24000\n",
      "weighted avg       0.89      0.89      0.89     24000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(predictions.label_ids, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f513159-550f-49d8-aec7-8f33af821bc5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "local_nmt",
   "language": "python",
   "name": "local_nmt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
