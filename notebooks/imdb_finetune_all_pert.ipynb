{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5c2c607-62c8-4664-a080-af75495d11a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from datasets import load_dataset, DatasetDict, load_from_disk\n",
    "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
    "\n",
    "from resilient_nlp.perturbers import WordScramblerPerturber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9256c35-71ed-47ec-8277-3b9d9adcf275",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration redacted--imdb-f63738dec0d5e230\n",
      "Reusing dataset parquet (/home/ec2-user/.cache/huggingface/datasets/parquet/redacted--imdb-f63738dec0d5e230/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3695244847c4c64a1c58e4928bf5572",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#imdb = load_from_disk(\"../data/imdb\")\n",
    "imdb = load_dataset('../output/huggingface/imdb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94b44124-64c6-440b-ba32-b54ac43f270e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    dev: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "    attack_eval_truncated: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 500\n",
       "    })\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 24000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "407124c2-ead7-4dad-91d5-dfd0a103d09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2db2dd12-4c11-436c-ae8f-53b2af4facf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sequence_length = 128\n",
    "batch_size = 32\n",
    "eval_steps = 100\n",
    "learning_rate=2e-05\n",
    "num_train_epochs=5\n",
    "output_dir = \"../output/\"\n",
    "model_dir = \"../models/\"\n",
    "early_stopping_patience = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4727b354",
   "metadata": {},
   "outputs": [],
   "source": [
    "wsp = WordScramblerPerturber(perturb_prob=0.2, weight_add=1.0, weight_drop=1.0, weight_swap=1.0,\n",
    "                             weight_split_word=1.0, weight_merge_words=1.0, start_char_present=True,\n",
    "                             end_char_present=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f78eba3-68ce-4841-b914-0d417c304de1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79354513202b440bb6cf1d5b920db111",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0ex [00:00, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ec89553905244e39a364e53aa3abcc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0ex [00:00, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f932b6e294f45728e8d0c113e12563d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0ex [00:00, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daab1cf4f2974747ace463a354033bd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0ex [00:00, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/ec2-user/.cache/huggingface/datasets/parquet/redacted--imdb-f63738dec0d5e230/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901/cache-bae2e0117af04f74.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d762a87bfe6547eeb2cd163967c885fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/ec2-user/.cache/huggingface/datasets/parquet/redacted--imdb-f63738dec0d5e230/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901/cache-723d494e7290a5a8.arrow\n",
      "Loading cached processed dataset at /home/ec2-user/.cache/huggingface/datasets/parquet/redacted--imdb-f63738dec0d5e230/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901/cache-540b8406383736c0.arrow\n"
     ]
    }
   ],
   "source": [
    "def tokenize_function(example):\n",
    "    return tokenizer(example[\"text\"],  truncation=True, padding=\"max_length\", max_length=max_sequence_length )\n",
    "\n",
    "def perturb_function(example):\n",
    "    example[\"text\"] = wsp.perturb(example[\"text\"])\n",
    "\n",
    "perturbed_datasets = imdb.map(perturb_function)\n",
    "tokenized_datasets = perturbed_datasets.map(tokenize_function, batched=True)\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e52c5fe-b83a-4242-a348-ac7bad7c9106",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['labels', 'input_ids', 'token_type_ids', 'attention_mask']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets = tokenized_datasets.remove_columns([\"text\", ])\n",
    "tokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")\n",
    "tokenized_datasets.set_format(\"torch\")\n",
    "tokenized_datasets[\"train\"].column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96f35ad9-bc7e-47c1-9269-92b22219bcb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.utils.data import DataLoader\n",
    "\n",
    "# train_dataloader = DataLoader(\n",
    "#     tokenized_datasets[\"train\"], shuffle=True, batch_size=16, collate_fn=data_collator\n",
    "# )\n",
    "# dev_dataloader = DataLoader(\n",
    "#     tokenized_datasets[\"dev\"], batch_size=16, collate_fn=data_collator\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87c413aa-a1e4-453d-acf8-ac1142be187f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for batch in train_dataloader:\n",
    "#     break\n",
    "# {k: v.shape for k, v in batch.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c6191ceb-b598-44f7-9af2-84b72dcc59a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, BertForSequenceClassification\n",
    "model = BertForSequenceClassification.from_pretrained(checkpoint, num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10b83c3a-dacd-4074-a33b-8937c54681f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "79bfacb1-1098-450f-a752-54ab607d0d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compute_metrics(eval_preds):\n",
    "#     metric = load_metric(\"imdb)\n",
    "#     logits, labels = eval_preds\n",
    "#     predictions = np.argmax(logits, axis=-1)\n",
    "#     return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "def compute_metrics(p):    \n",
    "    pred, labels = p\n",
    "    pred = np.argmax(pred, axis=1)\n",
    "    accuracy = accuracy_score(y_true=labels, y_pred=pred)\n",
    "    recall = recall_score(y_true=labels, y_pred=pred)\n",
    "    precision = precision_score(y_true=labels, y_pred=pred)\n",
    "    f1 = f1_score(y_true=labels, y_pred=pred)    \n",
    "    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8a2dbeb9-6f17-40ba-8d4c-52456aba5a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# training_args = TrainingArguments('bert-base-uncased-imdb', \n",
    "#                                   learning_rate=2e-05,\n",
    "#                                   per_device_train_batch_size =batch_size, \n",
    "#                                   per_device_eval_batch_size =batch_size,\n",
    "\n",
    "#                           )\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "   output_dir+\"bert-base-uncased-imdb\",\n",
    "   evaluation_strategy ='steps',\n",
    "   eval_steps = eval_steps , # Evaluation and Save happens every eval_steps steps\n",
    "   save_total_limit = 1, # Only last  model is saved. Older ones are deleted.\n",
    "   learning_rate=learning_rate,\n",
    "   per_device_train_batch_size=batch_size,\n",
    "   per_device_eval_batch_size=batch_size,\n",
    "   num_train_epochs=num_train_epochs,\n",
    "   metric_for_best_model = 'f1',\n",
    "   load_best_model_at_end=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5c9d9210-6305-4776-aea7-984968dca108",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, EarlyStoppingCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6cc9cffc-2ebc-4b96-b5e8-2925f88c33f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"dev\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    callbacks = [EarlyStoppingCallback(early_stopping_patience=early_stopping_patience)],\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "85e142b9-9a3a-4d18-a73d-9ab3e2951f76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='2900' max='3910' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2900/3910 14:23 < 05:00, 3.36 it/s, Epoch 3/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.392239</td>\n",
       "      <td>0.835000</td>\n",
       "      <td>0.821918</td>\n",
       "      <td>0.850202</td>\n",
       "      <td>0.835821</td>\n",
       "      <td>2.096100</td>\n",
       "      <td>477.072000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.343418</td>\n",
       "      <td>0.845000</td>\n",
       "      <td>0.877506</td>\n",
       "      <td>0.797571</td>\n",
       "      <td>0.835631</td>\n",
       "      <td>2.116700</td>\n",
       "      <td>472.430000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.347368</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.862705</td>\n",
       "      <td>0.852227</td>\n",
       "      <td>0.857434</td>\n",
       "      <td>2.113700</td>\n",
       "      <td>473.102000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.310695</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.819495</td>\n",
       "      <td>0.919028</td>\n",
       "      <td>0.866412</td>\n",
       "      <td>2.121700</td>\n",
       "      <td>471.321000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.361200</td>\n",
       "      <td>0.306364</td>\n",
       "      <td>0.865000</td>\n",
       "      <td>0.845857</td>\n",
       "      <td>0.888664</td>\n",
       "      <td>0.866732</td>\n",
       "      <td>2.124000</td>\n",
       "      <td>470.804000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.361200</td>\n",
       "      <td>0.313365</td>\n",
       "      <td>0.869000</td>\n",
       "      <td>0.853801</td>\n",
       "      <td>0.886640</td>\n",
       "      <td>0.869911</td>\n",
       "      <td>2.126400</td>\n",
       "      <td>470.270000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.361200</td>\n",
       "      <td>0.328975</td>\n",
       "      <td>0.864000</td>\n",
       "      <td>0.903153</td>\n",
       "      <td>0.811741</td>\n",
       "      <td>0.855011</td>\n",
       "      <td>2.130500</td>\n",
       "      <td>469.369000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.361200</td>\n",
       "      <td>0.334307</td>\n",
       "      <td>0.868000</td>\n",
       "      <td>0.891775</td>\n",
       "      <td>0.834008</td>\n",
       "      <td>0.861925</td>\n",
       "      <td>2.128200</td>\n",
       "      <td>469.876000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.361200</td>\n",
       "      <td>0.342044</td>\n",
       "      <td>0.876000</td>\n",
       "      <td>0.851711</td>\n",
       "      <td>0.906883</td>\n",
       "      <td>0.878431</td>\n",
       "      <td>2.138700</td>\n",
       "      <td>467.569000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.259000</td>\n",
       "      <td>0.326736</td>\n",
       "      <td>0.870000</td>\n",
       "      <td>0.866935</td>\n",
       "      <td>0.870445</td>\n",
       "      <td>0.868687</td>\n",
       "      <td>2.134100</td>\n",
       "      <td>468.586000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.259000</td>\n",
       "      <td>0.330890</td>\n",
       "      <td>0.869000</td>\n",
       "      <td>0.886994</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.863967</td>\n",
       "      <td>2.140300</td>\n",
       "      <td>467.235000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.259000</td>\n",
       "      <td>0.334555</td>\n",
       "      <td>0.877000</td>\n",
       "      <td>0.877800</td>\n",
       "      <td>0.872470</td>\n",
       "      <td>0.875127</td>\n",
       "      <td>2.147100</td>\n",
       "      <td>465.745000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.259000</td>\n",
       "      <td>0.353153</td>\n",
       "      <td>0.868000</td>\n",
       "      <td>0.880252</td>\n",
       "      <td>0.848178</td>\n",
       "      <td>0.863918</td>\n",
       "      <td>2.140400</td>\n",
       "      <td>467.195000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.259000</td>\n",
       "      <td>0.327494</td>\n",
       "      <td>0.874000</td>\n",
       "      <td>0.852490</td>\n",
       "      <td>0.900810</td>\n",
       "      <td>0.875984</td>\n",
       "      <td>2.138700</td>\n",
       "      <td>467.577000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.204900</td>\n",
       "      <td>0.347673</td>\n",
       "      <td>0.869000</td>\n",
       "      <td>0.843100</td>\n",
       "      <td>0.902834</td>\n",
       "      <td>0.871945</td>\n",
       "      <td>2.144800</td>\n",
       "      <td>466.241000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.204900</td>\n",
       "      <td>0.411831</td>\n",
       "      <td>0.870000</td>\n",
       "      <td>0.844697</td>\n",
       "      <td>0.902834</td>\n",
       "      <td>0.872798</td>\n",
       "      <td>2.144300</td>\n",
       "      <td>466.358000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.204900</td>\n",
       "      <td>0.454768</td>\n",
       "      <td>0.870000</td>\n",
       "      <td>0.847328</td>\n",
       "      <td>0.898785</td>\n",
       "      <td>0.872299</td>\n",
       "      <td>2.203100</td>\n",
       "      <td>453.897000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.204900</td>\n",
       "      <td>0.454740</td>\n",
       "      <td>0.874000</td>\n",
       "      <td>0.866534</td>\n",
       "      <td>0.880567</td>\n",
       "      <td>0.873494</td>\n",
       "      <td>2.142800</td>\n",
       "      <td>466.679000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.204900</td>\n",
       "      <td>0.419187</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.871032</td>\n",
       "      <td>0.888664</td>\n",
       "      <td>0.879760</td>\n",
       "      <td>2.146900</td>\n",
       "      <td>465.779000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.124700</td>\n",
       "      <td>0.432926</td>\n",
       "      <td>0.876000</td>\n",
       "      <td>0.900433</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.870293</td>\n",
       "      <td>2.147800</td>\n",
       "      <td>465.597000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.124700</td>\n",
       "      <td>0.440764</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.856867</td>\n",
       "      <td>0.896761</td>\n",
       "      <td>0.876360</td>\n",
       "      <td>2.145700</td>\n",
       "      <td>466.058000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.124700</td>\n",
       "      <td>0.428590</td>\n",
       "      <td>0.874000</td>\n",
       "      <td>0.862205</td>\n",
       "      <td>0.886640</td>\n",
       "      <td>0.874251</td>\n",
       "      <td>2.148400</td>\n",
       "      <td>465.462000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.124700</td>\n",
       "      <td>0.447088</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.893390</td>\n",
       "      <td>0.848178</td>\n",
       "      <td>0.870197</td>\n",
       "      <td>2.140600</td>\n",
       "      <td>467.150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.124700</td>\n",
       "      <td>0.511275</td>\n",
       "      <td>0.879000</td>\n",
       "      <td>0.867850</td>\n",
       "      <td>0.890688</td>\n",
       "      <td>0.879121</td>\n",
       "      <td>2.149400</td>\n",
       "      <td>465.246000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.104600</td>\n",
       "      <td>0.514275</td>\n",
       "      <td>0.869000</td>\n",
       "      <td>0.886994</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.863967</td>\n",
       "      <td>2.145000</td>\n",
       "      <td>466.211000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.104600</td>\n",
       "      <td>0.593743</td>\n",
       "      <td>0.868000</td>\n",
       "      <td>0.826715</td>\n",
       "      <td>0.927126</td>\n",
       "      <td>0.874046</td>\n",
       "      <td>2.144000</td>\n",
       "      <td>466.408000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.104600</td>\n",
       "      <td>0.564402</td>\n",
       "      <td>0.868000</td>\n",
       "      <td>0.878661</td>\n",
       "      <td>0.850202</td>\n",
       "      <td>0.864198</td>\n",
       "      <td>2.150600</td>\n",
       "      <td>464.984000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.104600</td>\n",
       "      <td>0.592584</td>\n",
       "      <td>0.872000</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.838057</td>\n",
       "      <td>0.866109</td>\n",
       "      <td>2.146100</td>\n",
       "      <td>465.959000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.104600</td>\n",
       "      <td>0.554955</td>\n",
       "      <td>0.871000</td>\n",
       "      <td>0.884211</td>\n",
       "      <td>0.850202</td>\n",
       "      <td>0.866873</td>\n",
       "      <td>2.151100</td>\n",
       "      <td>464.869000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2900, training_loss=0.19107767960120892, metrics={'train_runtime': 863.924, 'train_samples_per_second': 4.526, 'total_flos': 7796898636582912, 'epoch': 3.71})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4145d88f-d2f0-442e-9c9d-c42b12fe9a36",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/8f/6jh429wj3sb5ttmqxvss3c1r0000gp/T/ipykernel_9007/1077575558.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_dir\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"test_model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4095160f-a46a-4868-9af5-0df727f998b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='750' max='750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [750/750 00:50]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24000, 2) (24000,)\n"
     ]
    }
   ],
   "source": [
    "predictions = trainer.predict(tokenized_datasets[\"test\"])\n",
    "print(predictions.predictions.shape, predictions.label_ids.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0b3932f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "preds = np.argmax(predictions.predictions, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "03cc8359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.85      0.88     11994\n",
      "           1       0.86      0.92      0.89     12006\n",
      "\n",
      "    accuracy                           0.89     24000\n",
      "   macro avg       0.89      0.89      0.89     24000\n",
      "weighted avg       0.89      0.89      0.89     24000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(predictions.label_ids, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2c5a07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
