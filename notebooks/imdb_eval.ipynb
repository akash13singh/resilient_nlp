{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e638ec17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, DatasetDict, load_from_disk\n",
    "from transformers import AutoTokenizer, DataCollatorWithPadding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb285594",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb = load_from_disk(\"../data/imdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "607f78c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b48113da",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sequence_length = 128\n",
    "batch_size = 32\n",
    "eval_steps = 100\n",
    "learning_rate=2e-05\n",
    "num_train_epochs=5\n",
    "output_dir = \"../output/\"\n",
    "model_dir = \"../models/\"\n",
    "early_stopping_patience = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "595715ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd3327160c0f4e52a4fda847cde3e742",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40d14b0e7ea247a4b3f6844efee9dc3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2145ff09698c42f691a69461c5780dc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenize_function(example):\n",
    "    return tokenizer(example[\"text\"],  truncation=True, padding=\"max_length\", max_length=max_sequence_length )\n",
    "\n",
    "\n",
    "tokenized_datasets = imdb.map(tokenize_function, batched=True)\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae5d23f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['labels', 'input_ids', 'token_type_ids', 'attention_mask']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets = tokenized_datasets.remove_columns([\"text\", ])\n",
    "tokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")\n",
    "tokenized_datasets.set_format(\"torch\")\n",
    "tokenized_datasets[\"train\"].column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29d83ad8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    dev: Dataset({\n",
       "        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 24000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24f9065e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, BertForSequenceClassification\n",
    "model_finetuned = BertForSequenceClassification.from_pretrained(\"artemis13fowl/bert-base-uncased-imdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79665051",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_finetuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bffec05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, classification_report\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b13e0815",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(p):    \n",
    "    pred, labels = p\n",
    "    pred = np.argmax(pred, axis=1)\n",
    "    accuracy = accuracy_score(y_true=labels, y_pred=pred)\n",
    "    recall = recall_score(y_true=labels, y_pred=pred)\n",
    "    precision = precision_score(y_true=labels, y_pred=pred)\n",
    "    f1 = f1_score(y_true=labels, y_pred=pred)    \n",
    "    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "928dca3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "   output_dir+\"bert-base-uncased-imdb\",\n",
    "   evaluation_strategy ='steps',\n",
    "   eval_steps = eval_steps , # Evaluation and Save happens every eval_steps steps\n",
    "   save_total_limit = 1, # Only last  model is saved. Older ones are deleted.\n",
    "   learning_rate=learning_rate,\n",
    "   per_device_train_batch_size=batch_size,\n",
    "   per_device_eval_batch_size=batch_size,\n",
    "   num_train_epochs=num_train_epochs,\n",
    "   metric_for_best_model = 'f1',\n",
    "   load_best_model_at_end=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "18d05481",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_eval = Trainer(\n",
    "    model_finetuned,\n",
    "    training_args,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed98450f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 24000\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "073faa20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [32/32 03:36]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 2) (1000,)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.86      0.89       511\n",
      "           1       0.86      0.92      0.89       489\n",
      "\n",
      "    accuracy                           0.89      1000\n",
      "   macro avg       0.89      0.89      0.89      1000\n",
      "weighted avg       0.89      0.89      0.89      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = trainer_eval.predict(tokenized_datasets[\"test\"].shuffle().select(range(1000)))\n",
    "print(predictions.predictions.shape, predictions.label_ids.shape)\n",
    "preds = np.argmax(predictions.predictions, axis=-1)\n",
    "print(classification_report(predictions.label_ids, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b303074",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import create_repo\n",
    "create_repo(\"bert-base-uncased-imdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8d2c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import upload_file\n",
    "\n",
    "upload_file(\n",
    "    model_dir+\"bert-base-uncased-imdb\"+\"/config.json\",\n",
    "    path_in_repo=\"config.json\",\n",
    "    repo_id=\"artemis13fowl/bert-base-uncased-imdb\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec54c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import Repository\n",
    "\n",
    "repo = Repository(\"huggingface_repo1\", clone_from=\"artemis13fowl/bert-base-uncased-imdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8625c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo.git_pull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f188adef",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_finetuned.save_pretrained(\"huggingface_repo1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1740bcf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo.git_add()\n",
    "repo.git_commit(\"Add bert-base-uncased-imdb\")\n",
    "repo.git_push()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bcef4d8",
   "metadata": {},
   "source": [
    "### Common sense eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "4a1aa34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "6025a027",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 7592, 2182, 1045, 2572, 1059, 5886, 2890, 2024, 2017, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"Hello here i am wherre are you\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "cc3d2f4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 7592, 102], 'token_type_ids': [0, 0, 0], 'attention_mask': [1, 1, 1]}"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"Hello here i am wherre are you\",truncation=True, padding=\"max_length\", max_length=3 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "811fe907",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101, 7592, 2182, 1045, 2572, 1059, 5886, 2890, 2024, 2017, 102]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"Hello here i am wherre are you\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "298c21e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 7592, 2182, 1045, 2572, 1059, 5886, 2890, 2024, 2017, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode_plus(\"Hello here i am wherre are you\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "c7acee51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] hello here i am wherre are you [SEP]'"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([101, 7592, 2182, 1045, 2572, 1059, 5886, 2890, 2024, 2017, 102])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "f00b8fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "pipe = pipeline(\"sentiment-analysis\", model=model_finetuned, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "cb6b53c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = imdb['test'].shuffle().select(range(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "5df6e5b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "0 I'm a big fan of the \"Vacation\" franchise, and I love Randy Quaid as Cousin Eddie, and at least a couple of the behind-the-scenes names were involved in this project (most notably Matty Simmons, who produced or executive-produced all 4 of the theatrical releases, as well as \"Animal House\"). For those reasons I figured this made-for-TV spin off might be worth checking out, even without Chevy Chase.<br /><br />For the record, I did not expect it to be very good; I just thought it might be a slightly amusing diversion. Therefore, my high level of disappointment goes to prove just how bad this utter turd of a movie really was. It was mind-numbingly, jaw-droppingly, heart-stoppingly, head-explodingly terrible. Yet, somehow, I could not stop watching it. It's a sickness I have; I can't seem to walk out on a film or give up on a TV show before it ends. Nothing has ever made me want two hours of my life back more than this movie.\n",
      "935 165\n",
      "[{'label': 'LABEL_0', 'score': 0.9992308616638184}]\n",
      "--------------------\n",
      "0 This is supposedly a story in which a GROWN MAN tells a story about his youth. Yet, you see things like personal computers, e-mails, faxes, etc, which are items used in the late 20th Century and early 21st. <br /><br />So when is this guy supposed to be telling this story - in 2020. Gee, I wonder how advanced we are then. How about telling us that.<br /><br />Also, there are several legal issues which also make no sense. In the courtroom scene, the story falls into the usual pratfalls of surprise evidence, which is inadmissible in any real court of law in this country. Also, Grandma would have to be missing at least seven years in most states before to be declared officially dead.<br /><br />Congratulations Elmo Shropshire. You are now officially a SELLOUT.\n",
      "767 135\n",
      "[{'label': 'LABEL_0', 'score': 0.9776517748832703}]\n",
      "--------------------\n",
      "0 I spent three months living in the East End of London in the latter half of 1987, when the show had been on the air for almost two years. It was considered a running joke there.<br /><br />Why? Because it had an all-white cast. Every cast member and extra in the first couple of years was white.<br /><br />The street where I lived was a long one, with over 800 houses, and to the best of my knowledge I was one of only three or four white faces living on that street. We were on the corner of the Indian and Turkish \"quarters\", and even if you excluded those two races the Asians and Afro-Caribbeans outnumbered the white people twenty-to-one. Plus, of course, of the very few white people who *did* live in the area, the vast majority were Scots like me - a \"Cockney\" accent was never heard.<br /><br />That wasn't a racist rant, just a simple statement of fact. The BBC either couldn't be bothered crossing London to do their research before writing this soap, or else they only had white actors available and decided to bluff it out.<br /><br />Either way, as I say, in the East End of the time, we considered it a comedy show. :-)\n",
      "1135 211\n",
      "[{'label': 'LABEL_0', 'score': 0.8678964376449585}]\n",
      "--------------------\n",
      "1 I'ts like going around in a museum. You can appreciate the great talent of the main composer, Michael Cimino & this fabulous art desinger of light ..Vilmos Zsigmond. As I said I'ts like being in heaven discovering all the creation this man can applied to a single frame. Imagine when you can look at a moving picture of this artist. I can say: this film is one of the best.\n",
      "373 70\n",
      "[{'label': 'LABEL_1', 'score': 0.9992038607597351}]\n",
      "--------------------\n",
      "0 After watching this movie on a boring Saturday afternoon, I couldn't quite figure out why so many people liked it. It wasn't \"heartwarming\" or \"clever\"; it was merely an amalgam of every other \"mismatched people coming together during a holiday and despite their ideological differences learning something about each other\" movie ever made.<br /><br />The characters are a stereotype bouillabaisse -- We have the Blacks, the Hispanics, The Jews, The Asians, and the Homosexuals -- and they never do anything except what everyone expects characters in a movie like this to do. The black mother declares that it's \"all right, then\" when it's mentioned that another black character is at church instead of helping prepare dinner (because all blacks love church), the Hispanics seem only capable of speaking Spanish when the greet each other or make exclamations, the lesbians do nothing but cuddle and kiss (and one of them wears a bandanna. Because all lesbians dress like Ani DiFranco), and the Vietnamese family owns a video store. In L.A. Imagine that.<br /><br />Oh, and the movie is called \"What's Cooking\" because each ethnic family cooks a different version of what they think Thanksgiving dinner should be! The Black mother wants cornbread and macaroni and cheese, the Hispanics are shown rolling tortillas, the Vietnamese family is deep frying spring rolls; I'm surprised there wasn't a bottle of Manischewitz on the Jewish table. This is all shown via the time-honored tradition of the \"musical-montage\", where they play the Surfari's \"Wipeout\", rapidly switching the instruments used in the melody to reflect the respective cultures. Isn't that cute? Anyway, once the director is finished establishing how different everyone is, he attempts to show the inner humanity that we, as all people of every race, religion and culture share, by inventing implausible and overly dramatic conflicts for each of the families to deal with. It would be a plot-killer to mention what each of these conflicts are, but rest assured that they are indeed surprises, that is if you have been sleeping for the first half of the movie. The theme of \"disgracing the family\" runs pretty strong throughout.<br /><br />All in all, if you're the type of person who enjoys those new-fangled movies that revolve around the stories of unlikely characters intertwining, well, you still won't like this movie. If you like extended montages of food being passed around a table, then you need to put this in your Netflix queue. But if stereotypes and clichÃ©s are endearing to you, then make sure you ask for this for Christmas. Or Hanukkah. Or Kwanzaa.\n",
      "2628 429\n",
      "[{'label': 'LABEL_0', 'score': 0.993457019329071}]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(5):\n",
    "    print('-'*20)\n",
    "    text = sample[i]['text']\n",
    "    label = sample[i]['label']\n",
    "    print(label, text )\n",
    "    print(len(text), len(text.split()))\n",
    "    text_trunc = \" \".join(text.split()[:200])\n",
    "    print(pipe(text_trunc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "55c1d876",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_0', 'score': 0.9981714487075806}]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe(\"Latest attempt to revive the series actually based on a pretty good idea but without the required gore fx/violence for this type of thriller - and thus... BORING!! Good special fx, sets, costumes, etc. but the film comes of just plain silly and a near-waste of time... hopefully the next installment will correct this problem.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "4da3fdd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_1', 'score': 0.9867995381355286}]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#waste -> easte\n",
    "pipe(\"Latest attempt to revive the series actually based on a pretty good idea but without the required gore fx/violence for this type of thriller - and thus... BORING!! Good special fx, sets, costumes, etc. but the film comes of just plain sally and a near-easte of time... hopefully the next installment will correct this problem.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f9e2bd4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Oh If any day u wanna see a supernatural thriller turning out to be a comedy watch this movie<br /><br />\\nThis film was a shocker as it had so many actors in it but what they do and how they fit in?<br /><br />\\nThe handling of the college scenes is like a school play where each person comes talk and then the next person comes infront<br /><br />\\nOkay reasons to laugh at the film: 1) Akshay, Suneil, Aditya Panscholi, Sharad Kapoor, Arshad Warsi as college students \\n2)Akshay carries a gun in college 3) some pathetic stunts and SFX<br /><br />\\nthere are several more flaws like why doesn't the snake save his lover from being raped and comes in so late? \\nalso why he doesn't kill all of them together there only?<br /><br />But afterall they have to make a 2 hrs + film \\nso hence you have a tortorius movie<br /><br />The movie is painful to watch The film was directed by Rajkumar Kohli who was an expert \\nmaking such films in the past and had a successful record of films like JAANI DUSHMAN(1979) and NAGIN \\nRajkumar Kohli wants to help his son's non existent career Right from VIRODHI(1992),Aulad Ke Dushman (1993) and QAHAR(1996) \\nall flops he tried hard to promote his son and he also casts big stars so that his son gets noticed, sadly nothing could help his son's career\\n<br /><br />The film has several comical scenes like the death scenes, how the actors after being bashed by the snake are so fit to fight him \\nagain and the climax<br /><br />Direction by Rajkumar Kohli is bad Music is \""
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = \"\"\"Oh If any day u wanna see a supernatural thriller turning out to be a comedy watch this movie<br /><br />\n",
    "This film was a shocker as it had so many actors in it but what they do and how they fit in?<br /><br />\n",
    "The handling of the college scenes is like a school play where each person comes talk and then the next person comes infront<br /><br />\n",
    "Okay reasons to laugh at the film: 1) Akshay, Suneil, Aditya Panscholi, Sharad Kapoor, Arshad Warsi as college students \n",
    "2)Akshay carries a gun in college 3) some pathetic stunts and SFX<br /><br />\n",
    "there are several more flaws like why doesn't the snake save his lover from being raped and comes in so late? \n",
    "also why he doesn't kill all of them together there only?<br /><br />But afterall they have to make a 2 hrs + film \n",
    "so hence you have a tortorius movie<br /><br />The movie is painful to watch The film was directed by Rajkumar Kohli who was an expert \n",
    "making such films in the past and had a successful record of films like JAANI DUSHMAN(1979) and NAGIN \n",
    "Rajkumar Kohli wants to help his son's non existent career Right from VIRODHI(1992),Aulad Ke Dushman (1993) and QAHAR(1996) \n",
    "all flops he tried hard to promote his son and he also casts big stars so that his son gets noticed, sadly nothing could help his son's career\n",
    "<br /><br />The film has several comical scenes like the death scenes, how the actors after being bashed by the snake are so fit to fight him \n",
    "again and the climax<br /><br />Direction by Rajkumar Kohli is bad Music is bad<br /><br />That brings us to the cast \n",
    "Akshay Kumar - ordinary stuff, he has nothing much to do rather then stunts Suneil Shetty- awful Sonu Nigam- the worst debutante award goes \n",
    "to him, he gives cartoon acting a new meaning Aftab- terrible Arshad Warsi- nothing to do Sharad Kapoor- bad Aditya Panscholi- irritates \n",
    "Sunny Deol- is comical in the scene when he comes to save Sonu LOL Manisha Koirala- ordinary Rambha- Akshay's pair Kiran Kumar, \n",
    "Raza Murad are as usual Raj Babbar- hilarious for wrong reasons the girls are awful Which brings us to Munish Kohli \n",
    "This guy has a huge physique, he is even more stronger and taller then Akshay Kumar Sadly he comes across as poor man's Akshay \n",
    "His voice is awful, his expressions are painful The only thing he has to do in the movie is wear glasses and make an evil face \n",
    "Rajat Bedi is awful\n",
    "\"\"\"\n",
    "\n",
    "sent[:1500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "5e449b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb['train'].set_format(\"pandas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "1e6dcfc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I rented I AM CURIOUS-YELLOW from my video sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"I Am Curious: Yellow\" is a risible and preten...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>If only to avoid making this type of film in t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This film was probably inspired by Godard's Ma...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Oh, brother...after hearing about this ridicul...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  I rented I AM CURIOUS-YELLOW from my video sto...      0\n",
       "1  \"I Am Curious: Yellow\" is a risible and preten...      0\n",
       "2  If only to avoid making this type of film in t...      0\n",
       "3  This film was probably inspired by Godard's Ma...      0\n",
       "4  Oh, brother...after hearing about this ridicul...      0"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb['train'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e381c9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
