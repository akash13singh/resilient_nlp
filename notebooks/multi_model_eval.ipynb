{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "67daa863",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import copy\n",
    "import cProfile\n",
    "from datasets import load_dataset\n",
    "import math\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer, DataCollatorWithPadding, \\\n",
    "                         AutoModelForSequenceClassification, BertForSequenceClassification\n",
    "\n",
    "from resilient_nlp.mini_roben import Clustering, ClusterRepRecoverer, ClusterRecovererWithPassthrough\n",
    "from resilient_nlp.models import BertClassifier\n",
    "from resilient_nlp.perturbers import ToyPerturber, WordScramblerPerturber\n",
    "from runner import ExperimentRunner\n",
    "from word_score_attack import BertWordScoreAttack\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ae7a7c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration artemis13fowl--imdb-f63738dec0d5e230\n",
      "Reusing dataset parquet (/home/scpdxcs/.cache/huggingface/datasets/parquet/artemis13fowl--imdb-f63738dec0d5e230/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71c411dc790a40cab66ee2f78b486f32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# imdb = load_dataset('imdb')\n",
    "imdb = load_dataset('artemis13fowl/imdb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "9bc64b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(11)\n",
    "sampled_test_set = imdb['attack_eval_truncated'].select(range(31))\n",
    "\n",
    "# This is silly but apparently huggingface datasets are immutable?\n",
    "# Representing it as something a bit more sane\n",
    "sampled_test_set_dict = [\n",
    "    {\n",
    "        'text': row['text'],\n",
    "        'label': row['label'],\n",
    "    }\n",
    "    for row in sampled_test_set\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17700b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a09ce62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_finetuned = \"artemis13fowl/bert-base-uncased-imdb\"\n",
    "model_finetuned = BertForSequenceClassification.from_pretrained(checkpoint_finetuned).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b3c3fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "roben_clustering = Clustering.from_pickle(\"../vocab100000_ed1.pkl\")\n",
    "roben_recoverer = ClusterRecovererWithPassthrough(\"cache\", roben_clustering)\n",
    "roben_clustering2 = Clustering.from_pickle(\"../vocab100000_ed1_gamma0.3.pkl\")\n",
    "roben_recoverer2 = ClusterRecovererWithPassthrough(\"cache\", roben_clustering2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "effea54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(11)\n",
    "sampled_test_set_adv_no_ws = []\n",
    "wsp = WordScramblerPerturber(perturb_prob=0.1, weight_add=1, weight_drop=1, weight_swap=1,\n",
    "                             weight_split_word=0, weight_merge_words=0)\n",
    "\n",
    "for i in range(10):\n",
    "    test_item = copy.deepcopy(sampled_test_set_dict)\n",
    "\n",
    "    for row in test_item:\n",
    "        row['text'] = wsp.perturb([row['text']])[0][0]\n",
    "    sampled_test_set_adv_no_ws.append(test_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "651ef05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(11)\n",
    "sampled_test_set_adv_incl_ws = []\n",
    "wsp = WordScramblerPerturber(perturb_prob=0.1, weight_add=1, weight_drop=1, weight_swap=1,\n",
    "                             weight_split_word=1, weight_merge_words=1)\n",
    "\n",
    "for i in range(10):\n",
    "    test_item = copy.deepcopy(sampled_test_set_dict)\n",
    "\n",
    "    for row in test_item:\n",
    "        row['text'] = wsp.perturb([row['text']])[0][0]\n",
    "    sampled_test_set_adv_incl_ws.append(test_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2efe10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sequence_length = 128\n",
    "batch_size = 32\n",
    "eval_steps = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b958a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_model_predict(tokenizer, model, sentences, recoverer, return_pred_tensor):\n",
    "    if recoverer is not None:\n",
    "        sentences = [ recoverer.recover(s.lower()) for s in sentences ]\n",
    "    tokenized = tokenizer(sentences, truncation=True, padding='max_length', max_length=max_sequence_length,\n",
    "                          return_tensors='pt')\n",
    "    tokenized = { k: v.to(device) for k, v in tokenized.items() }\n",
    "    preds = model(**tokenized)\n",
    "    if return_pred_tensor:\n",
    "        return preds\n",
    "    else:\n",
    "        return torch.argmax(preds.logits, dim=1)\n",
    "\n",
    "def wrap_standard_model(tokenizer, model, recoverer=None, return_pred_tensor=True):\n",
    "    return lambda sentences: standard_model_predict(tokenizer, model, sentences, recoverer, return_pred_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ba7bb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mltokenizer_model_predict(runner, model, cls_embedding, sep_embedding, pad_embedding, sentences, return_pred_tensor):\n",
    "    # Truncate and lower case. Truncation is for performance only\n",
    "    sentences = [ s.lower()[:5*max_sequence_length] for s in sentences]\n",
    "    embedding = runner.embed(sentences=sentences,\n",
    "        start_token=cls_embedding, end_token=sep_embedding, pad_token=pad_embedding,\n",
    "        max_tokens=max_sequence_length)\n",
    "    preds = model(inputs_embeds=embedding['inputs_embeds'], attention_mask=embedding['attention_mask'])\n",
    "    if return_pred_tensor:\n",
    "        return preds\n",
    "    else:\n",
    "        return torch.argmax(preds.logits, dim=1)\n",
    "\n",
    "def wrap_mltokenizer_model(mltokenizer_prefix, tokenizer, model, return_pred_tensor=True):\n",
    "    filename = \"../{}.pth\".format(mltokenizer_prefix)\n",
    "    runner = ExperimentRunner(device, model_filename=filename)\n",
    "    cf_embedding = model.base_model.embeddings.word_embeddings\n",
    "    cls_token_id = tokenizer.vocab['[CLS]']\n",
    "    sep_token_id = tokenizer.vocab['[SEP]']\n",
    "    pad_token_id = tokenizer.vocab['[PAD]']\n",
    "    cls_embedding = cf_embedding(torch.tensor([cls_token_id], device=device)).view(-1)\n",
    "    sep_embedding = cf_embedding(torch.tensor([sep_token_id], device=device)).view(-1)\n",
    "    pad_embedding = cf_embedding(torch.tensor([pad_token_id], device=device)).view(-1)\n",
    "    \n",
    "    return lambda sentences: mltokenizer_model_predict(runner, model, cls_embedding, sep_embedding,\n",
    "                                                      pad_embedding, sentences, return_pred_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "2033ec30",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate_model(model, test_set):\n",
    "    num_batches = math.ceil(len(test_set) / batch_size)\n",
    "    \n",
    "    sentences = [ x['text'] for x in test_set ]\n",
    "    labels = [ x['label'] for x in test_set ]\n",
    "    pred_batches = []\n",
    "    \n",
    "    for i in tqdm(range(num_batches)):\n",
    "        bs = i * batch_size\n",
    "        be = bs + batch_size\n",
    "        \n",
    "        output = model(sentences[bs:be])\n",
    "        \n",
    "        pred_batches.append(torch.argmax(output.logits, dim=1).detach().cpu())\n",
    "    preds = torch.cat(pred_batches)\n",
    "    \n",
    "    print(classification_report(labels, preds, digits=4))\n",
    "    \n",
    "    accuracy = accuracy_score(labels, preds)\n",
    "    f1 = f1_score(labels, preds, average='macro')\n",
    "    \n",
    "    return accuracy, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "33c8259a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate_model_adv(model, test_sets):\n",
    "    labels = [ x['label'] for x in test_sets[0] ]\n",
    "    adv_preds = copy.copy(labels)\n",
    "    accuracy_list = []\n",
    "    f1_list = []\n",
    "    \n",
    "    for idx in tqdm(range(len(test_sets))):\n",
    "        test_set = test_sets[idx]\n",
    "        num_batches = math.ceil(len(test_set) / batch_size)\n",
    "    \n",
    "        sentences = [ x['text'] for x in test_set ]\n",
    "        pred_batches = []\n",
    "    \n",
    "        for i in range(num_batches):\n",
    "            bs = i * batch_size\n",
    "            be = bs + batch_size\n",
    "        \n",
    "            output = model(sentences[bs:be])\n",
    "        \n",
    "            pred_batches.append(torch.argmax(output.logits, dim=1).detach().cpu())\n",
    "        preds = torch.cat(pred_batches)\n",
    "        \n",
    "        for i in range(len(adv_preds)):\n",
    "            if labels[i] == 1.0 and preds[i] == 0.0:\n",
    "                adv_preds[i] = 0.0\n",
    "            elif labels[i] == 0.0 and preds[i] == 1.0:\n",
    "                adv_preds[i] = 1.0\n",
    "\n",
    "        accuracy_list.append(accuracy_score(labels, adv_preds))\n",
    "        f1_list.append(f1_score(labels, adv_preds, average='macro'))\n",
    "    \n",
    "    print(classification_report(labels, adv_preds, digits=4))    \n",
    "    \n",
    "    return accuracy_list, f1_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "26be9ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate_model_word_score(model, test_set, allow_whitespace_pert=True):\n",
    "    attacker = BertWordScoreAttack(\n",
    "        WordScramblerPerturber(perturb_prob=1, weight_add=1, weight_drop=1, weight_swap=1,\n",
    "                               weight_split_word=int(allow_whitespace_pert),\n",
    "                               weight_merge_words=int(allow_whitespace_pert)),\n",
    "        \"../output/imdb_word_scores.json\", model, tokenizer=None, max_sequence_length=max_sequence_length\n",
    "    )\n",
    "\n",
    "    res = attacker.attack(test_set, max_tokens_to_query=10, max_tries_per_token=2, mode=0, print_summary=False)\n",
    "    \n",
    "    print(classification_report(res['ground_truth'], res['perturbed_preds'], digits=4))    \n",
    "    \n",
    "    accuracy = accuracy_score(res['ground_truth'], res['perturbed_preds'])\n",
    "    f1 = f1_score(res['ground_truth'], res['perturbed_preds'], average='macro')\n",
    "    \n",
    "    return accuracy, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b537d1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model = wrap_standard_model(tokenizer, model_finetuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f5364f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mltok_model = wrap_mltokenizer_model('output/64k_lstm_all_pert_finetuned', tokenizer, model_finetuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6e49764a",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_roben_model = wrap_standard_model(tokenizer, model_finetuned, roben_recoverer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0eb23d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_roben_model2 = wrap_standard_model(tokenizer, model_finetuned, roben_recoverer2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3b6fcd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_models = {\n",
    "    'baseline': baseline_model,\n",
    "    'roben_1': baseline_roben_model,\n",
    "    'roben_2': baseline_roben_model2,\n",
    "}\n",
    "\n",
    "mltok_model_names = [\n",
    "    '64k_lstm_clean_vanilla',\n",
    "    '64k_lstm_no_whitespace_pert_vanilla',\n",
    "    '64k_lstm_all_pert_vanilla',\n",
    "    '64k_lstm_clean_finetuned',\n",
    "    '64k_lstm_no_whitespace_pert_finetuned',\n",
    "    '64k_lstm_all_pert_finetuned',\n",
    "    '64k_cnn_no_whitespace_pert_finetuned',\n",
    "]\n",
    "\n",
    "for name in mltok_model_names:\n",
    "    all_models[name] = wrap_mltokenizer_model(f'output/{name}', tokenizer, model_finetuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e61f9273",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluations = [\n",
    "    'clean',\n",
    "    'stochastic_no_ws',\n",
    "    'stochastic_incl_ws',\n",
    "    'word_score_no_ws',\n",
    "    'word_score_incl_ws',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "602a9ff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model baseline on clean\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    0.9231    0.9600        13\n",
      "           1     0.9474    1.0000    0.9730        18\n",
      "\n",
      "    accuracy                         0.9677        31\n",
      "   macro avg     0.9737    0.9615    0.9665        31\n",
      "weighted avg     0.9694    0.9677    0.9675        31\n",
      "\n",
      "Evaluating model baseline on stochastic_no_ws\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:04<00:00,  2.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8000    0.6154    0.6957        13\n",
      "           1     0.7619    0.8889    0.8205        18\n",
      "\n",
      "    accuracy                         0.7742        31\n",
      "   macro avg     0.7810    0.7521    0.7581        31\n",
      "weighted avg     0.7779    0.7742    0.7682        31\n",
      "\n",
      "Evaluating model baseline on stochastic_incl_ws\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:04<00:00,  2.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9000    0.6923    0.7826        13\n",
      "           1     0.8095    0.9444    0.8718        18\n",
      "\n",
      "    accuracy                         0.8387        31\n",
      "   macro avg     0.8548    0.8184    0.8272        31\n",
      "weighted avg     0.8475    0.8387    0.8344        31\n",
      "\n",
      "Evaluating model baseline on word_score_no_ws\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31it [00:14,  2.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6923    0.6923    0.6923        13\n",
      "           1     0.7778    0.7778    0.7778        18\n",
      "\n",
      "    accuracy                         0.7419        31\n",
      "   macro avg     0.7350    0.7350    0.7350        31\n",
      "weighted avg     0.7419    0.7419    0.7419        31\n",
      "\n",
      "Evaluating model baseline on word_score_incl_ws\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31it [00:14,  2.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6154    0.6154    0.6154        13\n",
      "           1     0.7222    0.7222    0.7222        18\n",
      "\n",
      "    accuracy                         0.6774        31\n",
      "   macro avg     0.6688    0.6688    0.6688        31\n",
      "weighted avg     0.6774    0.6774    0.6774        31\n",
      "\n",
      "Evaluating model roben_1 on clean\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8182    0.6923    0.7500        13\n",
      "           1     0.8000    0.8889    0.8421        18\n",
      "\n",
      "    accuracy                         0.8065        31\n",
      "   macro avg     0.8091    0.7906    0.7961        31\n",
      "weighted avg     0.8076    0.8065    0.8035        31\n",
      "\n",
      "Evaluating model roben_1 on stochastic_no_ws\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:04<00:00,  2.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7778    0.5385    0.6364        13\n",
      "           1     0.7273    0.8889    0.8000        18\n",
      "\n",
      "    accuracy                         0.7419        31\n",
      "   macro avg     0.7525    0.7137    0.7182        31\n",
      "weighted avg     0.7485    0.7419    0.7314        31\n",
      "\n",
      "Evaluating model roben_1 on stochastic_incl_ws\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:04<00:00,  2.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.4444    0.3077    0.3636        13\n",
      "           1     0.5909    0.7222    0.6500        18\n",
      "\n",
      "    accuracy                         0.5484        31\n",
      "   macro avg     0.5177    0.5150    0.5068        31\n",
      "weighted avg     0.5295    0.5484    0.5299        31\n",
      "\n",
      "Evaluating model roben_1 on word_score_no_ws\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31it [00:12,  2.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6667    0.4615    0.5455        13\n",
      "           1     0.6818    0.8333    0.7500        18\n",
      "\n",
      "    accuracy                         0.6774        31\n",
      "   macro avg     0.6742    0.6474    0.6477        31\n",
      "weighted avg     0.6755    0.6774    0.6642        31\n",
      "\n",
      "Evaluating model roben_1 on word_score_incl_ws\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31it [00:12,  2.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6250    0.3846    0.4762        13\n",
      "           1     0.6522    0.8333    0.7317        18\n",
      "\n",
      "    accuracy                         0.6452        31\n",
      "   macro avg     0.6386    0.6090    0.6039        31\n",
      "weighted avg     0.6408    0.6452    0.6246        31\n",
      "\n",
      "Evaluating model roben_2 on clean\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8333    0.7692    0.8000        13\n",
      "           1     0.8421    0.8889    0.8649        18\n",
      "\n",
      "    accuracy                         0.8387        31\n",
      "   macro avg     0.8377    0.8291    0.8324        31\n",
      "weighted avg     0.8384    0.8387    0.8377        31\n",
      "\n",
      "Evaluating model roben_2 on stochastic_no_ws\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:04<00:00,  2.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8182    0.6923    0.7500        13\n",
      "           1     0.8000    0.8889    0.8421        18\n",
      "\n",
      "    accuracy                         0.8065        31\n",
      "   macro avg     0.8091    0.7906    0.7961        31\n",
      "weighted avg     0.8076    0.8065    0.8035        31\n",
      "\n",
      "Evaluating model roben_2 on stochastic_incl_ws\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:04<00:00,  2.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5455    0.4615    0.5000        13\n",
      "           1     0.6500    0.7222    0.6842        18\n",
      "\n",
      "    accuracy                         0.6129        31\n",
      "   macro avg     0.5977    0.5919    0.5921        31\n",
      "weighted avg     0.6062    0.6129    0.6070        31\n",
      "\n",
      "Evaluating model roben_2 on word_score_no_ws\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31it [00:12,  2.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7000    0.5385    0.6087        13\n",
      "           1     0.7143    0.8333    0.7692        18\n",
      "\n",
      "    accuracy                         0.7097        31\n",
      "   macro avg     0.7071    0.6859    0.6890        31\n",
      "weighted avg     0.7083    0.7097    0.7019        31\n",
      "\n",
      "Evaluating model roben_2 on word_score_incl_ws\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31it [00:12,  2.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6667    0.6154    0.6400        13\n",
      "           1     0.7368    0.7778    0.7568        18\n",
      "\n",
      "    accuracy                         0.7097        31\n",
      "   macro avg     0.7018    0.6966    0.6984        31\n",
      "weighted avg     0.7074    0.7097    0.7078        31\n",
      "\n",
      "Evaluating model 64k_lstm_clean_vanilla on clean\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8462    0.8462    0.8462        13\n",
      "           1     0.8889    0.8889    0.8889        18\n",
      "\n",
      "    accuracy                         0.8710        31\n",
      "   macro avg     0.8675    0.8675    0.8675        31\n",
      "weighted avg     0.8710    0.8710    0.8710        31\n",
      "\n",
      "Evaluating model 64k_lstm_clean_vanilla on stochastic_no_ws\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:28<00:00,  2.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6429    0.6923    0.6667        13\n",
      "           1     0.7647    0.7222    0.7429        18\n",
      "\n",
      "    accuracy                         0.7097        31\n",
      "   macro avg     0.7038    0.7073    0.7048        31\n",
      "weighted avg     0.7136    0.7097    0.7109        31\n",
      "\n",
      "Evaluating model 64k_lstm_clean_vanilla on stochastic_incl_ws\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:28<00:00,  2.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6000    0.6923    0.6429        13\n",
      "           1     0.7500    0.6667    0.7059        18\n",
      "\n",
      "    accuracy                         0.6774        31\n",
      "   macro avg     0.6750    0.6795    0.6744        31\n",
      "weighted avg     0.6871    0.6774    0.6795        31\n",
      "\n",
      "Evaluating model 64k_lstm_clean_vanilla on word_score_no_ws\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31it [02:35,  5.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.4667    0.5385    0.5000        13\n",
      "           1     0.6250    0.5556    0.5882        18\n",
      "\n",
      "    accuracy                         0.5484        31\n",
      "   macro avg     0.5458    0.5470    0.5441        31\n",
      "weighted avg     0.5586    0.5484    0.5512        31\n",
      "\n",
      "Evaluating model 64k_lstm_clean_vanilla on word_score_incl_ws\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31it [02:40,  5.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.4667    0.5385    0.5000        13\n",
      "           1     0.6250    0.5556    0.5882        18\n",
      "\n",
      "    accuracy                         0.5484        31\n",
      "   macro avg     0.5458    0.5470    0.5441        31\n",
      "weighted avg     0.5586    0.5484    0.5512        31\n",
      "\n",
      "Evaluating model 64k_lstm_no_whitespace_pert_vanilla on clean\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9091    0.7692    0.8333        13\n",
      "           1     0.8500    0.9444    0.8947        18\n",
      "\n",
      "    accuracy                         0.8710        31\n",
      "   macro avg     0.8795    0.8568    0.8640        31\n",
      "weighted avg     0.8748    0.8710    0.8690        31\n",
      "\n",
      "Evaluating model 64k_lstm_no_whitespace_pert_vanilla on stochastic_no_ws\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:28<00:00,  2.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8182    0.6923    0.7500        13\n",
      "           1     0.8000    0.8889    0.8421        18\n",
      "\n",
      "    accuracy                         0.8065        31\n",
      "   macro avg     0.8091    0.7906    0.7961        31\n",
      "weighted avg     0.8076    0.8065    0.8035        31\n",
      "\n",
      "Evaluating model 64k_lstm_no_whitespace_pert_vanilla on stochastic_incl_ws\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:28<00:00,  2.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6667    0.6154    0.6400        13\n",
      "           1     0.7368    0.7778    0.7568        18\n",
      "\n",
      "    accuracy                         0.7097        31\n",
      "   macro avg     0.7018    0.6966    0.6984        31\n",
      "weighted avg     0.7074    0.7097    0.7078        31\n",
      "\n",
      "Evaluating model 64k_lstm_no_whitespace_pert_vanilla on word_score_no_ws\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31it [02:59,  5.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8000    0.6154    0.6957        13\n",
      "           1     0.7619    0.8889    0.8205        18\n",
      "\n",
      "    accuracy                         0.7742        31\n",
      "   macro avg     0.7810    0.7521    0.7581        31\n",
      "weighted avg     0.7779    0.7742    0.7682        31\n",
      "\n",
      "Evaluating model 64k_lstm_no_whitespace_pert_vanilla on word_score_incl_ws\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31it [03:03,  5.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7500    0.6923    0.7200        13\n",
      "           1     0.7895    0.8333    0.8108        18\n",
      "\n",
      "    accuracy                         0.7742        31\n",
      "   macro avg     0.7697    0.7628    0.7654        31\n",
      "weighted avg     0.7729    0.7742    0.7727        31\n",
      "\n",
      "Evaluating model 64k_lstm_all_pert_vanilla on clean\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8333    0.7692    0.8000        13\n",
      "           1     0.8421    0.8889    0.8649        18\n",
      "\n",
      "    accuracy                         0.8387        31\n",
      "   macro avg     0.8377    0.8291    0.8324        31\n",
      "weighted avg     0.8384    0.8387    0.8377        31\n",
      "\n",
      "Evaluating model 64k_lstm_all_pert_vanilla on stochastic_no_ws\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:28<00:00,  2.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8182    0.6923    0.7500        13\n",
      "           1     0.8000    0.8889    0.8421        18\n",
      "\n",
      "    accuracy                         0.8065        31\n",
      "   macro avg     0.8091    0.7906    0.7961        31\n",
      "weighted avg     0.8076    0.8065    0.8035        31\n",
      "\n",
      "Evaluating model 64k_lstm_all_pert_vanilla on stochastic_incl_ws\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:28<00:00,  2.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8182    0.6923    0.7500        13\n",
      "           1     0.8000    0.8889    0.8421        18\n",
      "\n",
      "    accuracy                         0.8065        31\n",
      "   macro avg     0.8091    0.7906    0.7961        31\n",
      "weighted avg     0.8076    0.8065    0.8035        31\n",
      "\n",
      "Evaluating model 64k_lstm_all_pert_vanilla on word_score_no_ws\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31it [02:59,  5.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8182    0.6923    0.7500        13\n",
      "           1     0.8000    0.8889    0.8421        18\n",
      "\n",
      "    accuracy                         0.8065        31\n",
      "   macro avg     0.8091    0.7906    0.7961        31\n",
      "weighted avg     0.8076    0.8065    0.8035        31\n",
      "\n",
      "Evaluating model 64k_lstm_all_pert_vanilla on word_score_incl_ws\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31it [02:53,  5.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7500    0.6923    0.7200        13\n",
      "           1     0.7895    0.8333    0.8108        18\n",
      "\n",
      "    accuracy                         0.7742        31\n",
      "   macro avg     0.7697    0.7628    0.7654        31\n",
      "weighted avg     0.7729    0.7742    0.7727        31\n",
      "\n",
      "Evaluating model 64k_lstm_clean_finetuned on clean\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9167    0.8462    0.8800        13\n",
      "           1     0.8947    0.9444    0.9189        18\n",
      "\n",
      "    accuracy                         0.9032        31\n",
      "   macro avg     0.9057    0.8953    0.8995        31\n",
      "weighted avg     0.9039    0.9032    0.9026        31\n",
      "\n",
      "Evaluating model 64k_lstm_clean_finetuned on stochastic_no_ws\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:28<00:00,  2.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7273    0.6154    0.6667        13\n",
      "           1     0.7500    0.8333    0.7895        18\n",
      "\n",
      "    accuracy                         0.7419        31\n",
      "   macro avg     0.7386    0.7244    0.7281        31\n",
      "weighted avg     0.7405    0.7419    0.7380        31\n",
      "\n",
      "Evaluating model 64k_lstm_clean_finetuned on stochastic_incl_ws\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:28<00:00,  2.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6923    0.6923    0.6923        13\n",
      "           1     0.7778    0.7778    0.7778        18\n",
      "\n",
      "    accuracy                         0.7419        31\n",
      "   macro avg     0.7350    0.7350    0.7350        31\n",
      "weighted avg     0.7419    0.7419    0.7419        31\n",
      "\n",
      "Evaluating model 64k_lstm_clean_finetuned on word_score_no_ws\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31it [02:55,  5.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6923    0.6923    0.6923        13\n",
      "           1     0.7778    0.7778    0.7778        18\n",
      "\n",
      "    accuracy                         0.7419        31\n",
      "   macro avg     0.7350    0.7350    0.7350        31\n",
      "weighted avg     0.7419    0.7419    0.7419        31\n",
      "\n",
      "Evaluating model 64k_lstm_clean_finetuned on word_score_incl_ws\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31it [02:51,  5.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6154    0.6154    0.6154        13\n",
      "           1     0.7222    0.7222    0.7222        18\n",
      "\n",
      "    accuracy                         0.6774        31\n",
      "   macro avg     0.6688    0.6688    0.6688        31\n",
      "weighted avg     0.6774    0.6774    0.6774        31\n",
      "\n",
      "Evaluating model 64k_lstm_no_whitespace_pert_finetuned on clean\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8571    0.9231    0.8889        13\n",
      "           1     0.9412    0.8889    0.9143        18\n",
      "\n",
      "    accuracy                         0.9032        31\n",
      "   macro avg     0.8992    0.9060    0.9016        31\n",
      "weighted avg     0.9059    0.9032    0.9036        31\n",
      "\n",
      "Evaluating model 64k_lstm_no_whitespace_pert_finetuned on stochastic_no_ws\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:28<00:00,  2.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8333    0.7692    0.8000        13\n",
      "           1     0.8421    0.8889    0.8649        18\n",
      "\n",
      "    accuracy                         0.8387        31\n",
      "   macro avg     0.8377    0.8291    0.8324        31\n",
      "weighted avg     0.8384    0.8387    0.8377        31\n",
      "\n",
      "Evaluating model 64k_lstm_no_whitespace_pert_finetuned on stochastic_incl_ws\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:28<00:00,  2.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6667    0.6154    0.6400        13\n",
      "           1     0.7368    0.7778    0.7568        18\n",
      "\n",
      "    accuracy                         0.7097        31\n",
      "   macro avg     0.7018    0.6966    0.6984        31\n",
      "weighted avg     0.7074    0.7097    0.7078        31\n",
      "\n",
      "Evaluating model 64k_lstm_no_whitespace_pert_finetuned on word_score_no_ws\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31it [03:03,  5.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8000    0.6154    0.6957        13\n",
      "           1     0.7619    0.8889    0.8205        18\n",
      "\n",
      "    accuracy                         0.7742        31\n",
      "   macro avg     0.7810    0.7521    0.7581        31\n",
      "weighted avg     0.7779    0.7742    0.7682        31\n",
      "\n",
      "Evaluating model 64k_lstm_no_whitespace_pert_finetuned on word_score_incl_ws\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31it [03:00,  5.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7500    0.6923    0.7200        13\n",
      "           1     0.7895    0.8333    0.8108        18\n",
      "\n",
      "    accuracy                         0.7742        31\n",
      "   macro avg     0.7697    0.7628    0.7654        31\n",
      "weighted avg     0.7729    0.7742    0.7727        31\n",
      "\n",
      "Evaluating model 64k_lstm_all_pert_finetuned on clean\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:02<00:00,  2.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8333    0.7692    0.8000        13\n",
      "           1     0.8421    0.8889    0.8649        18\n",
      "\n",
      "    accuracy                         0.8387        31\n",
      "   macro avg     0.8377    0.8291    0.8324        31\n",
      "weighted avg     0.8384    0.8387    0.8377        31\n",
      "\n",
      "Evaluating model 64k_lstm_all_pert_finetuned on stochastic_no_ws\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:28<00:00,  2.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8182    0.6923    0.7500        13\n",
      "           1     0.8000    0.8889    0.8421        18\n",
      "\n",
      "    accuracy                         0.8065        31\n",
      "   macro avg     0.8091    0.7906    0.7961        31\n",
      "weighted avg     0.8076    0.8065    0.8035        31\n",
      "\n",
      "Evaluating model 64k_lstm_all_pert_finetuned on stochastic_incl_ws\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:28<00:00,  2.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7500    0.6923    0.7200        13\n",
      "           1     0.7895    0.8333    0.8108        18\n",
      "\n",
      "    accuracy                         0.7742        31\n",
      "   macro avg     0.7697    0.7628    0.7654        31\n",
      "weighted avg     0.7729    0.7742    0.7727        31\n",
      "\n",
      "Evaluating model 64k_lstm_all_pert_finetuned on word_score_no_ws\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31it [03:01,  5.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8000    0.6154    0.6957        13\n",
      "           1     0.7619    0.8889    0.8205        18\n",
      "\n",
      "    accuracy                         0.7742        31\n",
      "   macro avg     0.7810    0.7521    0.7581        31\n",
      "weighted avg     0.7779    0.7742    0.7682        31\n",
      "\n",
      "Evaluating model 64k_lstm_all_pert_finetuned on word_score_incl_ws\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31it [03:03,  5.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7500    0.6923    0.7200        13\n",
      "           1     0.7895    0.8333    0.8108        18\n",
      "\n",
      "    accuracy                         0.7742        31\n",
      "   macro avg     0.7697    0.7628    0.7654        31\n",
      "weighted avg     0.7729    0.7742    0.7727        31\n",
      "\n",
      "Evaluating model 64k_cnn_no_whitespace_pert_finetuned on clean\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:01<00:00,  1.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    0.0769    0.1429        13\n",
      "           1     0.6000    1.0000    0.7500        18\n",
      "\n",
      "    accuracy                         0.6129        31\n",
      "   macro avg     0.8000    0.5385    0.4464        31\n",
      "weighted avg     0.7677    0.6129    0.4954        31\n",
      "\n",
      "Evaluating model 64k_cnn_no_whitespace_pert_finetuned on stochastic_no_ws\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:17<00:00,  1.72s/it]\n",
      "/anaconda/envs/cs224u/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/anaconda/envs/cs224u/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/anaconda/envs/cs224u/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000        13\n",
      "           1     0.5806    1.0000    0.7347        18\n",
      "\n",
      "    accuracy                         0.5806        31\n",
      "   macro avg     0.2903    0.5000    0.3673        31\n",
      "weighted avg     0.3371    0.5806    0.4266        31\n",
      "\n",
      "Evaluating model 64k_cnn_no_whitespace_pert_finetuned on stochastic_incl_ws\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:17<00:00,  1.72s/it]\n",
      "/anaconda/envs/cs224u/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/anaconda/envs/cs224u/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/anaconda/envs/cs224u/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000        13\n",
      "           1     0.5806    1.0000    0.7347        18\n",
      "\n",
      "    accuracy                         0.5806        31\n",
      "   macro avg     0.2903    0.5000    0.3673        31\n",
      "weighted avg     0.3371    0.5806    0.4266        31\n",
      "\n",
      "Evaluating model 64k_cnn_no_whitespace_pert_finetuned on word_score_no_ws\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31it [00:34,  1.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    0.0769    0.1429        13\n",
      "           1     0.6000    1.0000    0.7500        18\n",
      "\n",
      "    accuracy                         0.6129        31\n",
      "   macro avg     0.8000    0.5385    0.4464        31\n",
      "weighted avg     0.7677    0.6129    0.4954        31\n",
      "\n",
      "Evaluating model 64k_cnn_no_whitespace_pert_finetuned on word_score_incl_ws\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31it [00:35,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    0.0769    0.1429        13\n",
      "           1     0.6000    1.0000    0.7500        18\n",
      "\n",
      "    accuracy                         0.6129        31\n",
      "   macro avg     0.8000    0.5385    0.4464        31\n",
      "weighted avg     0.7677    0.6129    0.4954        31\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy_df = pd.DataFrame(columns=evaluations, index=all_models.keys())\n",
    "f1_df = pd.DataFrame(columns=evaluations, index=all_models.keys())\n",
    "\n",
    "for cur_model_name, cur_model in all_models.items():\n",
    "    for cur_evaluation in evaluations:\n",
    "        print(f'Evaluating model {cur_model_name} on {cur_evaluation}')\n",
    "        random.seed(11)\n",
    "        if cur_evaluation == 'clean':\n",
    "            acc, f1 = evaluate_model(cur_model, sampled_test_set)\n",
    "        elif cur_evaluation.startswith('stochastic_'):\n",
    "            if cur_evaluation == 'stochastic_no_ws':\n",
    "                acc_list, f1_list = evaluate_model_adv(cur_model, sampled_test_set_adv_no_ws)\n",
    "            elif cur_evaluation == 'stochastic_incl_ws':\n",
    "                acc_list, f1_list = evaluate_model_adv(cur_model, sampled_test_set_adv_incl_ws)\n",
    "            acc = acc_list[-1]\n",
    "            f1 = f1_list[-1]\n",
    "        elif cur_evaluation.startswith('word_score_'):\n",
    "            if cur_evaluation == 'word_score_no_ws':\n",
    "                acc, f1 = evaluate_model_word_score(cur_model, sampled_test_set, allow_whitespace_pert=False)\n",
    "            elif cur_evaluation == 'word_score_incl_ws':\n",
    "                acc, f1 = evaluate_model_word_score(cur_model, sampled_test_set, allow_whitespace_pert=True)\n",
    "\n",
    "        accuracy_df[cur_evaluation][cur_model_name] = acc\n",
    "        f1_df[cur_evaluation][cur_model_name] = f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "6e229c55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean</th>\n",
       "      <th>stochastic_no_ws</th>\n",
       "      <th>stochastic_incl_ws</th>\n",
       "      <th>word_score_no_ws</th>\n",
       "      <th>word_score_incl_ws</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>baseline</th>\n",
       "      <td>0.967742</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.83871</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.677419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roben_1</th>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.548387</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.645161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roben_2</th>\n",
       "      <td>0.83871</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.612903</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.709677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64k_lstm_clean_vanilla</th>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.548387</td>\n",
       "      <td>0.548387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64k_lstm_no_whitespace_pert_vanilla</th>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.774194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64k_lstm_all_pert_vanilla</th>\n",
       "      <td>0.83871</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.774194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64k_lstm_clean_finetuned</th>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.677419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64k_lstm_no_whitespace_pert_finetuned</th>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.83871</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.774194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64k_lstm_all_pert_finetuned</th>\n",
       "      <td>0.83871</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.774194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64k_cnn_no_whitespace_pert_finetuned</th>\n",
       "      <td>0.612903</td>\n",
       "      <td>0.580645</td>\n",
       "      <td>0.580645</td>\n",
       "      <td>0.612903</td>\n",
       "      <td>0.612903</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          clean stochastic_no_ws  \\\n",
       "baseline                               0.967742         0.774194   \n",
       "roben_1                                0.806452         0.741935   \n",
       "roben_2                                 0.83871         0.806452   \n",
       "64k_lstm_clean_vanilla                 0.870968         0.709677   \n",
       "64k_lstm_no_whitespace_pert_vanilla    0.870968         0.806452   \n",
       "64k_lstm_all_pert_vanilla               0.83871         0.806452   \n",
       "64k_lstm_clean_finetuned               0.903226         0.741935   \n",
       "64k_lstm_no_whitespace_pert_finetuned  0.903226          0.83871   \n",
       "64k_lstm_all_pert_finetuned             0.83871         0.806452   \n",
       "64k_cnn_no_whitespace_pert_finetuned   0.612903         0.580645   \n",
       "\n",
       "                                      stochastic_incl_ws word_score_no_ws  \\\n",
       "baseline                                         0.83871         0.741935   \n",
       "roben_1                                         0.548387         0.677419   \n",
       "roben_2                                         0.612903         0.709677   \n",
       "64k_lstm_clean_vanilla                          0.677419         0.548387   \n",
       "64k_lstm_no_whitespace_pert_vanilla             0.709677         0.774194   \n",
       "64k_lstm_all_pert_vanilla                       0.806452         0.806452   \n",
       "64k_lstm_clean_finetuned                        0.741935         0.741935   \n",
       "64k_lstm_no_whitespace_pert_finetuned           0.709677         0.774194   \n",
       "64k_lstm_all_pert_finetuned                     0.774194         0.774194   \n",
       "64k_cnn_no_whitespace_pert_finetuned            0.580645         0.612903   \n",
       "\n",
       "                                      word_score_incl_ws  \n",
       "baseline                                        0.677419  \n",
       "roben_1                                         0.645161  \n",
       "roben_2                                         0.709677  \n",
       "64k_lstm_clean_vanilla                          0.548387  \n",
       "64k_lstm_no_whitespace_pert_vanilla             0.774194  \n",
       "64k_lstm_all_pert_vanilla                       0.774194  \n",
       "64k_lstm_clean_finetuned                        0.677419  \n",
       "64k_lstm_no_whitespace_pert_finetuned           0.774194  \n",
       "64k_lstm_all_pert_finetuned                     0.774194  \n",
       "64k_cnn_no_whitespace_pert_finetuned            0.612903  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "79f4cd33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean</th>\n",
       "      <th>stochastic_no_ws</th>\n",
       "      <th>stochastic_incl_ws</th>\n",
       "      <th>word_score_no_ws</th>\n",
       "      <th>word_score_incl_ws</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>baseline</th>\n",
       "      <td>0.966486</td>\n",
       "      <td>0.758082</td>\n",
       "      <td>0.827202</td>\n",
       "      <td>0.735043</td>\n",
       "      <td>0.668803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roben_1</th>\n",
       "      <td>0.796053</td>\n",
       "      <td>0.718182</td>\n",
       "      <td>0.506818</td>\n",
       "      <td>0.647727</td>\n",
       "      <td>0.603949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roben_2</th>\n",
       "      <td>0.832432</td>\n",
       "      <td>0.796053</td>\n",
       "      <td>0.592105</td>\n",
       "      <td>0.688963</td>\n",
       "      <td>0.698378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64k_lstm_clean_vanilla</th>\n",
       "      <td>0.867521</td>\n",
       "      <td>0.704762</td>\n",
       "      <td>0.67437</td>\n",
       "      <td>0.544118</td>\n",
       "      <td>0.544118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64k_lstm_no_whitespace_pert_vanilla</th>\n",
       "      <td>0.864035</td>\n",
       "      <td>0.796053</td>\n",
       "      <td>0.698378</td>\n",
       "      <td>0.758082</td>\n",
       "      <td>0.765405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64k_lstm_all_pert_vanilla</th>\n",
       "      <td>0.832432</td>\n",
       "      <td>0.796053</td>\n",
       "      <td>0.796053</td>\n",
       "      <td>0.796053</td>\n",
       "      <td>0.765405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64k_lstm_clean_finetuned</th>\n",
       "      <td>0.899459</td>\n",
       "      <td>0.72807</td>\n",
       "      <td>0.735043</td>\n",
       "      <td>0.735043</td>\n",
       "      <td>0.668803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64k_lstm_no_whitespace_pert_finetuned</th>\n",
       "      <td>0.901587</td>\n",
       "      <td>0.832432</td>\n",
       "      <td>0.698378</td>\n",
       "      <td>0.758082</td>\n",
       "      <td>0.765405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64k_lstm_all_pert_finetuned</th>\n",
       "      <td>0.832432</td>\n",
       "      <td>0.796053</td>\n",
       "      <td>0.765405</td>\n",
       "      <td>0.758082</td>\n",
       "      <td>0.765405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64k_cnn_no_whitespace_pert_finetuned</th>\n",
       "      <td>0.446429</td>\n",
       "      <td>0.367347</td>\n",
       "      <td>0.367347</td>\n",
       "      <td>0.446429</td>\n",
       "      <td>0.446429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          clean stochastic_no_ws  \\\n",
       "baseline                               0.966486         0.758082   \n",
       "roben_1                                0.796053         0.718182   \n",
       "roben_2                                0.832432         0.796053   \n",
       "64k_lstm_clean_vanilla                 0.867521         0.704762   \n",
       "64k_lstm_no_whitespace_pert_vanilla    0.864035         0.796053   \n",
       "64k_lstm_all_pert_vanilla              0.832432         0.796053   \n",
       "64k_lstm_clean_finetuned               0.899459          0.72807   \n",
       "64k_lstm_no_whitespace_pert_finetuned  0.901587         0.832432   \n",
       "64k_lstm_all_pert_finetuned            0.832432         0.796053   \n",
       "64k_cnn_no_whitespace_pert_finetuned   0.446429         0.367347   \n",
       "\n",
       "                                      stochastic_incl_ws word_score_no_ws  \\\n",
       "baseline                                        0.827202         0.735043   \n",
       "roben_1                                         0.506818         0.647727   \n",
       "roben_2                                         0.592105         0.688963   \n",
       "64k_lstm_clean_vanilla                           0.67437         0.544118   \n",
       "64k_lstm_no_whitespace_pert_vanilla             0.698378         0.758082   \n",
       "64k_lstm_all_pert_vanilla                       0.796053         0.796053   \n",
       "64k_lstm_clean_finetuned                        0.735043         0.735043   \n",
       "64k_lstm_no_whitespace_pert_finetuned           0.698378         0.758082   \n",
       "64k_lstm_all_pert_finetuned                     0.765405         0.758082   \n",
       "64k_cnn_no_whitespace_pert_finetuned            0.367347         0.446429   \n",
       "\n",
       "                                      word_score_incl_ws  \n",
       "baseline                                        0.668803  \n",
       "roben_1                                         0.603949  \n",
       "roben_2                                         0.698378  \n",
       "64k_lstm_clean_vanilla                          0.544118  \n",
       "64k_lstm_no_whitespace_pert_vanilla             0.765405  \n",
       "64k_lstm_all_pert_vanilla                       0.765405  \n",
       "64k_lstm_clean_finetuned                        0.668803  \n",
       "64k_lstm_no_whitespace_pert_finetuned           0.765405  \n",
       "64k_lstm_all_pert_finetuned                     0.765405  \n",
       "64k_cnn_no_whitespace_pert_finetuned            0.446429  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "4b227192",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_df.to_csv(\"../output/grid_accuracy.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "69cb79c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_df.to_csv(\"../output/grid_f1.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
