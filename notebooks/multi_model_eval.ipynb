{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "027f446b",
   "metadata": {},
   "source": [
    "# Multi Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67daa863",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T17:37:11.549957Z",
     "iopub.status.busy": "2022-03-31T17:37:11.549161Z",
     "iopub.status.idle": "2022-03-31T17:38:55.687241Z",
     "shell.execute_reply": "2022-03-31T17:38:55.687845Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import copy\n",
    "import cProfile\n",
    "from datasets import load_dataset\n",
    "import itertools\n",
    "import json\n",
    "import math\n",
    "import nltk\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer, DataCollatorWithPadding, \\\n",
    "                         AutoModelForSequenceClassification, BertForSequenceClassification, \\\n",
    "                         BertModel, RobertaForSequenceClassification, RobertaModel\n",
    "\n",
    "from resilient_nlp.mini_roben import Clustering, ClusterRepRecoverer, ClusterRecovererWithPassthrough\n",
    "from resilient_nlp.models import BertClassifier\n",
    "from resilient_nlp.perturbers import ToyPerturber, WordScramblerPerturber\n",
    "from runner import ExperimentRunner\n",
    "from word_score_attack import BertWordScoreAttack\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5745bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = ('imdb', 'sst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b0399e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_types = ('bert', 'roberta')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920f47fc",
   "metadata": {},
   "source": [
    "Config for final evaluation on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4efd0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#eval_set_size = 500\n",
    "#use_dev_set = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67326e3",
   "metadata": {},
   "source": [
    "Config for evaluation on dev set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e1860e",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_set_size = 113\n",
    "use_dev_set = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c824af5",
   "metadata": {},
   "source": [
    "## IMDb Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0903049b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_test_set = {}\n",
    "sampled_test_set_dict = {}\n",
    "sampled_test_set_adv_no_ws = {}\n",
    "sampled_test_set_adv_incl_ws = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae7a7c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T17:38:55.696962Z",
     "iopub.status.busy": "2022-03-31T17:38:55.696275Z",
     "iopub.status.idle": "2022-03-31T17:38:57.375270Z",
     "shell.execute_reply": "2022-03-31T17:38:57.375885Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "imdb = load_dataset('artemis13fowl/imdb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc64b56",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T17:38:57.393928Z",
     "iopub.status.busy": "2022-03-31T17:38:57.393247Z",
     "iopub.status.idle": "2022-03-31T17:38:57.432347Z",
     "shell.execute_reply": "2022-03-31T17:38:57.432870Z"
    }
   },
   "outputs": [],
   "source": [
    "random.seed(11)\n",
    "if use_dev_set:\n",
    "    sampled_test_set['imdb'] = imdb['dev'].select(random.choices(range(len(imdb['dev'])), k=eval_set_size))\n",
    "else:\n",
    "    sampled_test_set['imdb'] = imdb['attack_eval_truncated'][:eval_set_size]\n",
    "\n",
    "\n",
    "# This is silly but apparently huggingface datasets are immutable?\n",
    "# Representing it as something a bit more sane\n",
    "sampled_test_set_dict['imdb'] = [\n",
    "    {\n",
    "        'text': row['text'],\n",
    "        'label': row['label'],\n",
    "    }\n",
    "    for row in sampled_test_set['imdb']\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34d21ea",
   "metadata": {},
   "source": [
    "## SST-5 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38106401",
   "metadata": {},
   "outputs": [],
   "source": [
    "treebank_detok = TreebankWordDetokenizer()\n",
    "\n",
    "sst = load_dataset('sst').map(\n",
    "    lambda row: {\n",
    "        \"text\": treebank_detok.detokenize(row[\"sentence\"].split()),\n",
    "        \"label\": min(math.floor(row[\"label\"] / 0.2), 4.0),\n",
    "    }, remove_columns=['sentence', 'tokens', 'tree']\n",
    ")\n",
    "\n",
    "random.seed(11)\n",
    "if use_dev_set:\n",
    "    sampled_test_set['sst'] = sst['validation'].select(random.choices(range(len(sst['validation'])), k=eval_set_size))\n",
    "else:\n",
    "    sampled_test_set['sst'] = sst['test'].select(random.choices(range(len(sst['validation'])), k=eval_set_size))\n",
    "\n",
    "sampled_test_set_dict['sst'] = [\n",
    "    {\n",
    "        'text': row['text'],\n",
    "        'label': row['label'],\n",
    "    }\n",
    "    for row in sampled_test_set['sst']\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5ec74a",
   "metadata": {},
   "source": [
    "### Perturbations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0dab9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_perturbed_multiset(input, wsp):\n",
    "    random.seed(11)\n",
    "    result = []\n",
    "\n",
    "    for i in range(10):\n",
    "        test_item = copy.deepcopy(input)\n",
    "\n",
    "        for row in test_item:\n",
    "            row['text'] = wsp.perturb([row['text']])[0][0]\n",
    "        result.append(test_item)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf674fa6",
   "metadata": {},
   "source": [
    "Perturbed set with no whitespace modifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8712401f",
   "metadata": {},
   "outputs": [],
   "source": [
    "wsp = WordScramblerPerturber(perturb_prob=0.1, weight_add=1, weight_drop=1, weight_swap=1,\n",
    "                             weight_split_word=0, weight_merge_words=0)\n",
    "\n",
    "for task in tasks:\n",
    "    sampled_test_set_adv_no_ws[task] = generate_perturbed_multiset(sampled_test_set_dict[task], wsp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc4acd0",
   "metadata": {},
   "source": [
    "Perturbed set with whitespace modifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72861511",
   "metadata": {},
   "outputs": [],
   "source": [
    "wsp = WordScramblerPerturber(perturb_prob=0.1, weight_add=1, weight_drop=1, weight_swap=1,\n",
    "                             weight_split_word=1, weight_merge_words=1)\n",
    "\n",
    "for task in tasks:\n",
    "    sampled_test_set_adv_incl_ws[task] = generate_perturbed_multiset(sampled_test_set_dict[task], wsp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6454c2",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370b1cdb",
   "metadata": {},
   "source": [
    "### BERT, including finetuned variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3573bce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = {}\n",
    "model_base = {}\n",
    "model_finetuned = { type: {} for type in model_types }\n",
    "model_finetuned_all_pert = { type: {} for type in model_types }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17700b9e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T17:38:57.438989Z",
     "iopub.status.busy": "2022-03-31T17:38:57.436437Z",
     "iopub.status.idle": "2022-03-31T17:38:58.316850Z",
     "shell.execute_reply": "2022-03-31T17:38:58.316245Z"
    }
   },
   "outputs": [],
   "source": [
    "bert_checkpoint = \"bert-base-uncased\"\n",
    "tokenizer['bert'] = AutoTokenizer.from_pretrained(bert_checkpoint)\n",
    "model_base['bert'] = BertModel.from_pretrained(bert_checkpoint).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09ce62d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T17:38:58.323968Z",
     "iopub.status.busy": "2022-03-31T17:38:58.321059Z",
     "iopub.status.idle": "2022-03-31T17:41:02.742864Z",
     "shell.execute_reply": "2022-03-31T17:41:02.743367Z"
    }
   },
   "outputs": [],
   "source": [
    "bert_checkpoint_finetuned_imdb = \"artemis13fowl/bert-base-uncased-imdb\"\n",
    "model_finetuned['bert']['imdb'] = BertForSequenceClassification.from_pretrained(bert_checkpoint_finetuned_imdb).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bc679c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_checkpoint_finetuned_imdb_all_pert = \"jjezabek/bert-base-uncased-imdb-all-pert\"\n",
    "model_finetuned_all_pert['bert']['imdb'] = BertForSequenceClassification.from_pretrained(bert_checkpoint_finetuned_imdb_all_pert).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2454c4ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T17:38:58.323968Z",
     "iopub.status.busy": "2022-03-31T17:38:58.321059Z",
     "iopub.status.idle": "2022-03-31T17:41:02.742864Z",
     "shell.execute_reply": "2022-03-31T17:41:02.743367Z"
    }
   },
   "outputs": [],
   "source": [
    "bert_checkpoint_finetuned_sst = \"jjezabek/bert-base-uncased-sst\"\n",
    "model_finetuned['bert']['sst'] = BertForSequenceClassification.from_pretrained(bert_checkpoint_finetuned_sst).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084978a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T17:38:57.438989Z",
     "iopub.status.busy": "2022-03-31T17:38:57.436437Z",
     "iopub.status.idle": "2022-03-31T17:38:58.316850Z",
     "shell.execute_reply": "2022-03-31T17:38:58.316245Z"
    }
   },
   "outputs": [],
   "source": [
    "roberta_checkpoint = \"roberta-base\"\n",
    "tokenizer['roberta'] = AutoTokenizer.from_pretrained(roberta_checkpoint)\n",
    "model_base['roberta'] = RobertaModel.from_pretrained(roberta_checkpoint).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a93a042",
   "metadata": {},
   "outputs": [],
   "source": [
    "roberta_checkpoint_finetuned_imdb = \"jjezabek/roberta-base-imdb\"\n",
    "model_finetuned['roberta']['imdb'] = RobertaForSequenceClassification.from_pretrained(roberta_checkpoint_finetuned_imdb).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae40370",
   "metadata": {},
   "outputs": [],
   "source": [
    "roberta_checkpoint_finetuned_sst = '/home/jasko/resilient_nlp/output/roberta-base-sst/checkpoint-900'\n",
    "model_finetuned['roberta']['sst'] = RobertaForSequenceClassification.from_pretrained(roberta_checkpoint_finetuned_sst).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63dab18",
   "metadata": {},
   "source": [
    "### RobEn clusterings (as baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5758ab39",
   "metadata": {},
   "source": [
    "The first clustering is ConnComp (which very aggressively merges clusters). The second is AggClust, which uses a cost function to better preserve fidelity. The second one should generally be better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3c3fb8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T17:41:02.748232Z",
     "iopub.status.busy": "2022-03-31T17:41:02.747612Z",
     "iopub.status.idle": "2022-03-31T17:43:45.925467Z",
     "shell.execute_reply": "2022-03-31T17:43:45.924906Z"
    }
   },
   "outputs": [],
   "source": [
    "roben_clustering = Clustering.from_pickle(\"../vocab100000_ed1.pkl\")\n",
    "roben_recoverer = ClusterRecovererWithPassthrough(\"cache\", roben_clustering)\n",
    "roben_clustering2 = Clustering.from_pickle(\"../vocab100000_ed1_gamma0.3.pkl\")\n",
    "roben_recoverer2 = ClusterRecovererWithPassthrough(\"cache\", roben_clustering2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17aaf07",
   "metadata": {},
   "source": [
    "## Model Prediction Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2efe10f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T17:43:49.085047Z",
     "iopub.status.busy": "2022-03-31T17:43:49.084381Z",
     "iopub.status.idle": "2022-03-31T17:43:49.087081Z",
     "shell.execute_reply": "2022-03-31T17:43:49.086570Z"
    }
   },
   "outputs": [],
   "source": [
    "max_sequence_length = 128\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cebe273",
   "metadata": {},
   "source": [
    "These are wrappers for standard (possibly finetuned) Huggingface models, using their normal tokenizers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b958a5c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T17:43:49.094914Z",
     "iopub.status.busy": "2022-03-31T17:43:49.094323Z",
     "iopub.status.idle": "2022-03-31T17:43:49.096390Z",
     "shell.execute_reply": "2022-03-31T17:43:49.096869Z"
    }
   },
   "outputs": [],
   "source": [
    "def standard_model_predict(tokenizer, model, sentences, recoverer, return_pred_tensor, recoverer_tokenize):\n",
    "    if recoverer is not None:\n",
    "        if recoverer_tokenize:\n",
    "            tok = nltk.tokenize.treebank.TreebankWordTokenizer()\n",
    "            sentences = [ \" \".join(tok_list) for tok_list in tok.tokenize_sents(sentences) ]\n",
    "        sentences = [ recoverer.recover(s.lower()) for s in sentences ]\n",
    "        if recoverer_tokenize:\n",
    "            detok = nltk.tokenize.treebank.TreebankWordDetokenizer()\n",
    "            sentences = [ detok.detokenize(s.split(\" \")) for s in sentences]\n",
    "    tokenized = tokenizer(sentences, truncation=True, padding='max_length', max_length=max_sequence_length,\n",
    "                          return_tensors='pt')\n",
    "    tokenized = { k: v.to(device) for k, v in tokenized.items() }\n",
    "    preds = model(**tokenized)\n",
    "    if return_pred_tensor:\n",
    "        return preds\n",
    "    else:\n",
    "        return torch.argmax(preds.logits, dim=1)\n",
    "\n",
    "def wrap_standard_model(tokenizer, model, recoverer=None, return_pred_tensor=True, recoverer_tokenize=False):\n",
    "    return lambda sentences: standard_model_predict(tokenizer, model, sentences, recoverer, return_pred_tensor,\n",
    "                                                    recoverer_tokenize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3cfccf9",
   "metadata": {},
   "source": [
    "This is a wrapper for the machine trained tokenizer+embedder (aka MockingBERT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba7bb36",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T17:43:49.104843Z",
     "iopub.status.busy": "2022-03-31T17:43:49.104249Z",
     "iopub.status.idle": "2022-03-31T17:43:49.106973Z",
     "shell.execute_reply": "2022-03-31T17:43:49.107449Z"
    }
   },
   "outputs": [],
   "source": [
    "def mltokenizer_model_predict(runner, model, cls_embedding, sep_embedding, pad_embedding, sentences, return_pred_tensor):\n",
    "    # Truncate and lower case. Truncation is for performance only\n",
    "    sentences = [ s.lower()[:8*max_sequence_length] for s in sentences]\n",
    "    embedding = runner.embed(sentences=sentences,\n",
    "        start_token=cls_embedding, end_token=sep_embedding, pad_token=pad_embedding,\n",
    "        max_tokens=max_sequence_length)\n",
    "    preds = model(inputs_embeds=embedding['inputs_embeds'], attention_mask=embedding['attention_mask'])\n",
    "    if return_pred_tensor:\n",
    "        return preds\n",
    "    else:\n",
    "        return torch.argmax(preds.logits, dim=1)\n",
    "\n",
    "def wrap_mltokenizer_model(mltokenizer_prefix, tokenizer, model, cf_embedding, type, return_pred_tensor=True):\n",
    "    filename = \"../{}.pth\".format(mltokenizer_prefix)\n",
    "    runner = ExperimentRunner(device, model_filename=filename)\n",
    "    if type == 'bert':\n",
    "        cls_token_id = tokenizer.vocab['[CLS]']\n",
    "        sep_token_id = tokenizer.vocab['[SEP]']\n",
    "        pad_token_id = tokenizer.vocab['[PAD]']\n",
    "    elif type == 'roberta':\n",
    "        cls_token_id = tokenizer.vocab['<s>']\n",
    "        sep_token_id = tokenizer.vocab['</s>']\n",
    "        pad_token_id = tokenizer.vocab['<pad>']\n",
    "    cls_embedding = cf_embedding(torch.tensor([cls_token_id], device=device)).view(-1)\n",
    "    sep_embedding = cf_embedding(torch.tensor([sep_token_id], device=device)).view(-1)\n",
    "    pad_embedding = cf_embedding(torch.tensor([pad_token_id], device=device)).view(-1)\n",
    "    \n",
    "    return lambda sentences: mltokenizer_model_predict(runner, model, cls_embedding, sep_embedding,\n",
    "                                                      pad_embedding, sentences, return_pred_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1da87ea",
   "metadata": {},
   "source": [
    "## Evaluation Helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a4b8cf",
   "metadata": {},
   "source": [
    "Evaluates a wrapped model on a test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2033ec30",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T17:43:49.113921Z",
     "iopub.status.busy": "2022-03-31T17:43:49.113314Z",
     "iopub.status.idle": "2022-03-31T17:43:49.115410Z",
     "shell.execute_reply": "2022-03-31T17:43:49.115943Z"
    }
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate_model(model, test_set):\n",
    "    num_batches = math.ceil(len(test_set) / batch_size)\n",
    "    \n",
    "    sentences = [ x['text'] for x in test_set ]\n",
    "    labels = [ x['label'] for x in test_set ]\n",
    "    pred_batches = []\n",
    "    \n",
    "    for i in tqdm(range(num_batches)):\n",
    "        bs = i * batch_size\n",
    "        be = bs + batch_size\n",
    "        \n",
    "        output = model(sentences[bs:be])\n",
    "        \n",
    "        pred_batches.append(torch.argmax(output.logits, dim=1).detach().cpu())\n",
    "    preds = torch.cat(pred_batches)\n",
    "    \n",
    "    print(classification_report(labels, preds, digits=4))\n",
    "    \n",
    "    accuracy = accuracy_score(labels, preds)\n",
    "    f1 = f1_score(labels, preds, average='macro')\n",
    "    \n",
    "    return accuracy, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac39aaf",
   "metadata": {},
   "source": [
    "Evaluates a wrapped model on a stochastic, pseudo-adversarial test set. This means that each input sentence is replicated x times (typically 10) with randomized perturbations, and an attack is considered successful if *any* of the predictions is incorrect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c8259a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T17:43:49.124562Z",
     "iopub.status.busy": "2022-03-31T17:43:49.123971Z",
     "iopub.status.idle": "2022-03-31T17:43:49.125916Z",
     "shell.execute_reply": "2022-03-31T17:43:49.126467Z"
    }
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate_model_adv(model, test_sets):\n",
    "    labels = [ x['label'] for x in test_sets[0] ]\n",
    "    adv_preds = copy.copy(labels)\n",
    "    accuracy_list = []\n",
    "    f1_list = []\n",
    "    \n",
    "    for idx in tqdm(range(len(test_sets))):\n",
    "        test_set = test_sets[idx]\n",
    "        num_batches = math.ceil(len(test_set) / batch_size)\n",
    "    \n",
    "        sentences = [ x['text'] for x in test_set ]\n",
    "        pred_batches = []\n",
    "    \n",
    "        for i in range(num_batches):\n",
    "            bs = i * batch_size\n",
    "            be = bs + batch_size\n",
    "        \n",
    "            output = model(sentences[bs:be])\n",
    "        \n",
    "            pred_batches.append(torch.argmax(output.logits, dim=1).detach().cpu())\n",
    "        preds = torch.cat(pred_batches)\n",
    "        \n",
    "        for i in range(len(adv_preds)):\n",
    "            if labels[i] != preds[i]:\n",
    "                adv_preds[i] = preds[i]\n",
    "\n",
    "        accuracy_list.append(accuracy_score(labels, adv_preds))\n",
    "        f1_list.append(f1_score(labels, adv_preds, average='macro'))\n",
    "    \n",
    "    print(classification_report(labels, adv_preds, digits=4))    \n",
    "    \n",
    "    return accuracy_list, f1_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1bba12b",
   "metadata": {},
   "source": [
    "Evaluates a model using WordScoreAttack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26be9ad5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T17:43:49.132768Z",
     "iopub.status.busy": "2022-03-31T17:43:49.132187Z",
     "iopub.status.idle": "2022-03-31T17:43:49.134404Z",
     "shell.execute_reply": "2022-03-31T17:43:49.134865Z"
    }
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate_model_word_score(model, test_set, allow_whitespace_pert=True, report_prefix=None, word_scores_file=None):\n",
    "    attacker = BertWordScoreAttack(\n",
    "        WordScramblerPerturber(perturb_prob=1, weight_add=1, weight_drop=1, weight_swap=1,\n",
    "                               weight_split_word=int(allow_whitespace_pert),\n",
    "                               weight_merge_words=int(allow_whitespace_pert)),\n",
    "        word_scores_file, model, tokenizer=None, max_sequence_length=max_sequence_length\n",
    "    )\n",
    "\n",
    "    res = attacker.attack(test_set, max_tokens_to_perturb=10, max_tries_per_token=4, mode=0, print_summary=False)\n",
    "\n",
    "    if report_prefix is not None:\n",
    "        res.to_csv(f\"{report_prefix}_df.csv\")\n",
    "        with open(f\"{report_prefix}_stats.json\", \"w\") as f:\n",
    "            json.dump(attacker.compute_attack_stats(), fp=f)            \n",
    "    \n",
    "    print(classification_report(res['ground_truth'], res['perturbed_preds'], digits=4))    \n",
    "    \n",
    "    accuracy = accuracy_score(res['ground_truth'], res['perturbed_preds'])\n",
    "    f1 = f1_score(res['ground_truth'], res['perturbed_preds'], average='macro')\n",
    "    \n",
    "    return accuracy, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6fcd6e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T17:44:32.712568Z",
     "iopub.status.busy": "2022-03-31T17:44:32.711928Z",
     "iopub.status.idle": "2022-03-31T17:45:57.105422Z",
     "shell.execute_reply": "2022-03-31T17:45:57.104806Z"
    }
   },
   "outputs": [],
   "source": [
    "all_models = {\n",
    "    'baseline': lambda task, type: wrap_standard_model(tokenizer[type], model_finetuned[type][task]),\n",
    "    'baseline_all_pert': lambda task, type: wrap_standard_model(tokenizer[type], model_finetuned_all_pert[type][task]),\n",
    "    'roben_1': lambda task, type: wrap_standard_model(tokenizer[type], model_finetuned[type][task], roben_recoverer),\n",
    "    'roben_2': lambda task, type: wrap_standard_model(tokenizer[type], model_finetuned[type][task], roben_recoverer2),\n",
    "    'roben_1_tok': lambda task, type: wrap_standard_model(tokenizer[type], model_finetuned[type][task], roben_recoverer, recoverer_tokenize=True),\n",
    "    'roben_2_tok': lambda task, type: wrap_standard_model(tokenizer[type], model_finetuned[type][task], roben_recoverer2, recoverer_tokenize=True),\n",
    "}\n",
    "\n",
    "mltok_model_names = [\n",
    "    '64k_lstm_clean_vanilla',\n",
    "    '64k_lstm_no_whitespace_pert_vanilla',\n",
    "    '64k_lstm_all_pert_vanilla',\n",
    "    '64k_lstm_clean_finetuned',\n",
    "    '64k_lstm_no_whitespace_pert_finetuned',\n",
    "    '64k_lstm_all_pert_finetuned',\n",
    "    '64k_cnn_no_whitespace_pert_finetuned',\n",
    "    '2m_lstm_all_pert_finetuned',\n",
    "    '32k_lstm_all_pert_finetuned_100ep',\n",
    "]\n",
    "\n",
    "for name in mltok_model_names:\n",
    "    if name.endswith('_vanilla'):\n",
    "        cf_embedding = lambda task, type: model_base[type].embeddings.word_embeddings\n",
    "        filename = lambda task, type, name: f'output/{type}_{name}'\n",
    "    else:\n",
    "        cf_embedding = lambda task, type: model_finetuned[type][task].base_model.embeddings.word_embeddings\n",
    "        filename = lambda task, type, name: f'output/{type}_{name}_{task}'\n",
    "    # name=name is a hack to avoid Python late binding\n",
    "    all_models[name] = lambda task, type, name=name, filename=filename, cf_embedding=cf_embedding: wrap_mltokenizer_model(filename(task, type, name), tokenizer[type], model_finetuned[type][task], cf_embedding(task, type), type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61f9273",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T17:45:57.109658Z",
     "iopub.status.busy": "2022-03-31T17:45:57.109097Z",
     "iopub.status.idle": "2022-03-31T17:45:57.111181Z",
     "shell.execute_reply": "2022-03-31T17:45:57.111650Z"
    }
   },
   "outputs": [],
   "source": [
    "evaluations = [\n",
    "    'clean',\n",
    "    'stochastic_no_ws',\n",
    "    'stochastic_incl_ws',\n",
    "    'word_score_no_ws',\n",
    "    'word_score_incl_ws',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602a9ff8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-31T17:45:57.146612Z",
     "iopub.status.busy": "2022-03-31T17:45:57.142921Z",
     "iopub.status.idle": "2022-04-01T06:14:51.176862Z",
     "shell.execute_reply": "2022-04-01T06:14:51.177399Z"
    }
   },
   "outputs": [],
   "source": [
    "model_task_ids = [ f\"{model}_{type}_{task}\" for task, type, model in itertools.product(tasks, model_types, all_models.keys()) ]\n",
    "\n",
    "accuracy_df = pd.DataFrame(columns=evaluations, index=model_task_ids)\n",
    "f1_df = pd.DataFrame(columns=evaluations, index=model_task_ids)\n",
    "\n",
    "for task, type in itertools.product(tasks, model_types):\n",
    "    for cur_model_name, cur_model_factory in all_models.items():\n",
    "        try:\n",
    "            cur_model = cur_model_factory(task, type)\n",
    "        except:\n",
    "            print(f'Failed loading model {cur_model_name} on {type} for task {task}, skipping')\n",
    "            accuracy_df.drop(f\"{cur_model_name}_{type}_{task}\", inplace=True)\n",
    "            f1_df.drop(f\"{cur_model_name}_{type}_{task}\", inplace=True)\n",
    "            continue\n",
    "        for cur_evaluation in evaluations:\n",
    "            print(f'Evaluating model {cur_model_name} on {type} on {cur_evaluation} for task {task}')\n",
    "            random.seed(11)\n",
    "            if cur_evaluation == 'clean':\n",
    "                acc, f1 = evaluate_model(cur_model, sampled_test_set[task])\n",
    "            elif cur_evaluation.startswith('stochastic_'):\n",
    "                if cur_evaluation == 'stochastic_no_ws':\n",
    "                    acc_list, f1_list = evaluate_model_adv(cur_model, sampled_test_set_adv_no_ws[task])\n",
    "                elif cur_evaluation == 'stochastic_incl_ws':\n",
    "                    acc_list, f1_list = evaluate_model_adv(cur_model, sampled_test_set_adv_incl_ws[task])\n",
    "                acc = acc_list[-1]\n",
    "                f1 = f1_list[-1]\n",
    "                with open(f\"../output/eval/{cur_model_name}_{type}_{task}_{cur_evaluation}_acc_list.json\", \"w\") as f:\n",
    "                    json.dump(acc_list, fp=f)\n",
    "                with open(f\"../output/eval/{cur_model_name}_{type}_{task}_{cur_evaluation}_f1_list.json\", \"w\") as f:\n",
    "                    json.dump(f1_list, fp=f)\n",
    "            elif cur_evaluation.startswith('word_score_'):\n",
    "                if cur_evaluation == 'word_score_no_ws':\n",
    "                    acc, f1 = evaluate_model_word_score(cur_model, sampled_test_set[task], allow_whitespace_pert=False,\n",
    "                                                        report_prefix=f\"../output/eval/{cur_model_name}_{type}_{task}_{cur_evaluation}\",\n",
    "                                                        word_scores_file=f\"../output/{task}_word_scores.json\")\n",
    "                elif cur_evaluation == 'word_score_incl_ws':\n",
    "                    acc, f1 = evaluate_model_word_score(cur_model, sampled_test_set[task], allow_whitespace_pert=True,\n",
    "                                                        report_prefix=f\"../output/eval/{cur_model_name}_{type}_{task}_{cur_evaluation}\",\n",
    "                                                        word_scores_file=f\"../output/{task}_word_scores.json\")\n",
    "\n",
    "            accuracy_df[cur_evaluation][f\"{cur_model_name}_{type}_{task}\"] = acc\n",
    "            f1_df[cur_evaluation][f\"{cur_model_name}_{type}_{task}\"] = f1\n",
    "        del cur_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e229c55",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-01T06:14:51.186588Z",
     "iopub.status.busy": "2022-04-01T06:14:51.184925Z",
     "iopub.status.idle": "2022-04-01T06:14:51.198999Z",
     "shell.execute_reply": "2022-04-01T06:14:51.198401Z"
    }
   },
   "outputs": [],
   "source": [
    "accuracy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f4cd33",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-01T06:14:51.208980Z",
     "iopub.status.busy": "2022-04-01T06:14:51.208404Z",
     "iopub.status.idle": "2022-04-01T06:14:51.211291Z",
     "shell.execute_reply": "2022-04-01T06:14:51.211757Z"
    }
   },
   "outputs": [],
   "source": [
    "f1_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b227192",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-01T06:14:51.215426Z",
     "iopub.status.busy": "2022-04-01T06:14:51.214848Z",
     "iopub.status.idle": "2022-04-01T06:14:51.219469Z",
     "shell.execute_reply": "2022-04-01T06:14:51.219961Z"
    }
   },
   "outputs": [],
   "source": [
    "accuracy_df.to_csv(\"../output/grid_accuracy.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69cb79c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-01T06:14:51.223400Z",
     "iopub.status.busy": "2022-04-01T06:14:51.222326Z",
     "iopub.status.idle": "2022-04-01T06:14:51.226522Z",
     "shell.execute_reply": "2022-04-01T06:14:51.227884Z"
    }
   },
   "outputs": [],
   "source": [
    "f1_df.to_csv(\"../output/grid_f1.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fff8d67",
   "metadata": {},
   "source": [
    "-----"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "2a4bb820c60e40c1ad0f64107d79c7f1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "46a5be577b9e40eeab875a637fb2c738": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4d936e5567d94706bcf6b4ef2236e146": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_cb6ac35c597a4aaaa22afa7869915e6c",
       "placeholder": "​",
       "style": "IPY_MODEL_d449ab3082d846d9bfe6f759ce4b6961",
       "value": "100%"
      }
     },
     "9cbbe48af9c74d1fa2a1dcfd7fedf44c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_4d936e5567d94706bcf6b4ef2236e146",
        "IPY_MODEL_b819c89091db48baa8d383ab5691e161",
        "IPY_MODEL_d88b1744e4b248d4862767ee803c7a82"
       ],
       "layout": "IPY_MODEL_46a5be577b9e40eeab875a637fb2c738"
      }
     },
     "9eb4ae5d3a0e4d26a146082921db36ad": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a961553d4e66474b986f6d9279bc6cfe": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "b819c89091db48baa8d383ab5691e161": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_cf845fb3afc3455384caed6df36f6f45",
       "max": 4,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_a961553d4e66474b986f6d9279bc6cfe",
       "value": 4
      }
     },
     "cb6ac35c597a4aaaa22afa7869915e6c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "cf845fb3afc3455384caed6df36f6f45": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d449ab3082d846d9bfe6f759ce4b6961": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "d88b1744e4b248d4862767ee803c7a82": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_9eb4ae5d3a0e4d26a146082921db36ad",
       "placeholder": "​",
       "style": "IPY_MODEL_2a4bb820c60e40c1ad0f64107d79c7f1",
       "value": " 4/4 [00:00&lt;00:00,  5.44it/s]"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
