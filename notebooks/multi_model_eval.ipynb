{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67daa863",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import copy\n",
    "from datasets import load_dataset\n",
    "import math\n",
    "import random\n",
    "from sklearn.metrics import classification_report\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer, DataCollatorWithPadding, \\\n",
    "                         AutoModelForSequenceClassification, BertForSequenceClassification\n",
    "\n",
    "from resilient_nlp.models import BertClassifier\n",
    "from resilient_nlp.perturbers import ToyPerturber, WordScramblerPerturber\n",
    "from lstm import ExperimentRunner\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae7a7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb = load_dataset('imdb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc64b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(11)\n",
    "sampled_test_set = random.choices(imdb['test'], k=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17700b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09ce62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_finetuned = \"artemis13fowl/bert-base-uncased-imdb\"\n",
    "model_finetuned = BertForSequenceClassification.from_pretrained(checkpoint_finetuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b5a7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = ToyPerturber()\n",
    "wsp = WordScramblerPerturber(perturb_prob=1, weight_add=1, weight_drop=1, weight_swap=1, weight_split_word=1, weight_merge_words=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9448d315",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(11)\n",
    "sampled_test_set_perturbed1 = copy.deepcopy(sampled_test_set)\n",
    "\n",
    "for row in sampled_test_set_perturbed1:\n",
    "    row['text'] = wsp.perturb([row['text']])[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0239e916",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(11)\n",
    "sampled_test_set_perturbed2 = copy.deepcopy(sampled_test_set)\n",
    "\n",
    "for row in sampled_test_set_perturbed2:\n",
    "    row['text'] = tp.perturb([row['text']])[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2efe10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sequence_length = 128\n",
    "batch_size = 32\n",
    "eval_steps = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b958a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_model_predict(tokenizer, model, sentences):\n",
    "    tokenized = tokenizer(sentences, truncation=True, padding='max_length', max_length=max_sequence_length,\n",
    "                          return_tensors='pt')\n",
    "    preds = model(**tokenized)\n",
    "    return torch.argmax(preds.logits, dim=1)\n",
    "\n",
    "def wrap_standard_model(tokenizer, model):\n",
    "    return lambda sentences: standard_model_predict(tokenizer, model, sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba7bb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mltokenizer_model_predict(runner, model, cls_embedding, sep_embedding, pad_embedding, sentences):\n",
    "    # Truncate and lower case. Truncation is for performance only\n",
    "    # sentences = [ s.lower()[:1000] for s in sentences]\n",
    "    # To investigate - truncation gives only a small speedup and tanks accuracy.\n",
    "    # So for now turning off truncation. This is not unfair, since we limit\n",
    "    # ourselves to max_sequence_length anyway\n",
    "    sentences = [ s.lower() for s in sentences]\n",
    "    embedding = runner.embed(sentences=sentences,\n",
    "        start_token=cls_embedding, end_token=sep_embedding, pad_token=pad_embedding,\n",
    "        max_tokens=max_sequence_length)\n",
    "    preds = model(inputs_embeds=embedding['inputs_embeds'], attention_mask=embedding['attention_mask'])\n",
    "    return torch.argmax(preds.logits, dim=1)\n",
    "\n",
    "def wrap_mltokenizer_model(mltokenizer_prefix, tokenizer, model):\n",
    "    runner = ExperimentRunner(device)\n",
    "    runner.model.load(\"../{}.pth\".format(mltokenizer_prefix), device)\n",
    "    runner.char_tokenizer.load_vocab(\"../{}_vocab.json\".format(mltokenizer_prefix))\n",
    "    cf_embedding = model.base_model.embeddings.word_embeddings\n",
    "    cls_token_id = tokenizer.vocab['[CLS]']\n",
    "    sep_token_id = tokenizer.vocab['[SEP]']\n",
    "    pad_token_id = tokenizer.vocab['[PAD]']\n",
    "    cls_embedding = cf_embedding(torch.tensor([cls_token_id])).view(-1)\n",
    "    sep_embedding = cf_embedding(torch.tensor([sep_token_id])).view(-1)\n",
    "    pad_embedding = cf_embedding(torch.tensor([pad_token_id])).view(-1)\n",
    "    \n",
    "    return lambda sentences: mltokenizer_model_predict(runner, model, cls_embedding, sep_embedding,\n",
    "                                                      pad_embedding, sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2033ec30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_set):\n",
    "    num_batches = math.ceil(len(test_set) / batch_size)\n",
    "    \n",
    "    sentences = [ x['text'] for x in test_set ]\n",
    "    labels = [ x['label'] for x in test_set ]\n",
    "    pred_batches = []\n",
    "    \n",
    "    for i in tqdm(range(num_batches)):\n",
    "        bs = i * batch_size\n",
    "        be = bs + batch_size\n",
    "        \n",
    "        pred_batches.append(model(sentences[bs:be]))\n",
    "    preds = torch.cat(pred_batches)\n",
    "    \n",
    "    print(classification_report(labels, preds, digits=4))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b537d1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model = wrap_standard_model(tokenizer, model_finetuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5364f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mltok_model1 = wrap_mltokenizer_model('model4', tokenizer, model_finetuned)\n",
    "mltok_model2 = wrap_mltokenizer_model('model5', tokenizer, model_finetuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a137e5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(baseline_model, sampled_test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800dc85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(mltok_model1, sampled_test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2fe575",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(mltok_model2, sampled_test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7489dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(baseline_model, sampled_test_set_perturbed1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f8fdc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(mltok_model1, sampled_test_set_perturbed1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45cb4382",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(mltok_model2, sampled_test_set_perturbed1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e01f3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(baseline_model, sampled_test_set_perturbed2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155c9ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(mltok_model1, sampled_test_set_perturbed2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76269157",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(mltok_model2, sampled_test_set_perturbed2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
