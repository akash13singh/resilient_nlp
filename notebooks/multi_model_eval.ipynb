{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67daa863",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import copy\n",
    "from datasets import load_dataset\n",
    "import math\n",
    "import random\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer, DataCollatorWithPadding, \\\n",
    "                         AutoModelForSequenceClassification, BertForSequenceClassification\n",
    "\n",
    "from resilient_nlp.mini_roben import Clustering, ClusterRepRecoverer, ClusterRecovererWithPassthrough\n",
    "from resilient_nlp.models import BertClassifier\n",
    "from resilient_nlp.perturbers import ToyPerturber, WordScramblerPerturber\n",
    "from runner import ExperimentRunner\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ae7a7c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "276c352d177e4dfa85e2da8e3b93cf27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.07k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration artemis13fowl--imdb-f77fd77a6b2e946b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset imdb/plain_text (download: 40.09 MiB, generated: 63.08 MiB, post-processed: Unknown size, total: 103.17 MiB) to C:\\Users\\Jasko\\.cache\\huggingface\\datasets\\parquet\\artemis13fowl--imdb-f77fd77a6b2e946b\\0.0.0\\0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "deeda35ebaa347cc994d2281ed88f727",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baa3a918b38a4279a794656b6b0f9d10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/43.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f33026a93f5b4e4abcc434eddb1f330f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/816k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0362e7bc7e66474ca838e2b8e90d397c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/20.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cb04b0f77d54989bf87f34b570750b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/20.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "579acad4f0c9411cb6c7463da796a0f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset parquet downloaded and prepared to C:\\Users\\Jasko\\.cache\\huggingface\\datasets\\parquet\\artemis13fowl--imdb-f77fd77a6b2e946b\\0.0.0\\0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2550e60a5ef41e4b26f5bc8830ecd1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# imdb = load_dataset('imdb')\n",
    "imdb = load_dataset('artemis13fowl/imdb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9bc64b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(11)\n",
    "sampled_test_set = random.choices(imdb['test'], k=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "17700b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a09ce62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_finetuned = \"artemis13fowl/bert-base-uncased-imdb\"\n",
    "model_finetuned = BertForSequenceClassification.from_pretrained(checkpoint_finetuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "71b5a7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "wsp = WordScramblerPerturber(perturb_prob=0.4, weight_add=1, weight_drop=1, weight_swap=1, weight_split_word=1, weight_merge_words=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8b3c3fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "roben_clustering = Clustering.from_pickle(\"../vocab100000_ed1.pkl\")\n",
    "roben_recoverer = ClusterRecovererWithPassthrough(\"cache\", roben_clustering)\n",
    "roben_clustering2 = Clustering.from_pickle(\"../vocab100000_ed1_gamma0.3.pkl\")\n",
    "roben_recoverer2 = ClusterRecovererWithPassthrough(\"cache\", roben_clustering2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9448d315",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(11)\n",
    "sampled_test_set_perturbed = copy.deepcopy(sampled_test_set)\n",
    "\n",
    "for row in sampled_test_set_perturbed:\n",
    "    row['text'] = wsp.perturb([row['text']])[0][0]\n",
    "\n",
    "sampled_test_set_perturbed_roben = copy.deepcopy(sampled_test_set_perturbed)\n",
    "for row in sampled_test_set_perturbed_roben:\n",
    "    row['text'] = roben_recoverer.recover(row['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "effea54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(11)\n",
    "sampled_test_set_adv = []\n",
    "\n",
    "for i in range(10):\n",
    "    test_item = copy.deepcopy(sampled_test_set)\n",
    "\n",
    "    for row in test_item:\n",
    "        row['text'] = wsp.perturb([row['text']])[0][0]\n",
    "    sampled_test_set_adv.append(test_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a2efe10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sequence_length = 128\n",
    "batch_size = 32\n",
    "eval_steps = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7b958a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_model_predict(tokenizer, model, sentences, recoverer):\n",
    "    if recoverer is not None:\n",
    "        sentences = [ recoverer.recover(s.lower()) for s in sentences ]\n",
    "    tokenized = tokenizer(sentences, truncation=True, padding='max_length', max_length=max_sequence_length,\n",
    "                          return_tensors='pt')\n",
    "    preds = model(**tokenized)\n",
    "    return torch.argmax(preds.logits, dim=1)\n",
    "\n",
    "def wrap_standard_model(tokenizer, model, recoverer=None):\n",
    "    return lambda sentences: standard_model_predict(tokenizer, model, sentences, recoverer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0ba7bb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mltokenizer_model_predict(runner, model, cls_embedding, sep_embedding, pad_embedding, sentences):\n",
    "    # Truncate and lower case. Truncation is for performance only\n",
    "    # sentences = [ s.lower()[:1000] for s in sentences]\n",
    "    # To investigate - truncation gives only a small speedup and tanks accuracy.\n",
    "    # So for now turning off truncation. This is not unfair, since we limit\n",
    "    # ourselves to max_sequence_length anyway\n",
    "    sentences = [ s.lower() for s in sentences]\n",
    "    embedding = runner.embed(sentences=sentences,\n",
    "        start_token=cls_embedding, end_token=sep_embedding, pad_token=pad_embedding,\n",
    "        max_tokens=max_sequence_length)\n",
    "    preds = model(inputs_embeds=embedding['inputs_embeds'], attention_mask=embedding['attention_mask'])\n",
    "    return torch.argmax(preds.logits, dim=1)\n",
    "\n",
    "def wrap_mltokenizer_model(mltokenizer_prefix, tokenizer, model):\n",
    "    filename = \"../{}.pth\".format(mltokenizer_prefix)\n",
    "    runner = ExperimentRunner(device, model_filename=filename)\n",
    "    cf_embedding = model.base_model.embeddings.word_embeddings\n",
    "    cls_token_id = tokenizer.vocab['[CLS]']\n",
    "    sep_token_id = tokenizer.vocab['[SEP]']\n",
    "    pad_token_id = tokenizer.vocab['[PAD]']\n",
    "    cls_embedding = cf_embedding(torch.tensor([cls_token_id])).view(-1)\n",
    "    sep_embedding = cf_embedding(torch.tensor([sep_token_id])).view(-1)\n",
    "    pad_embedding = cf_embedding(torch.tensor([pad_token_id])).view(-1)\n",
    "    \n",
    "    return lambda sentences: mltokenizer_model_predict(runner, model, cls_embedding, sep_embedding,\n",
    "                                                      pad_embedding, sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2033ec30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_set):\n",
    "    num_batches = math.ceil(len(test_set) / batch_size)\n",
    "    \n",
    "    sentences = [ x['text'] for x in test_set ]\n",
    "    labels = [ x['label'] for x in test_set ]\n",
    "    pred_batches = []\n",
    "    \n",
    "    for i in tqdm(range(num_batches)):\n",
    "        bs = i * batch_size\n",
    "        be = bs + batch_size\n",
    "        \n",
    "        pred_batches.append(model(sentences[bs:be]))\n",
    "    preds = torch.cat(pred_batches)\n",
    "    \n",
    "    print(classification_report(labels, preds, digits=4))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "33c8259a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_adv(model, test_sets):\n",
    "    labels = [ x['label'] for x in test_sets[0] ]\n",
    "    adv_preds = copy.copy(labels)\n",
    "    accuracy_list = []\n",
    "    f1_list = []\n",
    "    \n",
    "    for idx in tqdm(range(len(test_sets))):\n",
    "        test_set = test_sets[idx]\n",
    "        num_batches = math.ceil(len(test_set) / batch_size)\n",
    "    \n",
    "        sentences = [ x['text'] for x in test_set ]\n",
    "        pred_batches = []\n",
    "    \n",
    "        for i in range(num_batches):\n",
    "            bs = i * batch_size\n",
    "            be = bs + batch_size\n",
    "        \n",
    "            pred_batches.append(model(sentences[bs:be]))\n",
    "        preds = torch.cat(pred_batches)\n",
    "        \n",
    "        for i in range(len(adv_preds)):\n",
    "            if labels[i] == 1.0 and preds[i] == 0.0:\n",
    "                adv_preds[i] = 0.0\n",
    "            elif labels[i] == 0.0 and preds[i] == 1.0:\n",
    "                adv_preds[i] = 1.0\n",
    "\n",
    "        accuracy_list.append(accuracy_score(labels, adv_preds))\n",
    "        f1_list.append(f1_score(labels, adv_preds, average='macro'))\n",
    "    \n",
    "    print(classification_report(labels, adv_preds, digits=4))    \n",
    "    \n",
    "    return accuracy_list, f1_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b537d1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model = wrap_standard_model(tokenizer, model_finetuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f5364f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mltok_model = wrap_mltokenizer_model('output/64k_lstm_all_pert_finetuned', tokenizer, model_finetuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6e49764a",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_roben_model = wrap_standard_model(tokenizer, model_finetuned, roben_recoverer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0eb23d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_roben_model2 = wrap_standard_model(tokenizer, model_finetuned, roben_recoverer2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a137e5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(baseline_model, sampled_test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356d0cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(baseline_roben_model, sampled_test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b3e2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(baseline_roben_model2, sampled_test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800dc85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(mltok_model, sampled_test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ba7489dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:22<00:00,  3.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7525    0.7917    0.7716        96\n",
      "           1     0.7980    0.7596    0.7783       104\n",
      "\n",
      "    accuracy                         0.7750       200\n",
      "   macro avg     0.7752    0.7756    0.7749       200\n",
      "weighted avg     0.7761    0.7750    0.7751       200\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(baseline_model, sampled_test_set_perturbed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f7b83859",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:17<00:00,  2.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7449    0.7604    0.7526        96\n",
      "           1     0.7745    0.7596    0.7670       104\n",
      "\n",
      "    accuracy                         0.7600       200\n",
      "   macro avg     0.7597    0.7600    0.7598       200\n",
      "weighted avg     0.7603    0.7600    0.7601       200\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(baseline_roben_model, sampled_test_set_perturbed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4ea55597",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:17<00:00,  2.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7917    0.7917    0.7917        96\n",
      "           1     0.8077    0.8077    0.8077       104\n",
      "\n",
      "    accuracy                         0.8000       200\n",
      "   macro avg     0.7997    0.7997    0.7997       200\n",
      "weighted avg     0.8000    0.8000    0.8000       200\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(baseline_roben_model2, sampled_test_set_perturbed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "40f8fdc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [03:38<00:00, 31.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8400    0.8750    0.8571        96\n",
      "           1     0.8800    0.8462    0.8627       104\n",
      "\n",
      "    accuracy                         0.8600       200\n",
      "   macro avg     0.8600    0.8606    0.8599       200\n",
      "weighted avg     0.8608    0.8600    0.8601       200\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(mltok_model, sampled_test_set_perturbed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "88816c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [02:48<00:00, 16.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.4107    0.4792    0.4423        96\n",
      "           1     0.4318    0.3654    0.3958       104\n",
      "\n",
      "    accuracy                         0.4200       200\n",
      "   macro avg     0.4213    0.4223    0.4191       200\n",
      "weighted avg     0.4217    0.4200    0.4181       200\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.775, 0.625, 0.555, 0.51, 0.47, 0.465, 0.455, 0.445, 0.445, 0.42],\n",
       " [0.7749493636068114,\n",
       "  0.62454006157543,\n",
       "  0.5531118977680702,\n",
       "  0.5082296266559615,\n",
       "  0.46808510638297873,\n",
       "  0.46273003439532023,\n",
       "  0.45268760513168127,\n",
       "  0.4433160309937561,\n",
       "  0.4433160309937561,\n",
       "  0.41907051282051283])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model_adv(baseline_model, sampled_test_set_adv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4f176032",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [02:55<00:00, 17.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.2935    0.2812    0.2872        96\n",
      "           1     0.3611    0.3750    0.3679       104\n",
      "\n",
      "    accuracy                         0.3300       200\n",
      "   macro avg     0.3273    0.3281    0.3276       200\n",
      "weighted avg     0.3286    0.3300    0.3292       200\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.76, 0.655, 0.575, 0.505, 0.45, 0.405, 0.375, 0.37, 0.35, 0.33],\n",
       " [0.7597838054248824,\n",
       "  0.6542999574137628,\n",
       "  0.5741376286981137,\n",
       "  0.5046904315196998,\n",
       "  0.45,\n",
       "  0.4042702310330154,\n",
       "  0.37460913070669166,\n",
       "  0.36943248924031635,\n",
       "  0.34895833333333337,\n",
       "  0.32757928542753917])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model_adv(baseline_roben_model, sampled_test_set_adv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6854c3b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [34:03<00:00, 204.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6667    0.7500    0.7059        96\n",
      "           1     0.7391    0.6538    0.6939       104\n",
      "\n",
      "    accuracy                         0.7000       200\n",
      "   macro avg     0.7029    0.7019    0.6999       200\n",
      "weighted avg     0.7043    0.7000    0.6996       200\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.86, 0.82, 0.775, 0.75, 0.74, 0.74, 0.735, 0.72, 0.715, 0.7],\n",
       " [0.8599439775910365,\n",
       "  0.8199279711884755,\n",
       "  0.7749493636068114,\n",
       "  0.74997499749975,\n",
       "  0.7399739973997399,\n",
       "  0.7399739973997399,\n",
       "  0.7349403615813558,\n",
       "  0.7199999999999999,\n",
       "  0.7149928748218706,\n",
       "  0.6998799519807923])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model_adv(mltok_model, sampled_test_set_adv)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
