{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33bc9e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertModel, BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba64ed40",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_weights_name = 'bert-base-uncased'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3cc16e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_tokenizer = BertTokenizer.from_pretrained(bert_weights_name)\n",
    "bert_model = BertModel.from_pretrained(bert_weights_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12076e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_embeddings(ids1, ids2, layer_num ):\n",
    "    with torch.no_grad():\n",
    "        reps1 = bert_model(torch.tensor([ids1]), output_hidden_states=True)\n",
    "        reps2 = bert_model(torch.tensor([ids2]), output_hidden_states=True)\n",
    "        \n",
    "    for token_num in range(len(ids1)):\n",
    "        print(token_num,\n",
    "              torch.equal(reps1.hidden_states[layer_num][0][token_num], \n",
    "                          reps2.hidden_states[layer_num][0][token_num])\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0609240",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent1 = \"Deposit money in the bank\"\n",
    "sent2 = \"View on the river bank\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ba693e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['deposit', 'money', 'in', 'the', 'bank'],\n",
       " ['view', 'on', 'the', 'river', 'bank'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens1 = bert_tokenizer.tokenize(sent1)\n",
    "tokens2 = bert_tokenizer.tokenize(sent2)\n",
    "tokens1, tokens2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9d2d0e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([101, 12816, 2769, 1999, 1996, 2924, 102],\n",
       " [101, 3193, 2006, 1996, 2314, 2924, 102])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids1 = bert_tokenizer.encode(sent1, add_special_tokens=True)\n",
    "ids2 = bert_tokenizer.encode(sent2, add_special_tokens=True)\n",
    "ids1, ids2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf6eb65",
   "metadata": {},
   "source": [
    "### Layer 0 embeddings of same words are same. \"Bank\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b98c76b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 True\n",
      "1 False\n",
      "2 False\n",
      "3 False\n",
      "4 False\n",
      "5 True\n",
      "6 True\n"
     ]
    }
   ],
   "source": [
    "compare_embeddings(ids1, ids2, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407f49ba",
   "metadata": {},
   "source": [
    "### Layer 12 emebddings of even SEP are different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12f5d9e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 False\n",
      "1 False\n",
      "2 False\n",
      "3 False\n",
      "4 False\n",
      "5 False\n",
      "6 False\n"
     ]
    }
   ],
   "source": [
    "compare_embeddings(ids1, ids2, 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9433a2e",
   "metadata": {},
   "source": [
    "### Same word at different positions have different embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62fe314b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = \"deep deep\"\n",
    "tokens = bert_tokenizer.tokenize(sent)\n",
    "tokens\n",
    "ids = bert_tokenizer.encode(sent, add_special_tokens=True)\n",
    "ids\n",
    "reps =  bert_model(torch.tensor([ids]), output_hidden_states=True)\n",
    "embeddings_0_sent = reps.hidden_states[0][0]\n",
    "embeddings_0_sent.shape\n",
    "torch.equal(embeddings_0_sent[1], embeddings_0_sent[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79031eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "local_nmt",
   "language": "python",
   "name": "local_nmt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
